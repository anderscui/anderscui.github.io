<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>82年生的金智英</title>
    <url>/2021/07/01/82%E5%B9%B4%E7%94%9F%E7%9A%84%E9%87%91%E6%99%BA%E8%8B%B1/</url>
    <content><![CDATA[<p>这本书从文学性上来讲，只能说勉强还行，但是其中金智英的经历实在太真实了，可以说让人触目惊心，将这些遭遇放在中国也毫无违和感。女性生活的整个经历，从成长、教育到职场、婚姻和育儿，充满了大量的男性难以想象的问题：性别刻板印象、性别歧视、性别规训、机会平等等等。其中的性别规训尤为突出，正如福柯所说的，性别规训是一种弥漫于整个社会的、像毛细血管似的“微观权力“。它的触手渗透到社会的方方面面，对人们的日常生活的每个细节都不放过。金智英的多数遭遇，也正符合第二波女权主义提出的”the personal is political“，因为身边的人”好像也都是这么做的“。</p>
<p>与其说金智英是得了育儿抑郁，不如说是她在压抑之下无法正常发声，只能通过变换的形象代替自己发声吧。</p>
]]></content>
  </entry>
  <entry>
    <title>Deep Learning in PyTorch</title>
    <url>/2020/06/12/Deep-Learning-in-PyTorch/</url>
    <content><![CDATA[<h1 id="Deep-Learning-in-PyTorch"><a href="#Deep-Learning-in-PyTorch" class="headerlink" title="Deep Learning in PyTorch"></a>Deep Learning in PyTorch</h1><p>该书的读书笔记，想从此系统的学习DL，尤其是NLP相关。</p>
<h1 id="1-Introducing-DL-and-PyTorch-library"><a href="#1-Introducing-DL-and-PyTorch-library" class="headerlink" title="1. Introducing DL and PyTorch library"></a>1. Introducing DL and PyTorch library</h1><h3 id="The-deep-learning-revolution"><a href="#The-deep-learning-revolution" class="headerlink" title="The deep learning revolution"></a>The deep learning revolution</h3><p>即使到2000年代末，ML领域仍然很依赖于<strong>特征工程（feature engineering）</strong>。特征用于将输入数据转换为数值，以用于下游算法。特征工程的目标是接受原始数据，得到其<strong>表示（representation）</strong>。</p>
<p>DL则将特征寻找过程自动化了。虽然，DL中仍需要特征工程，它的重点不再是精心构建特征，而是通过对数学实体的操作”发现“这些特征。通常情况下，这些自动发现的表示优于手工构建的。</p>
<h3 id="1-3-2-Immediate-versus-deferred-execution"><a href="#1-3-2-Immediate-versus-deferred-execution" class="headerlink" title="1.3.2 Immediate versus deferred execution"></a>1.3.2 Immediate versus deferred execution</h3><p>DL库们的一个关键区别是立即执行与延迟执行。PyTorch的易用性很大程度上来自于它的立即执行的实现方式。</p>
<p>PyTorch默认情况下使用立即执行（eager mode）。</p>
<p>NN的基础组块是neuron，大量neuron连接在一起构成网络。之前TF默认使用静态图，而PyTorch使用动态图，之后两者逐渐同时支持两种模式。</p>
<h2 id="1-4-PyTorch-的组件"><a href="#1-4-PyTorch-的组件" class="headerlink" title="1.4 PyTorch 的组件"></a>1.4 PyTorch 的组件</h2><p>其核心是多维数组——tensor，以及对tensor的诸多操作，这些都在<code>torch</code> 模块中。</p>
<p>创建NN的模块在 <code>torch.nn</code> 中，如全连接层，卷积层，激活函数，损失函数之类。</p>
<p>要训练模型，我们还需要：数据源管理，optimizer。加载与处理数据的工具在 <code>torch.util.data</code>，两个主要的类是 <code>Dataset</code> 和 <code>DataLoader</code>。optimizer位于 <code>torch.optim</code> 模块中。</p>
<h1 id="2-It-starts-with-a-tensor"><a href="#2-It-starts-with-a-tensor" class="headerlink" title="2. It starts with a tensor"></a>2. It starts with a tensor</h1><p>在很高的层次上，DL可以理解为将一种输入转换为另一种形式的输出。</p>
<p>转换过程的第一步，需要将输入表示为浮点数。之后的</p>
]]></content>
      <tags>
        <tag>Deep Learning, PyTorch</tag>
      </tags>
  </entry>
  <entry>
    <title>async-in-c#</title>
    <url>/2019/12/31/async-in-c/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>非典型孤独（atypical）</title>
    <url>/2017/10/03/atypical/</url>
    <content><![CDATA[<p>来自美剧<a href="https://movie.douban.com/subject/26895435/">非典型孤独（Atypical）</a></p>
<hr>
<h1 id="Nobody’s-normal"><a href="#Nobody’s-normal" class="headerlink" title="Nobody’s normal"></a>Nobody’s normal</h1><p>在剧中山姆被诊断为患有自闭症，还提到他是一个高功能自闭症，以及自闭症不能完全治愈。如果你看过《生活大爆炸》，也许会想到谢耳朵，其饰演者吉姆·帕森斯认为谢耳朵的表现很接近于阿斯伯格综合征。同时IMDB的剧集简介中提到了自闭症光谱。我想，有必要先了解一下这几个术语，下面相关术语的信息摘自维基。</p>
<h2 id="自闭症"><a href="#自闭症" class="headerlink" title="自闭症"></a>自闭症</h2><p>自闭症（Autism）为一种脑部因发育障碍所导致的疾病，其特征是情绪表达困难、社交互动障碍、语言和非语言的沟通有问题，以及日常上常见的，表现出限制的行为与重复的动作，明显的特定兴趣。不能进行正常的语言表达和社交活动，常做一些刻板和守旧性的动作和行为。自闭症的病因仍然未知，很多研究人员怀疑自闭症是由基因控制，再由环境因素触发。</p>
<p>部分自闭症患者可经过诊疗、实习及特殊教育，可改善他们的社交能力，而可参与主流教育及社交活动。<strong>但以现时医疗科技水平来说，并不可能完整根治自闭症，仅是提升自闭儿的功能</strong>。</p>
<h2 id="高功能自闭症"><a href="#高功能自闭症" class="headerlink" title="高功能自闭症"></a>高功能自闭症</h2><p>高功能自闭症（High-functioning autism，简称HFA），指智商中等或更高的自闭症患者，且多数具有语言能力，学习能力较佳、自闭倾向较不明显；但语言理解与表达力、人际互动与聊天的能力仍有困难的自闭症患者。</p>
<h2 id="阿斯伯格综合征"><a href="#阿斯伯格综合征" class="headerlink" title="阿斯伯格综合征"></a>阿斯伯格综合征</h2><p>阿斯伯格综合征（Asperger syndrome，简称AS），属一种发展障碍，其重要特征是社交与非言语交际的困难，同时伴随着兴趣狭隘及重复特定行为，但相较于其他泛自闭症障碍，仍相对保有语言及认知发展。亚斯伯格症患者的智力正常，其中有许多人智商偏高具有天赋，只有极少数的人属于高智商，经常出现肢体笨拙和语言表达方式异常等状况，偶尔会发出怪声音，但并不作为诊断依据。其症状一般在两岁前出现，并伴随患者终生，目前没有有效治疗方法，预后差。</p>
<h2 id="自闭症光谱"><a href="#自闭症光谱" class="headerlink" title="自闭症光谱"></a>自闭症光谱</h2><p>自闭症光谱（Autism spectrum）是一种心理状况的谱系障碍，亦称自闭症谱系障碍或泛自闭症障碍，描述了一个被DSM-5（精神障碍诊断与统计手册（第5版））归类为神经发展综合征的症状群的范围。 被诊断为自闭症（autism spectrum disorder (ASD)）的人必须存在下列两个症状。</p>
<ul>
<li>缺乏社交沟通与社交互动。（或社交及沟通上的广泛性异常）</li>
<li>局限的、重复的行为、兴趣或活动。（或异常局限性的兴趣、高度重复性的行为）</li>
</ul>
<p>自闭症光谱有三个主要项目：自闭症、亚斯伯格综合征、待分类的广泛性发展障碍。自闭症在光谱核心位置，而阿斯伯格综合征在手册（第5版）中被移除。</p>
<hr>
]]></content>
      <tags>
        <tag>Movie</tag>
        <tag>电影</tag>
      </tags>
  </entry>
  <entry>
    <title>beautiful-racket-part-1</title>
    <url>/2020/10/03/beautiful-racket-part-1/</url>
    <content><![CDATA[<h1 id="Foreword-by-Matthew-Flatt"><a href="#Foreword-by-Matthew-Flatt" class="headerlink" title="Foreword by Matthew Flatt"></a>Foreword by Matthew Flatt</h1><p>让我们回顾1993年时的事情：</p>
<ul>
<li>为 GC 是否可作为手动内存管理的替代项而争论过（当时还没有 Java）</li>
<li>为一等函数和闭包是否能被平均水平的程序员掌握而讨论过（当时还没有 JavaScript）</li>
<li>我们终于确认了，静态类型系统辅以良好的保证确实物有所值（此时大部分程序员没有听说过 Haskell 和 ML，在 Java 引入泛型的几年之前）</li>
</ul>
<p>此类技术，眼下已经属于理所应当，而彼时却会引发争论。当然，这些变化不是在一夜之间发生的。部分原因是，硬件性能和软件的scale的变化，改变了编程语言的可能性与tradeoff。部分原因是，越来越多的人尝试不同技术，然后不愿再回去了。</p>
<p>本书的核心是语言的可扩展性，对 Racket 来说是其中的 Macro。那么，如果宏真地这么好，为什么不是每个人都已在使用？如同 GC，宏看起来很酷，但也引入了太多 overhead（不是程序执行上，而是程序理解上）。类似于一等函数，宏在代码中引入了另一维度。</p>
<p>PS：应该不类似于与 GC，因为GC实际上是大大减轻了程序员的心智负担。</p>
<h1 id="Make-a-language-in-one-hour-stacker"><a href="#Make-a-language-in-one-hour-stacker" class="headerlink" title="Make a language in one hour: stacker"></a>Make a language in one hour: stacker</h1><h2 id="Why-Make-Languages"><a href="#Why-Make-Languages" class="headerlink" title="Why Make Languages"></a>Why Make Languages</h2><h3 id="What-is-a-programming-language"><a href="#What-is-a-programming-language" class="headerlink" title="What is a programming language?"></a>What is a programming language?</h3><p>不管是编写一般的程序，还是特殊的 compiler 与 interpreter，它们都遵循一个统一的模式：</p>
<ul>
<li>take some input -&gt; put it into a processing device -&gt; get a result</li>
</ul>
<p>中间的部分 device 可大可小，可以说一个函数、程序，也可以是一种编程语言。以如此抽象的视角去看待，那么编程语言可以视为特殊的函数，一个函数可以视为一种 DSL（在一个极小的领域内）。</p>
<h3 id="How-are-languages-implemented-in-Racket"><a href="#How-are-languages-implemented-in-Racket" class="headerlink" title="How are languages implemented in Racket?"></a>How are languages implemented in Racket?</h3><p>分为三步：</p>
<ul>
<li>设计语言的 notation 和 behavior</li>
<li>编写一个 Racket 程序来读入源代码，将其 notation 和 behavior 转换为相应的 Racket 程序</li>
<li>执行转换后的 Racket 程序</li>
</ul>
<p>第三步整个地由 Racket toolchain 完成，因此只需要关注前两部。</p>
<h3 id="The-Components-of-a-Language"><a href="#The-Components-of-a-Language" class="headerlink" title="The Components of a Language"></a>The Components of a Language</h3><ul>
<li>reader：将源代码从字符串转换为 Racket 的 S 表达式。</li>
<li>expander：确定这些表达式如何对应到可执行的 Racket 表达式（从而可进一步产生结果）</li>
</ul>
<p>reader 负责将程序转换为正确的形式；expander 负责给这些形式赋予意义。</p>
<p>奇妙的是，我们甚至可以先将 reader 设计为生成不存在的函数，之后再在 expander 中实现。</p>
<h2 id="The-Reader"><a href="#The-Reader" class="headerlink" title="The Reader"></a>The Reader</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; stacker.rkt</span><br><span class="line">#lang br/quicklang</span><br><span class="line"></span><br><span class="line">(define (read-syntax path port)</span><br><span class="line">  (define src-lines (port-&gt;lines port))</span><br><span class="line">  (datum-&gt;syntax #f &#x27;(module lucy br</span><br><span class="line">                      &quot;Hello World&quot;)))</span><br><span class="line"></span><br><span class="line">(provide read-syntax)</span><br></pre></td></tr></table></figure>

<p>每个 reader 都需要提供一个 <code>read-syntax</code> 函数，Racket 给 reader 传入两个参数：path 与 port。</p>
<p>每一个 <code>read-syntax</code> 都需要做一件事情：返回代码，该代码描述了一个称为 <code>syntax object</code> 的模块。Racket 将源代码替换为此模块。新模块将调用 expander，从而将模块完全扩展。此后，模块将被 Racket 解释器正常求值。</p>
<h3 id="reader-示例解释"><a href="#reader-示例解释" class="headerlink" title="reader 示例解释"></a>reader 示例解释</h3><p><code>read-syntax</code> 函数做两件事情，一是从 port 中读取源代码，二是将结果转为上述的模块（模块也是表达式）。模块的模式是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; 此表达式包含需要 expand 和 evaluate 的表达式</span><br><span class="line">(module module-name which-expander</span><br><span class="line">    42</span><br><span class="line">    &quot;foobar&quot;</span><br><span class="line">    (+ 1 1)</span><br><span class="line">    ...)</span><br></pre></td></tr></table></figure>

<p>示例中，先将代码表示为 data（quote），在用 <code>datum-syntax</code> 将其转换为 <code>syntax object</code>。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>现在可以测试所编写的 reader 代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">; stacker-test.rkt</span><br><span class="line">#lang reader &quot;stacker.rkt&quot;</span><br><span class="line"></span><br><span class="line">foo</span><br><span class="line">bar</span><br></pre></td></tr></table></figure>

<p>在执行时，这段代码将会被完全替换为 reader 返回的结果，因此打印出：<code>Hello World</code>。</p>
<p>一般地，每一个以 <code>#lang</code> 开头的文件都会被如此转换为另一个模块。</p>
<h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p>上面的Hello World什么也不错，实际上是完全忽略了输入，下面来让它做点事情。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#lang br/quicklang</span><br><span class="line"></span><br><span class="line">(define (read-syntax path port)</span><br><span class="line">  (define src-lines (port-&gt;lines port))</span><br><span class="line">  (define src-datums (format-datums &#x27;(handle ~a) src-lines))</span><br><span class="line">  (define module-datum `(module stacker-mod &quot;stacker.rkt&quot;</span><br><span class="line">                          ,@src-datums))</span><br><span class="line">  (datum-&gt;syntax #f module-datum))</span><br><span class="line"></span><br><span class="line">(provide read-syntax)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>format-datums</code> 接受字符串列表，对每个元素进行格式化。</li>
<li>先是表示 quasiquote ，<code>,@</code> 则读取列表</li>
</ul>
<p>用如下代码测试：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#lang reader &quot;stacker.rkt&quot;</span><br><span class="line">4</span><br><span class="line">8</span><br><span class="line">+</span><br><span class="line">3</span><br><span class="line">*</span><br></pre></td></tr></table></figure>

<p>转换的模块内容是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;(handle)</span><br><span class="line">&#x27;(handle 4)</span><br><span class="line">&#x27;(handle 8)</span><br><span class="line">&#x27;(handle +)</span><br><span class="line">&#x27;(handle 3)</span><br><span class="line">&#x27;(handle *)</span><br></pre></td></tr></table></figure>


]]></content>
      <categories>
        <category>FP, Racket</category>
      </categories>
      <tags>
        <tag>FP, Racket</tag>
      </tags>
  </entry>
  <entry>
    <title>concurrency-in-go</title>
    <url>/2021/03/22/concurrency-in-go/</url>
    <content><![CDATA[<h1 id="Concurrency-in-Go"><a href="#Concurrency-in-Go" class="headerlink" title="Concurrency in Go"></a>Concurrency in Go</h1><p>参考：《Go in Action》第六章</p>
<ul>
<li>使用 <code>goroutine</code> 运行代码</li>
<li>检测和修复 race condition</li>
<li>在 channel 之间共享数据</li>
</ul>
<p>Go 运行时 scheduler 能够有效地管理所有 goroutines。scheduler 在 OS 之上，将 OS 的线程绑定到 logical 处理器，后者执行 goroutine。</p>
<p>并发同步源于 CSP 范式，CSP 是一个消息传输模型。它通过在 goroutine 之间的数据通信来同步数据，而非 lock。在 Go 中，消息传输的核心数据类型是 <code>channel</code>。</p>
<h2 id="并发与并行"><a href="#并发与并行" class="headerlink" title="并发与并行"></a>并发与并行</h2><p>OS 调度线程，使之执行于物理处理器上，Go 运行时调度 goroutines，使之执行于逻辑处理器上。每个逻辑处理器则独立地绑定在单个 OS 线程上。</p>
<h2 id="Goroutines"><a href="#Goroutines" class="headerlink" title="Goroutines"></a>Goroutines</h2><h2 id="Race-Condition"><a href="#Race-Condition" class="headerlink" title="Race Condition"></a>Race Condition</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go build -race</span><br></pre></td></tr></table></figure>

<h2 id="Locking-shared-resources"><a href="#Locking-shared-resources" class="headerlink" title="Locking shared resources"></a>Locking shared resources</h2>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>effective-go</title>
    <url>/2021/03/14/effective-go/</url>
    <content><![CDATA[<h1 id="Effective-Go"><a href="#Effective-Go" class="headerlink" title="Effective Go"></a>Effective Go</h1><p><a href="https://golang.org/doc/effective_go">Effective Go</a></p>
<h1 id="Errors"><a href="#Errors" class="headerlink" title="Errors"></a>Errors</h1><p><code>error</code> 的信息可以通过前缀来增加信息，如 <code>image: unknown format</code>。</p>
<h2 id="Panic"><a href="#Panic" class="headerlink" title="Panic"></a>Panic</h2><p>向调用者报告错误通常的方法是返回一个 <code>error</code>，但有时候一个错误发生，意味着严重的或很难预料到的错误（比如本应是无限循环，却退出了），此时退出程序也许更为合适，这是 <code>panic</code> 的用场。</p>
<p>通常来说，应避免使用 <code>panic</code>，但凡程序还有救的话。一些特殊情况是，程序启动时无法连接到主数据库，那么继续执行下去也无意义，此时可以 <code>panic</code>。</p>
<h2 id="Recover"><a href="#Recover" class="headerlink" title="Recover"></a>Recover</h2><p>在 <code>panic</code> 调用后（包括自定义 <code>panic</code>，以及 slice 索引越界等运行时错误），当前函数执行立即结束，开始释放 goroutines，执行 defferred 函数。如果释放过程到了程序的 top level 代码，程序就终止了。</p>
<p>但还是可以通过 <code>recover</code> 来重新获得 goroutine 的掌控，继续执行程序。</p>
<p><code>recover</code> 停止上述释放过程，返回 <code>panic</code> 的参数，<code>recover</code> 只能用于 deferred 函数。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>golang-organization</title>
    <url>/2021/03/14/golang-organization/</url>
    <content><![CDATA[<h1 id="Go-程序的代码组织"><a href="#Go-程序的代码组织" class="headerlink" title="Go 程序的代码组织"></a>Go 程序的代码组织</h1><p>参考：<br><a href="https://golang.org/doc/code">How to Write Go Code</a><br><a href="https://stackoverflow.com/questions/55442878/organize-local-code-in-packages-using-go-modules/57314494#57314494">Organize Local Code</a><br><a href="https://github.com/golang-standards/project-layout">Common Project Layout</a><br><a href="https://golang.org/doc/effective_go">Effective Go</a></p>
<h1 id="代码组织（Code-organization）"><a href="#代码组织（Code-organization）" class="headerlink" title="代码组织（Code organization）"></a>代码组织（Code organization）</h1><p>Go 程序以 <code>package</code> 组织。<code>package</code> 是一组在同一目录下的源代码文件集合。</p>
<p>一个代码库包含一个或多个 <code>module</code>。<code>module</code> 是一组相关的 Go <code>package</code>。Go 代码通常仅包含一个 <code>module</code>，名为 <code>go.mod</code> 的文件声明了 module 路径。</p>
<p><code>go.mod</code> 在代码库根目录，其定义的 module 包含了该目录下所有的 package。</p>
<p>module 的路径可作为 import 的前缀，同时也说明了 <code>go</code> 命令如何定位并下载之。引用路径是字符串值，package 的引用路径是 module 的子目录，比如：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">github.com/google/go-cmp/cmp</span><br></pre></td></tr></table></figure>

<p>但标准库中的 package 不需要 module 路径前缀。</p>
<h2 id="init"><a href="#init" class="headerlink" title="init"></a>init</h2><p>每个源文件可以包含自己的 <code>init</code> 函数，以进行必要之设置。<code>init</code> 在所属 package 内的所有变量初始化之后（这又在所有引用的 package eval 之后）执行。</p>
<p><code>init</code> 可用于在程序真正执行之前验证和修复程序状态，也可进行配置、初始化变量等等。</p>
<p>所有的 <code>init</code> 函数会被编译器发现，并在 <code>main</code> 函数之前调用之。</p>
<h2 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h2><p>对于简单的程序，repository 下只有一个 <code>module</code>，通过 <code>go.mod</code> 选择一个名称，如果想少打点字，使用 local name，而非完整路径。</p>
<p>在项目内添加不同的目录，其中含有的代码的部分即是 package，这样让代码组织更清晰。package 下可以继续嵌套。</p>
<p>如果要引用本地其它 repository 的 package，使用 <code>replace</code>。如果要发布代码，使用完整路径。</p>
<h1 id="Don’t-Panic"><a href="#Don’t-Panic" class="headerlink" title="Don’t Panic"></a>Don’t Panic</h1>]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>golang-packages</title>
    <url>/2021/03/14/golang-packages/</url>
    <content><![CDATA[<h1 id="Go-语言中的-Modules-与-Packages"><a href="#Go-语言中的-Modules-与-Packages" class="headerlink" title="Go 语言中的 Modules 与 Packages"></a>Go 语言中的 Modules 与 Packages</h1><h1 id="创建一个简单-app"><a href="#创建一个简单-app" class="headerlink" title="创建一个简单 app"></a>创建一个简单 app</h1><p><a href="https://golang.org/doc/tutorial/getting-started">参考：golang-getting-started</a></p>
<h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">mkdir hello</span><br><span class="line">cd hello</span><br></pre></td></tr></table></figure>

<h2 id="依赖追踪（dependency-tracking）"><a href="#依赖追踪（dependency-tracking）" class="headerlink" title="依赖追踪（dependency tracking）"></a>依赖追踪（dependency tracking）</h2><p>如果代码需要引入其它模块（module），在 Go 中使用当前项目的 module 来管理。当前的 module 由 <code>go.mod</code> 文件定义。<code>go.mod</code> 包含在代码库中，与代码同在。</p>
<p>要在当前项目中其中依赖追踪，需运行 <code>go mod init</code> 命令。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> mod init andersc.com/hello</span><br><span class="line"></span><br><span class="line"><span class="comment">// 内容</span></span><br><span class="line">module andersc.com/hello</span><br><span class="line"><span class="keyword">go</span> <span class="number">1.15</span></span><br></pre></td></tr></table></figure>

<h2 id="编辑代码"><a href="#编辑代码" class="headerlink" title="编辑代码"></a>编辑代码</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;rsc.io/quote&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fmt.Println(quote.Go())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里定义了一个 <code>package</code>，加了若干 <code>import</code>，并包含了如何函数 <code>main()</code>。</p>
<p>使用如下命令来修改依赖项，它会检查依赖项的修改，并生成 <code>go.sum</code> 文件，同时下载必要之文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go mod tidy</span><br></pre></td></tr></table></figure>

<h2 id="运行-app"><a href="#运行-app" class="headerlink" title="运行 app"></a>运行 app</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">go</span> run .</span><br></pre></td></tr></table></figure>

<p>以上是最简单的 app，有第三方库的引用，但 app 自身结构及其简单。</p>
<h1 id="创建一个略复杂的-app"><a href="#创建一个略复杂的-app" class="headerlink" title="创建一个略复杂的 app"></a>创建一个略复杂的 app</h1><p>Go 程序的代码首先分组为 packages，packages 再分组为 modules。</p>
<p><a href="https://golang.org/doc/tutorial/create-module">参考：golang-create-module</a></p>
<h2 id="创建一个可复用的-module"><a href="#创建一个可复用的-module" class="headerlink" title="创建一个可复用的 module"></a>创建一个可复用的 module</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">mkdir</span> greetings</span><br><span class="line"><span class="built_in">cd</span> greetings</span><br><span class="line"></span><br><span class="line">go mod init andersc.com/greetings</span><br></pre></td></tr></table></figure>

<p>创建并编辑 <code>greetings.go</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> greetings</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Hello</span><span class="params">(name <span class="type">string</span>)</span></span> <span class="type">string</span> &#123;</span><br><span class="line">	<span class="comment">// Return a greeting that embeds the name in a msg.</span></span><br><span class="line">	msg := fmt.Sprintf(<span class="string">&quot;Hi, %v. Welcome!&quot;</span>, name)</span><br><span class="line">	<span class="keyword">return</span> msg</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样，一个简单的 module 和 package 就完成了，并且可被其它 module 引用。</p>
<h2 id="在另一-module-中调用"><a href="#在另一-module-中调用" class="headerlink" title="在另一 module 中调用"></a>在另一 module 中调用</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ..</span><br><span class="line"><span class="built_in">mkdir</span> hello</span><br><span class="line"><span class="built_in">cd</span> hello</span><br><span class="line">go mod init andersc.com/hello</span><br></pre></td></tr></table></figure>

<p>入口程序：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line">	<span class="string">&quot;andersc.com/greetings&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="comment">// Get a greeting msg and print it.</span></span><br><span class="line">	msg := greetings.Hello(<span class="string">&quot;Gladys&quot;</span>)</span><br><span class="line">	fmt.Println(msg)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>由于 <code>greetings</code> module 在本地，需要修改 <code>go.mod</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">go mod edit -replace=andersc.com/greetings=../greetings</span><br><span class="line"></span><br><span class="line">go mod tidy</span><br><span class="line"></span><br><span class="line">go run . <span class="comment"># Hi, Gladys. Welcome!</span></span><br></pre></td></tr></table></figure>

<p>至此，一个“完整的” app 搭建完毕。</p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>exploratory-data-analysis-nlp-tools</title>
    <url>/2020/07/30/exploratory-data-analysis-nlp-tools/</url>
    <content><![CDATA[<p><a href="https://neptune.ai/blog/exploratory-data-analysis-natural-language-processing-tools">原文链接</a></p>
<p>Exploratory Data Analysis（探索性数据分析，EDA）是分析数据集以获取其主要特征的一种方法，通常会结合使用可视化方法。它主要是来查看，在借助于正式的模型与假设检验之外，数据还能告诉我们什么。在历史上，John Tukey是推广EDA的关键人物（1977年，出版同名书籍）。</p>
<p>本文通过实例讨论在NLP中的EDA。</p>
<h1 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install \</span><br><span class="line">   pandas matplotlib numpy \</span><br><span class="line">   nltk seaborn sklearn gensim pyldavis \</span><br><span class="line">   wordcloud textblob spacy textstat</span><br></pre></td></tr></table></figure>

<h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p><a href="https://www.kaggle.com/therohk/million-headlines">ABC News Headlines</a></p>
<h1 id="文本统计"><a href="#文本统计" class="headerlink" title="文本统计"></a>文本统计</h1><p>文本的可视化统计数据很简单，但能给出有效的信息。</p>
<ul>
<li>词频</li>
<li>句长</li>
<li>平均词长</li>
<li>…</li>
</ul>
<p>以此了解文本数据的基本特征。对continuous data，使用histogram，对categorical data，使用bar chart。</p>
<p>参考：<br><a href="https://en.wikipedia.org/wiki/Exploratory_data_analysis">Exploratory_data_analysis</a></p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP, Exploratory Data Analysis</tag>
      </tags>
  </entry>
  <entry>
    <title>《幸福课》笔记</title>
    <url>/2017/09/24/happiness/</url>
    <content><![CDATA[<p><a href="https://book.douban.com/subject/27050457/">原书信息</a></p>
<blockquote>
<p>陈海贤（动机在杭州），浙江大学心理学博士，中国临床心理学会注册心理师。曾在浙江大学心理中心任职，期间开设《积极心理学》的通识课，广受欢迎，被誉为浙江大学版的“幸福课”。</p>
</blockquote>
<blockquote>
<p>你大概也正处于某种“匮乏”当中，也因此，你的内心会有种种不安。这些不安一方面推动你去想象未来、远方、更好的自己，让你急着想要成长和改变；另一方面，也容易让你对自己、对世界采取一种防御的姿态，让你在自我怀疑中裹足不前。所以，你经常觉得自己敏感内向；你有关于未来生活的远大设想，却总会责怪自己没有足够的意志力去执行它；你一边焦虑自己变平庸，一边害怕竞争的激烈；你会为如何与他人相处头疼，会纠结于他人的负面评价；有时候你会害怕孤独，有时候又宁可回归孤独；偶尔，你还会感到空虚沮丧，并经常怀疑人生的意义……</p>
</blockquote>
<blockquote>
<p>如果是这样，那这本书就是为你写的。</p>
</blockquote>
<p>如果你也感到焦虑，因焦虑而焦虑；总感觉时间不够用，但内心却深知，自己并没有利用好时间；不允许自己闲下来；</p>
<h1 id="自序"><a href="#自序" class="headerlink" title="自序"></a>自序</h1><p><del>&gt; 追求幸福如登山，登顶只是瞬间的事，而攀爬的过程却艰辛而漫长。</del></p>
<p><del>你也许爬过一座山，却未必爬过他人在爬的山，或者未走过他在走的那条路，仅能给出一点建议而已。</del></p>
<blockquote>
<p>幸福之路，坑多路少。原因之一是，我们生活在一个<strong>不完美、充满缺陷的世界</strong>中。<strong>幸福需要我们承认这种不完美，扎根于这种不完美，并从中感受真实的生机。而太多的人生问题，是因为我们想要逃离这种不完美。</strong></p>
</blockquote>
<blockquote>
<p>如果你总致力于怎么把生活打扫得一尘不染，你就不会知道在泥浆里跳舞的快乐。</p>
</blockquote>
<p>如果我们能接受世界本来的不完美，许多问题就不是问题了。（当我们憧憬未来、努力上进，似乎都在暗示着：现在的自己不够好。）</p>
<p>现实有各种限制，先天的、后天的，自我的、他人的。想象的幸福是什么样的呢？或许也能想到某些限制，但总是不够多。要走出想象，努力去生活，进入生活本身。这样才能更了解自己的能力和限制，唯有如此，才能有更合理的想象。真正了解生活的限制，才能有自由，就像一只鱼儿不会因为不能飞翔而感到悲伤。</p>
<blockquote>
<p>你大概也正处于某种“匮乏”当中，也因此，你的内心会有种种不安。这些不安一方面推动你去想象未来、远方、更好的自己，让你急着想要成长和改变；另一方面，也容易让你对自己、对世界采取一种防御的姿态，让你在自我怀疑中裹足不前。所以，你经常觉得自己敏感内向；你有关于未来生活的远大设想，却总会责怪自己没有足够的意志力去执行它；你一边焦虑自己变平庸，一边害怕竞争的激烈；你会为如何与他人相处头疼，会纠结于他人的负面评价；有时候你会害怕孤独，有时候又宁可回归孤独；偶尔，你还会感到空虚沮丧，并经常怀疑人生的意义……</p>
</blockquote>
<p>匮乏，将限制我们的目光，使其短视和失焦。</p>
<p>如意与不如意者，要么减小后者，要么扩大后者。</p>
<blockquote>
<p>但只有在行驶中，你才知道该怎么调整、转向、把握平衡。</p>
</blockquote>
<blockquote>
<p>如果说本书中让我们焦虑的“远方”是<strong>完美又脆弱的虚假自尊</strong>，<strong>抽象又缥缈的高远目标</strong>，对成为一个很厉害的人的期待，快速免于匮乏的想象，高效专注、心无旁骛的状态，左右逢源、八面玲珑的人格，与父母和朋友的完美关系……那“脚下”则是把失败当作反馈的成长思维、认真对待琐事的无差别心、不功利的兴趣和努力、匮乏和不安中的淡定从容、内疚与自责中的自我和解、对性格优势和缺陷的了解和接纳、在不完美关系中的自我滋养……</p>
</blockquote>
<blockquote>
<p>这些“远方”都很好，唯一的问题是，<strong>它既不像这个真实的世界，也不像我们真正的自己</strong>。它是我们应对匮乏和不安的想象，并不是真实的幸福。而“脚下”呢，说不上好，也说不上坏，但我们踩下的每一步都很踏实。</p>
</blockquote>
<h1 id="假想的自我与真实的成长"><a href="#假想的自我与真实的成长" class="headerlink" title="假想的自我与真实的成长"></a>假想的自我与真实的成长</h1><blockquote>
<p>我非理想中的我，我非将来的我，我亦非过去的我。</p>
</blockquote>
<h2 id="名校学生病"><a href="#名校学生病" class="headerlink" title="名校学生病"></a>名校学生病</h2><blockquote>
<p>考败来浙；严格的父母；严苛的高中，唯成绩论；身边总有更好的人（成绩好，专业有趣，有前途）；</p>
</blockquote>
<p>PS：成绩天然带有对比。</p>
<blockquote>
<p>但如果真让他无所事事一会儿，哪怕几分钟，他就会被“变平庸”的恐惧和焦虑折磨。</p>
</blockquote>
<p>此时的“努力”已经走样。少有成功的喜悦，却多失败的恐惧。</p>
<h2 id="假想中的完美自我"><a href="#假想中的完美自我" class="headerlink" title="假想中的完美自我"></a>假想中的完美自我</h2><blockquote>
<p>感到安全时，人天生就有探索世界、接受挑战的冲动，这是我们<strong>做事的内在动机</strong>。但是，这种内在动机很容易被破坏。</p>
</blockquote>
<p>比如评价性语言，褒贬、施压、攀比。无论褒贬，评价容易带来不安，陷入防御心态和过度的自我关注。</p>
<blockquote>
<p>当儿童担心自己不被父母或他人认可时，他们会产生强烈的焦虑和不安。于是，他们会在幻想中创造出一个他们认为的、父母喜爱的“自我”，来缓解这种焦虑。这个假想的自我通常都是完美的——聪明、美丽、优秀，毫无瑕疵。当他们用幻想的自我来对照现实的自我时，他们会觉得自己像个冒牌货。他们努力维持幻想中的形象，害怕别人看到幻想背后真实的自己。</p>
</blockquote>
<p>即使别人真诚地以为他们已经做得很好。</p>
<blockquote>
<p>在心理结构中，自我像是一个调节器或维修包。当一切运转良好时，我们会把生命能量投射到与外部世界的互动中。世界向我们提问，我们努力解答。自我也在与世界的互动中逐渐变得丰富起来。但是如果我们感到不安，就会把注意力投射到自我本身，就像打开维修包里的探测器，去探索和发现自己的问题。</p>
</blockquote>
<blockquote>
<p>当我们把注意力放到自我修正时，自我的发展却因为缺乏与真实世界的互动而逐渐停滞了。越停滞，我们越想修正自我，越容易变得以自我为中心，这形成了恶性循环。</p>
</blockquote>
<blockquote>
<p>不安全感也可能是一种动力，但它和自发的、通过挑战获得成就感的动力并不相同。很多心理学家以不同的术语区分了这两种动力：追求成功的动机和避免失败的动机（阿特金森），指向成长的动机和满足匮乏的动机（马斯洛）……而斯坦福大学心理学教授德韦克认为，这两种动力背后，是<strong>两种不同的心智模式：成长型思维和僵固型思维</strong>。</p>
</blockquote>
<h2 id="成长型思维和僵固型思维"><a href="#成长型思维和僵固型思维" class="headerlink" title="成长型思维和僵固型思维"></a>成长型思维和僵固型思维</h2><p>两种心智模式，对于<strong>拖延症</strong>有着重要的影响。它们的区别在于注重成长的可能性，还是当前的评价，前者开放，后者封闭。</p>
<p>它们决定了一个人如何看待挑战、失败、努力（努力证明自己的无能？）、批评。如何看待他人的成功？</p>
<blockquote>
<p>仔细思索，你会发现成长型思维的底层是安全感。这种安全感不是因为“我是一个什么样的人”，而是因为“我有很多可能性”。<strong>拥有这种安全感的人，不需要保护某种特定的自我观念，也不需要过度的自我关注</strong>。他们突破了自我中心的束缚，转而从成长和发展的角度看问题。在这种视角下，“自我”并不是一种固定的状态，而是一个不断创造和形成自身的过程。</p>
</blockquote>
<p>做到原以为做不到的事情；回想三年前的自己，是否有很大进步？</p>
<p>不太关注结果，专心做事，结果反而更好；</p>
<blockquote>
<p>成长究竟是怎么发生的？从微观层面看，人的大脑由各种各样的神经元组成，这些神经元的连接方式构成了我们储存和加工信息的能力。未知的挑战一方面让我们焦虑，另一方面也在不断训练我们的大脑。挑战越多，大脑就会变得越复杂，相应地，人的能力也在不断增长。</p>
</blockquote>
<blockquote>
<p>从宏观层面看，人的能力是通过与环境的互动成长起来的。我们与环境的互动越多，获得的反馈机会就越多，我们的能力成长就越快。</p>
</blockquote>
<blockquote>
<p>这种成长和进步的路径需要我们重新思考失败和错误的价值。曾有一个来访者问我：“总是为说错话、做错事懊恼不已，担心自己还会犯错误，影响工作和生活，该怎么办？”</p>
</blockquote>
<blockquote>
<p>对他来说，<strong>错误意味着失败和对自己的否定</strong>。他很少<strong>从反馈的角度理解错误</strong>。</p>
</blockquote>
<p>从而最直接的表现就是畏手畏脚。</p>
<h2 id="成长中的关系"><a href="#成长中的关系" class="headerlink" title="成长中的关系"></a>成长中的关系</h2><blockquote>
<p>布尼尔祈祷文中几句经典的祈祷词，是这样的：</p>
</blockquote>
<blockquote>
<p>上帝啊，请赐予我胸怀，让我接受无法改变的事；请赐予我勇气，让我改变能够改变的事；请赐予我智慧，让我能够分辨这两者。”</p>
</blockquote>
<blockquote>
<p>多么言简意赅、简单实用又发人深省！简直道尽了所有鸡汤的精髓。</p>
</blockquote>
<p>常见者：一眼就觉得不合适，分手。但实际上关系也可以成长。</p>
<p>若你相信能在一期，可能就在一起了，若不相信那也就不可能在一起了。相信才会去为之做些什么。</p>
<blockquote>
<p>你相信你们俩的关系是一成不变的还是不断成长的？以及，你对自己的信念有多坚定？</p>
</blockquote>
<blockquote>
<p>“相信”这事，说来缥缈，却力量巨大。你相信什么，往往决定了你怎么看待你们之间的关系，以及采取什么样的行动来处理你们的关系。而看法和行动，又会进一步影响你们的关系。</p>
</blockquote>
<p>一见钟情&#x2F;性格不合&#x2F;三观不一致&#x2F;没感觉 vs. 开放的好奇心</p>
<blockquote>
<p>秉持成长型思维的人，更容易相信关系是不断成长的，也因此更愿意投入精力来经营和改善这段关系。</p>
</blockquote>
<p>相处中亦有正反馈。</p>
<h2 id="像一棵树一样成长"><a href="#像一棵树一样成长" class="headerlink" title="像一棵树一样成长"></a>像一棵树一样成长</h2><blockquote>
<p>曾有学生问我这样的问题：“假如兔子都在拼命奔跑，作为乌龟的你，前进的动力在哪里？”</p>
</blockquote>
<blockquote>
<p>根据心理学家海德特的说法，人格的核心，其实是一个故事。</p>
</blockquote>
<blockquote>
<p>这个故事凝缩了我们对整个人生的理解，成了我们独特的人生线索。这个故事有一个目标，通常就是成功或幸福；有很多围绕目标展开的情节，就是你的每段人生经历。而我们的<strong>意义感，也通常源于对这个人生故事的理解</strong>。可以说，我们的人生就在完成这样一个独特的故事。只是，<strong>故事开始的时候，我们也不知道这个故事是怎样的</strong>。我们一边当观众，一边当编剧；一边经历，一边修改故事大纲。</p>
</blockquote>
<blockquote>
<p>当我们接受一个故事作为我们人生范本的时候，我们也接受了这个故事背后所隐含的假设。这些假设像是故事的潜台词，它被视为理所当然，很少有人认出它，去质疑它。</p>
</blockquote>
<blockquote>
<p>当我们用龟兔赛跑来比喻我们的人生时，它同样隐含了我们对人生的一些信念：</p>
</blockquote>
<ul>
<li>人生是一场赛跑：必须要和别人比赛吗？</li>
<li>终点处只有一个胜利者：一定要分出胜负吗？只能有一个胜者吗？</li>
<li>跑得快还是慢，是一种固定的能力。如果你跑得慢，你就一直跑得慢。</li>
<li>奔跑很辛苦。但既然你已经跑得很慢了，就只有拼命奔跑，才能获得成功。</li>
</ul>
<blockquote>
<p>这些隐含的信念所体现的，正是僵固型思维的特征：用一个假设的、“必然会存在”的、比我们强的人作为比较标准，来<strong>消减我们成长和进步的意义</strong>。</p>
</blockquote>
<p>它们来自：焦虑的父母、功利的学校、浮躁而现实的社会文化共同的产物？</p>
<p>同时，也会有人<strong>假设自我是一个已经存在并相对固定的东西</strong>。它通常由我们的童年经历决定，而我们以后的经历，只是对已经形成的自我的修修补补。</p>
<p>那么，还可以选择什么样的故事呢？一条河流或一颗树。</p>
<blockquote>
<p>源头固然很重要，但它最终的形态如何，取决于它在流向大海的途中会遇到哪些山坡、丘陵、沙漠……它怎么面对障碍，以及选择在什么地方拐弯。真实的自己并不是一开始就存在，它是我们在跟环境的互动中，在应对困难、做出选择的过程中，逐渐塑造出来的。</p>
</blockquote>
<blockquote>
<p>假如自我是一条流动的、尚未成形的河流，那么“发现自我”，或者“证明自我”也就没有意义。因为就算我们能通过某件事证明自己，我们所能证明的，也仅仅是某个阶段、某种状态下的自己。就像这条河流会有一段湍急、有一段平缓，你却没法通过单一的某段河流来评判它。</p>
</blockquote>
<p>源头能决定你是黄河还是长江，我们却不能简单地说长江是什么河，它有湍急的三峡，也有开阔平稳的河段，还接纳了不知多少条支流。</p>
<blockquote>
<p>这是我见过的关于成长型自我最好的隐喻。</p>
</blockquote>
<blockquote>
<p>如果从树的角度，重新回答开头那个同学的问题，我大概会说，人和人之间的关系，并不只有比较和竞争。我们做事的动力，也不只是想比别人优越。我们每个人都努力生长，既相互竞争，又彼此扶持，形成了一个完整的生态系统。我们是亲人、朋友、同学、同事、公民……也许我们有高有低，但我们在共同生长的土地下面根须相连。如果你问一棵树为什么还要生长，既然总有其他树比它长得高。它大概会回答：“傻孩子，因为我是一棵树啊。”</p>
</blockquote>
<p>如何面对现实中的评价体系？不要简单地认为，一件事情非得如此如此不可，很多时候还是有选择的。一定要赚很多钱吗？一定要买大房子吗？孩子一定要去最好的学区吗？</p>
<h1 id="更大的世界与眼前的生活"><a href="#更大的世界与眼前的生活" class="headerlink" title="更大的世界与眼前的生活"></a>更大的世界与眼前的生活</h1><p>较之于当下在我们之内的，我们身后的过去和眼前的未来，都是琐事。<br>	– 奥利弗·温德尔·霍姆斯<br>	<br>很多人都生活在平静的绝望中。<br>	– 梭罗</p>
<p>从眼前的琐事到更远的地方。</p>
<h2 id="世界那么大，我想去看看，然后呢？"><a href="#世界那么大，我想去看看，然后呢？" class="headerlink" title="世界那么大，我想去看看，然后呢？"></a>世界那么大，我想去看看，然后呢？</h2><blockquote>
<p>英雄就是要反抗我们想反抗又不敢反抗的势力，做我们想做又不敢做的事情。我们从英雄故事中吸收力量，寻找榜样。对于每一个深陷琐碎的日常、<strong>只能在夜深人静的时候透过窗户遥想外面世界的人</strong>，这封文艺的辞职信足够提供想象的素材，成为我们编织英雄梦想的线索。</p>
</blockquote>
<blockquote>
<p>人能忍受辛苦，但很难忍受停滞的感觉。他们在<strong>努力探索生活的可能性</strong>。</p>
</blockquote>
<p>你觉得外面有更大的世界，但你的世界可能是另一些人更大的世界。即对绝大多数人来说，总有“更大的世界”，更大的世界在<strong>远方</strong>。</p>
<blockquote>
<p>看来对大部分人来说，“更大的世界”都不在此时此地，而在“远方”。它意味着变化、希望、丰富的体验和更多的可能性。</p>
</blockquote>
<p>变化、希望、可能性都在未来。我们可以去想象，但一定要清醒地认识到，只是想象，永不能到达远方，而且远方亦有其远方。</p>
<p>世间的一切，唯有内心感受到的才是真实的。若只是走马观花，你自己都不愿相信“去过”那个地方。故更大的空间不是最重要的，要内心有更丰富的体验。</p>
<p>行万里路，为的是回归内心。而回归内心，则不惟行万里路一途。</p>
<blockquote>
<p>“远方”是一个充满诱惑的神奇的词。卡尔维诺说，对远方的思念、空虚感、期待，可以延绵不绝，比生命更长久。这种思念究其本质，就是<strong>对生命可能性的向往</strong>。当人们陷于生活的琐碎无聊、疲惫厌倦时，“远方”就会在幻想中被制造出来。它所代表的可能性，既能容纳过去的失败、挫折和悔恨，又能容纳未来的希望。</p>
</blockquote>
<p>当前所经历的生活，不是可能性，而是“确然性”。因对其不满意，故而期望其它的可能性。</p>
<blockquote>
<p>“远方”的意义到底在哪里？人们心里有疑惑，去远方寻找答案。答案并不在“远方”，而在寻找的过程本身。</p>
</blockquote>
<p>以前想过，远方的意义在于，让自己抽身出来，面对自我，因为平日里面对的多是身外之事。如果能够抽身，那么都可以面对自己。此处与彼处，都可以去寻找，都可以在寻找的过程中找到某些答案。</p>
<blockquote>
<p>一件事是不是琐事，并不是由这件事的性质决定的，而是由你对待它的态度决定的。</p>
</blockquote>
<p>身在此处或彼处，都有“琐事”，不愿做琐事，即意味着只要结果，不要过程。这不是一种现实的态度，要记住，在去往彼处的途中，各种琐事、趣事都是其必然包含的，要想到目的地，也要想到如何到达。一个目的地如此，整个生活也是。</p>
<blockquote>
<p>他们并不对无聊琐事失望，相反，心自由了，他们对什么样的生活都充满热情。他们哪里也不想去，却反而自由了。而那些想要逃离的人，却到处看到囚牢。</p>
</blockquote>
<blockquote>
<p>我们总是习惯了用“好”“坏”“重要”“不重要”来<strong>评价</strong>一件事。这件事能帮助我们升职加薪吗？能够帮助我们快速成长吗？评价并不总会带来“意义感”——有时候，意义感是我们沉浸在一件事中体会到的。<strong>但评价却经常带来“无意义感”</strong>。</p>
</blockquote>
<blockquote>
<p>而我们对生命的态度，除了沉下心来体验，还能做什么呢？</p>
</blockquote>
<blockquote>
<p>很多人总是容易把做“正事”的时间看作“我的时间”，而把做琐事的时间看作“占用了我的时间”，好像那一段时间不再属于他了。而实际上，陪伴孩子的时间和修行的时间一样，都是“我的时间”，我们有责任以认真的态度度过它。</p>
</blockquote>
<p>如果一件事情“占用了你的时间”，你可不可以不去做呢？如果必须要去做，那么它不就是你时间的一部分吗？自己的时间，为什么不认真对待呢？</p>
<h2 id="过程本身也是目的"><a href="#过程本身也是目的" class="headerlink" title="过程本身也是目的"></a>过程本身也是目的</h2><blockquote>
<p>《禅与摩托车维修艺术》中的一句话：“今天，佛陀或是耶稣坐在电脑和变速器的齿轮旁边修行，会像坐在山顶和莲花座上一样自在。如果情形不是如此，那无异于亵渎了佛陀——也就亵渎了你自己。”</p>
</blockquote>
<p>多隆成为大神的过程中，驱动力是什么？</p>
<blockquote>
<p>不是高远的目标。如果他念念不忘远大目标，未必能做到这么专注。人心里有了执念，就会有担心。一担心，就很难做到专注了。</p>
</blockquote>
<p>当然可以有高远的目标，但在每个当下，却不能时时想着它。高远的目标指引了方向，当下的事情则让自己迈出一步步。不积跬步，到不了；走偏了，也到不了。</p>
<p>前行，省视，反馈，继续前行，如此确保，不忘方向，亦不走偏。</p>
<blockquote>
<p>要有远大理想，这几乎成了我们对世界的基本信条。越是对现实不满，越是害怕泯于众人，我们越会紧紧抓住高远的目标不放。但如果高远目标没有现实的路径，就很容易把生活变得抽象而无趣。</p>
</blockquote>
<p>因其高远，路径难现，且他人之路径亦他人耳，未必适合自己。想太多高远的事物，会让每一个当下的时刻“抽象而无趣”，这是真的。</p>
<p>远处的目标固然是想要的，但一个事实是，眼下的每一刻却是我们能经历和体验的所有。只要结果，不要过程？没有过程，何来结果？</p>
<p>再者，结果不可控，过程则可以。</p>
<blockquote>
<p>我们总是东张西望，觉得只有有人给了我们这样的保证，才舍得全情投入。古人说，尽人事，安天命。说的是，做我们能做的事，把命运的部分交给命运。这里面有一种信任。这种信任并不是对“公平买卖”的信任，而是死心塌地地交付。不是“只要我努力投入，上天就会给我回报”，而是“即使上天不给我回报，我也会努力投入”。</p>
</blockquote>
<p>问题在于，时间只有一次，你投不投入，你做这件事或那件事，它都一样流逝。对于一件事情“不感兴趣”而不投入，不投入则更不感兴趣，这似乎是必然的结果。想一想，有哪些事情是当你沉下心来认真去做，发现它比想象地更有趣？</p>
<p>对于要做的事情，投入它；不要担心回报如何，若无投入，结果只能是——它不值得做，但事实真地如此吗？</p>
<blockquote>
<p>心理学家米哈里提出一个叫作“<strong>福流（flow）</strong>”的概念。他说，福流是人们在全情投入时所产生的一种特殊的忘我体验。在福流的状态下，人们的注意力高度集中、心中没有任何杂念，觉得一切活力畅通无阻，自己跟眼前的事密不可分、浑然一体，甚至忘记了时间。（爬山除了爬山之外，没有别的理由，它完全是一种自我沟通。）福流所描述的，大概是多隆经常会有的、沉浸于某件事的状态。米哈里把这种状态看作人类的最优体验，是幸福感真正的来源。悖论是，福流需要我们“忘我”，放下对事物以外的“目标”的执念。也正是因为“忘我”了，我们反而能够成就更深刻、更复杂的自己。</p>
</blockquote>
<p>如果你曾沉浸于解数学题、登山、下棋、篮球比赛，就能感受到，”忘我“，放下事物以外的执念与杂念，这是我们可能有的最幸福的体验。解出题来、登上山顶，却只是一瞬间的事情。</p>
<blockquote>
<p>不要以成功为目标——你越是对它念念不忘，就越有可能错过它。</p>
</blockquote>
<p>目标不因在意而自然成功，需要投入，而且能否成功，并不确定，因此更无须过于关注，努力去做即可。要记住，<strong>成功是副产品</strong>。</p>
<blockquote>
<p>能够专注于当下的事情，这就是难得的福报。</p>
</blockquote>
<h2 id="我想去远方，把人生格盘重来"><a href="#我想去远方，把人生格盘重来" class="headerlink" title="我想去远方，把人生格盘重来"></a>我想去远方，把人生格盘重来</h2><blockquote>
<p>力求每时每刻都有事做，好避免深层次的思考</p>
</blockquote>
<blockquote>
<p>这些年，我始终没发现自己热爱什么，只知道自己讨厌什么。我太害怕失败了，于是我什么也没做。</p>
</blockquote>
<p>如果遇见一个我深爱的人，我一定全力去爱；如果有一件我热爱的事情，我一定全力以赴，你也这样想过吗？那这样的人和事为何一定会出现在你面前？</p>
<blockquote>
<p>它的功能和梦很像：<strong>满足我们纠正过去生活的愿望</strong>。伤心和挫折在心里郁结越久，你的“把生活格盘重来”的念头就会停留越久，你就会忍不住想把幻想拉进现实。</p>
</blockquote>
<blockquote>
<p>这段挫折给你留下的印记太深了，以至于你无法接受这样的事实：你有过一段不太成功的大学经历。这段经历事实上已经结束了，但你在心里一直延续着它。你想要一个光明的、深V翻转的结尾，强烈到宁可不开始新的生活，也不愿意为这段经历画上一个句号。</p>
</blockquote>
<p>你现在的生活，是否真地如你所想的那么糟糕？现在回想起来，刚来上海时，你算是一个”会写程序“的程序员吗？你现在自认为是一个中等的程序员，那么是否一路是自己学过来的？没错，想起名校CS的人，差距颇大，但从起点开始，很多事情确实不是那么容易控制的。如何学习？如何学习如何学习？如何面试、找工作？如何去学习不同领域的知识？如何与人交往？如何恋爱？如何寻找soulmate？这么多问题，你不是一路摸索着过来的吗？</p>
<p>尽管与某些人有明显差距，但是你必须也要考虑自己的经历。回到22岁，某些人已经编程超过10年了，你呢？再到18岁，你或许仍会因一次考试的不理想而耿耿于怀，但是已然发生的事情，悔恨有何益？回到17岁，你仰慕爱因斯坦、欧拉，你热爱数学，但如果没错的话，你想能在数学上达到前10000就很满足了。看到了吗？在你自认为最擅长数学时，也没有那么高的期望，现在却认为这目标低得惊人。是的，我想过学好数学，但彼时亦没有”成为伟大的数学家“这种念想。再往前推，初中在放羊，极想看书时无书可看；小学还曾经有过两个班在一个教室。</p>
<p>（插播一条：大学里，认识到自己也是很平庸的，放弃数学，开始学习编程。然后，在08年前后，自认为已经学得不错了，值得注意的是，这时做编程工作仅3年，对于CS几乎是没了解的，所谓”不错“完全是幻觉。）</p>
<p>这些，你可以说不能作为借口。但是，这些是事实，如果你承认天赋与家庭的重要性，那么碰巧这两者都是无法选择的。然后，”往者不可谏“。</p>
<p>当然，你回想起来，会觉得有”本可以过得更好“的可能性，但是天赋与家庭不可选择与更改的前提下，在这个起点上，你做的看起来也还不错了。我真心如此觉得，我确定你不是自己想象地那么一无是处。至于其他人做得多好，和你没有任何关系，只需做好自己的事情，做喜欢的事情。（如果所有数学家都跟欧拉、高斯、陶哲轩相比，干脆都自杀算了）</p>
<p>另外，是之前想到的：</p>
<ul>
<li>最佳先天与最佳环境的组合毕竟也有上限，如高斯，欧拉，拉格朗日，则不如此完美者更有上限。然则作为个体，只能尽力去做，与自己相比。但上限在哪里说不清。只思考上限无意义，不能了解，亦有害于生活。不如放下执念，投入到眼前之事，踏实前行。</li>
<li>一生之上限不可了解，一个月可以，且有反馈调整。努力、反馈、自省，如此反复前行，此乃正途。</li>
</ul>
<p>总之，不能太纠结于与他人的比较，各方面条件有差别，难有合适的参考系。与自己比较，看自己与过去三年、十年有多大进步。专注于自己的事情。明白每个人，包括自己，都是有上限的，但不必担心上限在哪里，如果此上限太低会怎样，过去的已过去，着眼于当下与未来，尽力去做就好。</p>
<p>你不知道具体上限在哪，你也不希望知道，不是吗？在余生里，对生活充满热情，去体验，去实现吧：）</p>
<p>我好像说服自己了，几欲激动落泪。</p>
<blockquote>
<p>因为我们每个人都带着自己长长的过去，这些长长的过去并不会因为到了“远方”就消失。它不在环境里，而在我们的头脑里，在我们的所思所想中，在我们对挑战的应对里，在我们和环境的互动中。我们需要了解自己的想法和行为模式，需要了解它们的历史、好处和可能的问题。</p>
</blockquote>
<h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><ul>
<li>生活中的哪些时间被你当作“不是我的时间”而敷衍度过了？</li>
<li>尝试以认真投入的态度做一件琐碎的事情，比如洗碗、扫地、做饭或者照看孩子，集中注意力，全情投入，把它当作一种修行般郑重。感受事情的每个细节，观察自己在做这件事时的情绪和感受。（练习”庄严“地做事）</li>
<li></li>
</ul>
<h1 id="理想与平庸"><a href="#理想与平庸" class="headerlink" title="理想与平庸"></a>理想与平庸</h1><p>想象的自我不是真实的，是否平庸不重要，重要的是你经历和体验到了什么。</p>
<h1 id="匮乏与不安"><a href="#匮乏与不安" class="headerlink" title="匮乏与不安"></a>匮乏与不安</h1><p>爱的匮乏是最大的匮乏，匮乏让人短视。</p>
<h1 id="接纳与改变"><a href="#接纳与改变" class="headerlink" title="接纳与改变"></a>接纳与改变</h1><p>细水长流。</p>
<h1 id="拖延与不拖延"><a href="#拖延与不拖延" class="headerlink" title="拖延与不拖延"></a>拖延与不拖延</h1><p>拖延与另一个我，或真实的我。</p>
<h1 id="敏感与内向"><a href="#敏感与内向" class="headerlink" title="敏感与内向"></a>敏感与内向</h1><h1 id="爱与孤独"><a href="#爱与孤独" class="headerlink" title="爱与孤独"></a>爱与孤独</h1><h1 id="空虚和意义感"><a href="#空虚和意义感" class="headerlink" title="空虚和意义感"></a>空虚和意义感</h1><p>存在即意义。</p>
<h1 id="结束与开始"><a href="#结束与开始" class="headerlink" title="结束与开始"></a>结束与开始</h1>]]></content>
      <tags>
        <tag>心理学</tag>
        <tag>幸福心理学</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello, Rust</title>
    <url>/2017/09/24/hello-rust/</url>
    <content><![CDATA[<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># On Mac</span><br><span class="line">$ curl https://sh.rustup.rs -sSf | sh</span><br></pre></td></tr></table></figure>

<p>运行此命令，按其中的提示安装即可。</p>
<h2 id="升级与卸载"><a href="#升级与卸载" class="headerlink" title="升级与卸载"></a>升级与卸载</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ rustup update</span><br><span class="line"></span><br><span class="line">$ rustup self uninstall</span><br></pre></td></tr></table></figure>

<h2 id="确认"><a href="#确认" class="headerlink" title="确认"></a>确认</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ rustc --version</span><br></pre></td></tr></table></figure>

<h2 id="本地文档"><a href="#本地文档" class="headerlink" title="本地文档"></a>本地文档</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用此命令在浏览器中打开本地文档，其中包含 The Rust Programming Language.</span><br><span class="line">$rustup doc</span><br></pre></td></tr></table></figure>

<h1 id="Hello-World"><a href="#Hello-World" class="headerlink" title="Hello, World!"></a>Hello, World!</h1><p>假设把代码放在某个目录下，cd到它，创建一个<code>main.rs</code>文件（rs是Rust文件的扩展名）：</p>
<figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，编译再运行之：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ rustc main.rs</span><br><span class="line">$ ./main</span><br></pre></td></tr></table></figure>

<h2 id="Rust程序的结构"><a href="#Rust程序的结构" class="headerlink" title="Rust程序的结构"></a>Rust程序的结构</h2><p><code>fn</code>定义一个函数，而<code>main</code>同时是特别的<strong>入口函数</strong>，与<code>C</code>和<code>C#</code>之类语言类似。Rust中的函数需要花括号包含其函数体。</p>
<p>第二行<code>println!(&quot;Hello, world!&quot;);</code>，输出一行文本到屏幕。这里看起来有点特别的是<code>println!</code>，带有<code>!</code>在Rust中意味着调用宏而非函数。行末的<code>;</code>表示一个表达式的结束，<strong>大多数</strong>Rust代码行以<code>;</code>结束。</p>
<h1 id="编译和执行的分离"><a href="#编译和执行的分离" class="headerlink" title="编译和执行的分离"></a>编译和执行的分离</h1><p>作为静态语言，Rust程序执行之前需要先行编译，这类似于<code>gcc</code>或<code>clang</code>。</p>
<p>对于简单的程序，可如上使用<code>rustc</code>，对于更为复杂的程序，你可能需要<code>Cargo</code>这个工具。</p>
<h1 id="Cargo"><a href="#Cargo" class="headerlink" title="Cargo"></a>Cargo</h1><p><code>Cargo</code>是Rust的构建系统（Build System）和包管理器（Package Manager）。它可以生成代码、下载依赖库，生成库代码。</p>
<p><code>Cargo</code>随Rust一起安装。</p>
<h2 id="以Cargo创建一个项目"><a href="#以Cargo创建一个项目" class="headerlink" title="以Cargo创建一个项目"></a>以Cargo创建一个项目</h2><p>使用命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cargo new hello_cargo --bin</span><br></pre></td></tr></table></figure>

<p>创建一个项目，<code>--bin</code>表示所创建者为可执行文件（binaries）。<code>Cargo</code>生成了两个文件：</p>
<ul>
<li>Cargo.toml（TOML格式的配置文件）</li>
<li>src&#x2F;main.rs（与上面手工创建的一样）</li>
</ul>
<p>Cargo.toml内容如下：</p>
<figure class="highlight toml"><table><tr><td class="code"><pre><span class="line"><span class="section">[package]</span></span><br><span class="line"><span class="attr">name</span> = <span class="string">&quot;hello_cargo&quot;</span></span><br><span class="line"><span class="attr">version</span> = <span class="string">&quot;0.1.0&quot;</span></span><br><span class="line"><span class="attr">authors</span> = [<span class="string">&quot;andersc &lt;andersc@mail.com&gt;&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="section">[dependencies]</span></span><br></pre></td></tr></table></figure>

<p><code>[dependencies]</code>列出了依赖的库，这些依赖在Rust中称为<code>crate</code>。Cargo创建了初始的目录结构，也是建议将代码放在src下，其它文件放在顶级目录。</p>
<h2 id="Building-and-Running-a-Cargo-Project"><a href="#Building-and-Running-a-Cargo-Project" class="headerlink" title="Building and Running a Cargo Project"></a>Building and Running a Cargo Project</h2><p>使用如下命令编译并运行程序：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cargo build</span><br><span class="line">$ ./target/debug/hello_cargo</span><br></pre></td></tr></table></figure>

<p>首次执行<code>cargo build</code>时，它会创建文件<code>Cargo.lock</code>，用于跟踪应用的依赖。一般不需要手工改动之。作为一种更快捷的方式，可以用<code>cargo run</code>来编译并运行程序。</p>
<h2 id="发布程序"><a href="#发布程序" class="headerlink" title="发布程序"></a>发布程序</h2><p>上面可见，编译的程序放在了<code>debug</code>下，如果要正式发布，则应使用<code>cargo build --release</code>选项，这会优化所生成的程序，代价是编译时间更长。</p>
<h1 id="开发环境"><a href="#开发环境" class="headerlink" title="开发环境"></a>开发环境</h1><ul>
<li>Sublime 3：<a href="https://github.com/rust-lang/sublime-rust">Sublime Rust</a></li>
<li><a href="https://intellij-rust.github.io/">IntelliJ Rust</a></li>
</ul>
<h1 id="Guessing-Game"><a href="#Guessing-Game" class="headerlink" title="Guessing Game"></a>Guessing Game</h1><p>通过一个真实的程序来演示几个Rust的常见概念，如<code>let</code>， <code>match</code>，方法，关联函数，使用外部库等。</p>
<p>猜数游戏是一个经典的编程初学者的问题。</p>
<h2 id="建立项目"><a href="#建立项目" class="headerlink" title="建立项目"></a>建立项目</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">cargo new guessing_game --bin</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> guessing_game</span></span><br></pre></td></tr></table></figure>

<h2 id="感受一下"><a href="#感受一下" class="headerlink" title="感受一下"></a>感受一下</h2><figure class="highlight rust"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> std::io;</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() &#123;</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Guess the number!&quot;</span>);</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;Please input your guess.&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">guess</span> = <span class="type">String</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    io::<span class="title function_ invoke__">stdin</span>().<span class="title function_ invoke__">read_line</span>(&amp;<span class="keyword">mut</span> guess)</span><br><span class="line">               .<span class="title function_ invoke__">expect</span>(<span class="string">&quot;Failed to read line&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">&quot;You guessed: &#123;&#125;&quot;</span>, guess);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这里面，<code>use</code>不用多说；let创建一个<strong>变量</strong>，不过在Rust中变量默认是不可修改的，如果希望修改，则需要使用<strong>mut</strong>；String:new()就是所谓关联函数（associated function），相当于其它语言中的<strong>静态方法</strong>。</p>
<p><code>stdin</code>是io的关联函数；read_line函数读取用户输入，将值赋给一个变量，<code>&amp;</code>表示参数为<strong>引用（reference）</strong>。</p>
]]></content>
      <tags>
        <tag>Programming</tag>
        <tag>Rust</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo的安装与配置</title>
    <url>/2017/06/27/hexo-so/</url>
    <content><![CDATA[<p>可能是npm的问题，也可能是Hexo的问题，总之：</p>
<ul>
<li>Error: Cannot find module ‘.&#x2F;build&#x2F;Release&#x2F;DTraceProviderBindings’频繁出现</li>
<li>将网站从一个目录移动到另一个目录也颇需要一番周折</li>
</ul>
<p>可参考的两篇文章：</p>
<ul>
<li><p><a href="http://www.ixirong.com/2016/08/30/solve-hexo-not-found-problem/">mac osx 下 hexo DTraceProviderBindings 错误</a></p>
</li>
<li><p><a href="https://absentm.github.io/2016/08/31/The-note-of-how-to-rebuild-hexo-next-blogs-when-switch-to-another-PC-or-reinstall-system/">The note of how to rebuild hexo+next blogs when switch to another PC or reinstall system</a></p>
</li>
</ul>
<p>PS：不熟悉Node.js，每次安装都莫名担心会失败。。。</p>
<p>PPS：测试git commit效果。</p>
<p>PPPS：测试Github Pages更新。</p>
]]></content>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>历史：要讲述一个怎样的故事？</title>
    <url>/2017/06/28/history-of-history/</url>
    <content><![CDATA[<h1 id="序言（葛剑雄）"><a href="#序言（葛剑雄）" class="headerlink" title="序言（葛剑雄）"></a>序言（葛剑雄）</h1><p>本书每一章都以一个具体的历史事件或人物开始，引出相应地理论、概念或方法。</p>
<p>尽管对不熟悉西方历史背景的中国读者来说，这些内容显得陌生。</p>
<p>“历史是一个过程、一种论辩，是由关于过去的真实故事所构成的。”</p>
<p>历史上的故事有很多，我们会挑哪些出来讲？以哪种方式来回想？讲述的效果如何？凡此种种，都带给我们一个问题——历史是为了什么，或为了谁？</p>
<p>过去的历史被编纂出来，“历史服务于一个目的：给人们以认同感。在这个意义上，它就像记忆一样，但它是谁的记忆？有哪些事情需要记忆？</p>
<p>原始证据与”二手“资料</p>
<p>“历史学家能否理解和接近过去的生活？他们写下的故事是否是’真实的故事’？历史的意义会是什么？”</p>
<p>“为何要研究历史，历史何以重要”的三个理由。（认识到以不同方式行事的可能性：避免想当然，比如对于同性恋的看法。）</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>历史学科的三种著作：实践入门指南；哲学考察；研究方法的辩论文。</p>
<p>“书中所写，代表了我在<strong>历史是什么、如何研究历史、历史为了什么</strong>等方面的看法”。</p>
<h2 id="本书三部分：描述在过去历史是什么。"><a href="#本书三部分：描述在过去历史是什么。" class="headerlink" title="本书三部分：描述在过去历史是什么。"></a>本书三部分：描述在过去历史是什么。</h2><p>（自过去至今历史是什么；如何用手头的资料进行（处理、解释）历史工作；历史与真相）</p>
<p>故事：吉扬·德让谋杀案。</p>
<h1 id="一、关于谋杀和历史的问题"><a href="#一、关于谋杀和历史的问题" class="headerlink" title="一、关于谋杀和历史的问题"></a>一、关于谋杀和历史的问题</h1><p>1301年的一起谋杀案。多明我会居士；纯洁派（异端）。谋杀的过程记录在1308年的宗教裁判簿中。</p>
<p>这就是历史：很久以前发生的一个真实故事，<strong>如今被重新讲述</strong>。重新讲述，意味着在过去与现在之间建立起了一个<strong>不对等的联系</strong>（如何不对等？）。（是不是只要建立了这种联系就可以了呢？）</p>
<p>书写历史的过程（历史编纂）——这个“建立联系”的过程——疑问丛生。</p>
<p>在许多方面，历史始于问题也终于问题；历史永远不会真正地结束，历史是一个过程。（这里的“历史”符合“历史编纂”的过程，后者确实永不会结束。）</p>
<h2 id="历史的两种含义"><a href="#历史的两种含义" class="headerlink" title="历史的两种含义"></a>历史的两种含义</h2><ul>
<li>过去本身（忘记历史，就意味着背叛）</li>
<li>历史学家就过去所写的内容（TODO）</li>
</ul>
<p>历史编纂</p>
<ul>
<li>书写历史的过程</li>
<li>对这一过程的研究</li>
</ul>
<p>本书：</p>
<ul>
<li>历史编纂：书写历史的过程</li>
<li>历史：历史编纂的最终成果（其实没有“最终”一说）</li>
</ul>
<p><strong>历史</strong>与<strong>过去</strong>之间存在着本质的差别。</p>
<h2 id="回到故事"><a href="#回到故事" class="headerlink" title="回到故事"></a>回到故事</h2><p>回到故事，上述故事是如何被记载下来的？1308年，吉扬四次出现在名为达布利斯的宗教法官面前。而吉扬最初是被其另一个兄弟热罗牵连进来，热罗<strong>主动</strong>找到宗教法官，指认了许多与纯洁派有染的人。热罗、吉扬及其他至少十五人的供词，都被记录在宗教裁判簿中。这些登记簿有一部分留存至今，所以他们在14世纪初的谈话仍能为我们所知。</p>
<p>这一登记簿由以为现代历史学家编辑、印刷出来。本书作者采用了其中的某些资料，然后本书的读者才知道了吉扬·德让的故事。</p>
<p>那么是什么引起了这位<strong>现代历史学家</strong>和本书作者的关注呢？</p>
<blockquote>
<ol>
<li>谋杀案，有头有尾的故事。</li>
</ol>
</blockquote>
<blockquote>
<ol start="2">
<li>故事中的人不是国王、王子或圣徒，他们是寻常百姓，因此我们也许会很欣喜地发现自己对他们竟然知之甚详。</li>
</ol>
</blockquote>
<p>过去是一个异邦</p>
<blockquote>
<p>哈特利：”过去是一个异邦，在那里他们的行为方式全然不同。“<br>道格拉斯·亚当斯：”过去的确是一个异邦，他们的行为方式就像我们一样。“</p>
</blockquote>
<p>两种说法都有道理。有些事情有共鸣（送信件、离开家乡去旅行、对迫害的恐惧）。有些则不是（了解宗教，不了解纯洁派、异端的概念、宗教审判的程序等）。</p>
<p>更多要素</p>
<blockquote>
<p>14世纪时，如果你是识字的（litteratus），意味着你能读写<strong>拉丁文</strong>，并知道怎样解释经文。仅掌握本国语言不算是识字的，不管是英语还是法语。</p>
</blockquote>
<h2 id="历史：被选择的故事"><a href="#历史：被选择的故事" class="headerlink" title="历史：被选择的故事"></a>历史：被选择的故事</h2><p>吉扬·德让谋杀案显然不是1301年发生在法国南部的唯一事件，但历史学家无法讲述来自过去的<strong>每一个故事</strong>，而只能是其中的一部分。现存资料多有残缺，甚或未留下任何资料。但即使只就我们拥有的证据而言，仍然有许多可说之事。</p>
<p>历史学家需要判断哪些事情是可以说或应该说的。所以，历史不过是那些引起历史学家注意的事情构成的，他们进而决定为其读者<strong>复述这些事情</strong>。</p>
<p>历史学家选择他们的真实故事的依据，已随时间推移而发生变化。</p>
<p>（故事：故是过去之意，故历史本身乃故事：）</p>
<h2 id="历史：故事的解释"><a href="#历史：故事的解释" class="headerlink" title="历史：故事的解释"></a>历史：故事的解释</h2><p>吉扬·德让谋杀案，就其在历史上的影响来看，只算是一幅小插图。如果在故事发生几百年之后的历史学家选择呈现这个故事，而不多说些什么，是很不寻常的。</p>
<p>我们还需要<strong>解释</strong>过去。找出故事更宏大的背景，就是为了不仅仅说出”发生了什么“，而且要说出它<strong>意外着什么</strong>。</p>
<p>对于故事，我们可以选择感兴趣的那些；对于故事的背景，也是类似的。仅就这起谋杀案而言，我们可以考虑（以下可见对于宗教审判与异端各种可能角度的比较思考）：</p>
<ul>
<li>宗教审判和异端。纯洁派信仰者的行为与信仰、审判的程序及其变化</li>
<li>把故事放到犯罪史中考察。中世纪还有另一些谋杀案，比如1170年的托马斯·贝克特；或聚焦下层社会的犯罪行为；</li>
<li>故事发生地在法国南部的”朗格多克“，该地区一度在情感上与加泰罗尼亚而不是巴黎更加亲密，后来教皇因异端下令讨伐该地区，这些讨伐导致了法国北部对南部的政治控制。纯洁派的抵御是与法国政治史紧密联系在一起的。</li>
<li>还可以忽略故事的叙述，关注其它细节。如识字问题；登记簿有关桥梁的记录告诉了我们一些地理知识；或者是农业或建筑方面的东西。</li>
</ul>
<blockquote>
<p>吉扬的供词周围有一个完整的世界，这个对他来说是理所当然的世界以撩人的碎屑和片段展现在我们面前。</p>
</blockquote>
<p>（平民历史的重要性。过去的理所当然，如今看起来饶有趣味。）</p>
<h2 id="历史：猜测与犯”错“"><a href="#历史：猜测与犯”错“" class="headerlink" title="历史：猜测与犯”错“"></a>历史：猜测与犯”错“</h2><p>记录的证据呈现在我们面前，但人们不可能知道每一个细节。历史学家通过合理的猜测填补其中的空白。</p>
<p><strong>猜测</strong>暗示着历史编纂过程具有某种程度的不确定性。在更广泛的意义上，历史学家总是把事情弄”错“，因为：</p>
<ul>
<li>我们永远无法使之完全”正确“</li>
<li>相互之间无法达成一致</li>
<li>需要以自己的方式弄”错“</li>
</ul>
<p>不过，在弄错的同时，历史学家总是试图使之”正确“。在这一点上，历史学家有时喜欢将自己的工作与文学区别开来。但历史也伴随着想象。</p>
<h2 id="历史：是一种论辩"><a href="#历史：是一种论辩" class="headerlink" title="历史：是一种论辩"></a>历史：是一种论辩</h2><p>如果过去没有缺漏，现有的证据总是清晰可信，那么历史学家就无事可做，我们也将失去互相论辩的机会。<strong>历史首先是一种论辩</strong>，不同历史学家之间、过去与现在之间、实际发生与即将发生之间。<strong>论辩是重要的，它们创造了改变事物的可能性</strong>。</p>
<h2 id="历史：真实的故事"><a href="#历史：真实的故事" class="headerlink" title="历史：真实的故事"></a>历史：真实的故事</h2><blockquote>
<p>本书使用用”真实的故事“这个说法来谈论历史。（真实的；故事；解释；）</p>
</blockquote>
<p>（历史即故往之事。真实的，言下之意是，过去作为客观真实之存在；故事，即已过去之片段解释感兴趣之事。）</p>
<p>过去就像生活一样无序、混乱、复杂，历史就是要弄清这种混乱的意义所在，从漩涡中发现或创造模式、意义和故事。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>历史是一个过程、论辩，由过去的真实故事构成。</p>
<p>历史使我们有机会反思自己与过去之间的关系，审视我们挑出来讲述的过去故事的种类、我们回想起那些故事的方式以及讲述那些故事的效果。</p>
<p>当过去重新进入现在，它就成了一个强有力的所在。思考历史，部分是要思考历史是为了什么——或为了谁。此时，我们需要理解<strong>在过去历史是什么</strong>。（见下一章）</p>
<h1 id="二、（走出）政治之塔"><a href="#二、（走出）政治之塔" class="headerlink" title="二、（走出）政治之塔"></a>二、（走出）政治之塔</h1><p>故事：巴比伦国王那波尼德斯搜寻一座太阳神庙。</p>
<p>那波尼德斯热衷于寻找太阳神庙，因为这使他有机会与自己的高贵传统建立联系，而这种联系隐含着权力与权威。他对这一发现的理解方式和将其记录下来的动机，不一定与我们自己对历史的兴趣一致。</p>
<p>（此国王做法近乎历史学家，形成自己的一种解释）</p>
<h2 id="历史的历史"><a href="#历史的历史" class="headerlink" title="历史的历史"></a>历史的历史</h2><p>探寻它的根源何在、从何而来、如何演变，以及在不同的时间和地点被用于何种目的。</p>
<p>无疑，历史作为一门学科随着时间推移在发生变化，而这种变化还在继续着。</p>
<blockquote>
<p>某种意义上，一切历史都希望说出自己当前时代的某些事情。</p>
</blockquote>
<blockquote>
<p>一切历史都是当代史。（贝内德托·克罗齐）</p>
</blockquote>
<h2 id="古希腊的两位历史学家"><a href="#古希腊的两位历史学家" class="headerlink" title="古希腊的两位历史学家"></a>古希腊的两位历史学家</h2><p>希罗多德写下了希腊语波斯之间发生战争的原因。希罗多德拒绝了波斯人的传说，选择依靠”事实“而不是虚构的看法。这种做法使他看起来更像是一位20世纪的历史学家。事实上，他<strong>有时</strong>被称为”历史之父“。</p>
<p>但希罗多德并非总是如此”现代“，他的历史仍有许多令人难以置信的传说，比如骑在海豚尾巴上的阿里翁、特尔斐的神谕。希罗多德总是乐于偏离对政治事件的记述，告诉我们当地人的习俗、不同地区的神秘而奇妙的动物，以及任何吸引他的令人难以置信的故事。因此，他有时又被称为”谎言之父“。</p>
<p>此外，希罗多德利用过去来提供关于环境和性格的说明，以备当时之用。他这样做是因为<strong>在他看来时间是循环的：历史一圈圈地旋转，同样的主题和问题一次次地出现</strong>。他的《历史》中发生的事件背后往往隐藏着循环的命运之轮。</p>
<p>当基督教产生了第一批历史学家后，这种时间观念发生了颇有争议的变化。基督教信仰认为，世界在两个固定的点——造物与天启——之间无情地移动。这个框架就历史意味着什么和人们如何着手探讨历史，提出了完全不同的观念。</p>
<p>另外，早期基督徒把历史当做对过去的<strong>辩驳式</strong>描述来写，他们试图说服基督徒和异教徒，基督教比异教信仰更古老、更理性、更道德也更有效，如尤西比乌斯的《教会史》。之后，奥古斯丁的《上帝之城》对神学和历史进行了一次大规模的糅合，他的学生奥罗修斯写了一个更通俗的版本《反世俗的历史》。</p>
<p>通过抄写对自己有利的原始文献，通过坚持《圣经》的历史准确性，通过将自己教派的历史与宏大的线性时间叙事相结合，尤西比乌斯和奥罗修斯开始创造权威性的历史。他们的工作也得到了另一要素——<strong>修辞观念</strong>——的支持。这种修辞观念的要点在于，照此写就的历史应该具有说服力、易于被接受。</p>
<p>可以说，在彼时的历史学家看来，”修辞“是历史编纂方法的合理组成部分。</p>
<p>随着中世纪的延续，<strong>修辞</strong>仍然保留在历史编纂中，但<strong>另一些要素</strong>开始出现了。12世纪时，马尔梅斯伯里的威廉写了大量的历史著作。他的写作方法具有显著的现代特征：搜寻资料和文献，与人们交谈以调查最近发生之事。他苛刻而多疑，面对手头的资料，运用猜测以进行解释。（苛刻、多疑、合理猜测的艺术是现代历史学家的三种美德）</p>
<p>在12世纪和13世纪，开始有更多的人开始创作历史，历史的<strong>主题</strong>逐渐拓展，如世界史、国家史、武士史。撰写历史仍然是为了特殊的目的（奉承一位赞助人、褒扬一座城市等），但这些<strong>目的</strong>也在变得更为宽泛多样。风格和方法也多样化了。</p>
<p>进入文艺复兴时期，意大利相信自己以一种前所未有的方式重新发现和恢复了<strong>古典智慧</strong>的荣耀。<strong>这在很多方面影响了历史编纂</strong>。从过去吸取哲学教训的观念再次受到青睐，西塞罗式的修辞术是历史学家最基本的风格。历史著作的数量迅速增长。</p>
<p>”文艺复兴“是后人的术语，但时人确信他们的“现代时期”在本质上不同于已经过去的年代。历史学家开始证明佛罗伦萨是古罗马的直接继承者，意大利公民是古典思想的真正继承者。这种撰写历史的新动机使关于过去的观念发生了地震般的转变。历史学家不再把当前时代看作是人类七个世代中的倒数第二个（如基督教历史学家那样），他们谈论的是三个时期：古代、中世纪和现代。中世纪是一个黑暗时代，普遍的看法是，在4世纪到14世纪之间没有发生任何非常重要的事情。</p>
<p>经过16世纪，修辞再次成了支配性的灵感之神，风格再次征服了内容。历史不仅要写得漂亮，而且应仅限于那些与它的“尊严”相称的事件与人物，他们对“日常生活”不大有兴趣。</p>
<p>16世纪的宗教改革导致基督教内部分裂之后，修辞开始再次与宗教辩论结盟。新教与天主教的历史学家们相互攻伐。这种历史编纂之争从未停止过，但**“历史”显然是服务于它的从业者的**。</p>
<p>对于历史的<strong>怀疑与批评</strong>在那个时代就开始出现了，这些怀疑不仅指向当时的历史学家，也开始指向古代的历史学家和历史著作。菲利普·锡德尼讽刺地写道：“历史学家……身上装满了被老鼠咬过的古老记录，授权自己……凌驾于历史之上，他们最大的权威就建立在显然是道听途说的基础上。”历史陷入了某种危机。</p>
<p>法国历史学家让·博丹的《理解历史的简易方法》中，有一章阐明了历史读者应该如何怀疑过去的历史学家，怀疑他们的<strong>目的、方法和偏见</strong>。博丹把“真相”放回了议事日程。到16世纪末，历史又再次着眼于过去的“真实故事”。</p>
<p>从上面的回顾可以看到，“历史”对于不同的人总是意味着不同的事情。</p>
<p>本章并非在描述人们在撰写历史方面变得更好、更聪明的“进步”故事。这样的理解会错过关键所在。所有这些历史学家都尽力去理解被他们视为可能的过去。我们会——<strong>从我们当前的立场</strong>——看到某些尝试比另一些更加准确。但这是根据我们对何为“真实”的看法得出的。过去的人们会有不同的看法。</p>
<h2 id="历史：是一种记忆？"><a href="#历史：是一种记忆？" class="headerlink" title="历史：是一种记忆？"></a>历史：是一种记忆？</h2><p>有人说撰写历史是一种自然和必要的活动：<strong>历史之于社会，正如记忆之于个人</strong>。历史当然是非常有力的，但回头看看过去的那些历史学家们的故事，我们会理解到，人们撰写历史是由于他们自己时代的特定环境和需要。萨瑟恩指出，11世纪和17世纪的交替时期之所以出现历史编纂的热潮，是因为彼时正在经历特殊的骚乱与动荡。在这里，历史服务于一个目的：给人们以认同感。在这个意义上，它就像记忆一样。问题是，它是<strong>谁的</strong>记忆？有<strong>哪些事情</strong>要记忆？</p>
<p>本章所有的历史学家都倾向于选择记忆某类领域的事情：伟人、教会、政府、政治。这种模式部分是由希腊人提出的：不是希罗多德，而是他的继承者修昔底德。他认为，历史与政治和国家有关，而与其它任何事情无涉。有人评论道，<strong>修昔底德把自己关在了政治史之塔中，还想把我们所有人都束缚在那里</strong>。我们该如何逃离那座塔呢？</p>
<h1 id="三、事实是怎样的？"><a href="#三、事实是怎样的？" class="headerlink" title="三、事实是怎样的？"></a>三、事实是怎样的？</h1><p>1885年，90岁的兰克在他柏林的书房里，创造自己最后的历史著作。通过向助手口述，他对自己历史学家的一生做了简单的描述。他提到了阅读沃尔特·司各特爵士历史小说的经历：</p>
<blockquote>
<p>书中对秃头查理和路易十一的处理方式和其它内容一起让我很不愉快，它们似乎……与历史证据完全相反。我研究了……当时的记载……确信司各特所描绘的秃头查理或路易十一从不曾存在过。这种比较使我相信，历史资料本身比浪漫的虚构更加美丽，而且无论如何要更加有趣。我彻底厌倦了虚构，下定决心在自己的著作中避免任何捏造和想象，严格终于事实。</p>
</blockquote>
<p>兰克经常被称为<strong>现代历史编纂之父</strong>，他呼吁历史学家写出“科学的”和“客观的”历史，其历史哲学被浓缩在一句广为引用的名言中：</p>
<blockquote>
<p>仅仅说出事实是怎样的。</p>
</blockquote>
<p>本章将叙述16世纪到20世纪之间历史编纂的某些发展。期间许多也许不会把自己看作历史学家的学者，为今天的“历史”贡献了特定的要素。</p>
<p>（真相的问题<br>如何利用历史文献的问题<br>过去与现在之间的“区别”问题）</p>
<h2 id="问题：什么是真相"><a href="#问题：什么是真相" class="headerlink" title="问题：什么是真相"></a>问题：什么是真相</h2><p>“历史”在16世纪遭遇了怀疑主义者的围攻，他们认为历史是不准确和无用的。他们所谴责的“历史”大部分是运用了修辞技巧的历史，<strong>由既要提供精炼的叙述，又要从过去的政治事件中提出惩戒性“教训”的双重期望所驱动</strong>。</p>
<p>除了让·博丹，还有另一些历史的捍卫者。</p>
<p>捍卫历史“真相”的最初驱动力来自宗教冲突。（对，从最无处不在的偏见——信仰中发展出了用于获取客观真相的手段）新教和天主教都用历史来支持他们相互对立的对于权威性的诉求。相关学者的方法比较简单：大量搜集可用于防御敌人攻击的证据。</p>
<p>更复杂的是分析古文物学家提供的文献。与历史学家相比，古文物学家没有重要的故事要讲，只有强烈的热爱要表达。但正是这些古文物学家创造除了经由保留下来的文献和资料研究过去的手段。</p>
<h2 id="问题：如何使用文献。"><a href="#问题：如何使用文献。" class="headerlink" title="问题：如何使用文献。"></a>问题：如何使用文献。</h2><p>1439年，洛伦佐·瓦拉针对也许是基督诞生以来一千四百年间最著名的文献，撰写了一篇也许是最著名的文献分析。这份文献就是《康斯坦丁赠礼》，它旨在记录4世纪时叫这个名字的罗马皇帝赠与基督教会的礼物与权利。整个中世纪，《赠礼》是教会最有效的一件武器。瓦拉则证明它是一件伪造品。</p>
<p>至少从12世纪开始，就有人对《赠礼》提出质疑，瓦拉采用了新的方式。他聚焦于文献的<strong>语言</strong>。通过分析其使用的拉丁文风格和所提供的细节，他断言这是一件伪造品。瓦拉注意到文献中的拉丁文根本不像4世纪的“古典”拉丁语。</p>
<p>将文献学应用用历史文献，提供了两种探究过去的新思想：</p>
<ul>
<li>人们可根据其内部特征鉴定一份文献，判断历史记录中什么是“真相”</li>
<li>语言（因而还有文化）在不同的历史时期是变化的；人们谈话和生活的方式随时间流逝而变动。</li>
</ul>
<h2 id="问题：过去如何不同于现在"><a href="#问题：过去如何不同于现在" class="headerlink" title="问题：过去如何不同于现在"></a>问题：过去如何不同于现在</h2><p>瓦拉把语言和文化再次引入了历史。历史包含比政治“事件”更多的内容，这一观念第一次逃离了修昔底德的政治史之塔。</p>
<p>这些观念及其寓意并不完全出自瓦拉，也没有直接引起历史实践的革命。瓦拉不是一位“历史学家”，发展这些主题的那些人也不是。他们毋宁说是文献学家、古钱币学家、地志学家等。在16世纪和17世纪，这些古文物学家的追求在整个欧洲越来越流行，甚至在19世纪，业余学者还会追忆这些古文物学家。如今历史学家使用的许多文献汇编，都是这些维多利亚时代团体的产物。</p>
<p>古文物学家与历史学家的不同之处在于，前者试图拼凑一幅图画，而后者则是讲述一个故事。</p>
<p>博杜安（1520-1573）是一位想要弄清罗马法律从过去到当代如何演变的学者，他看到了将历史研究与法学相结合的可能性，试图“清楚历史中的神话”。博杜安提出，历史学家应该像一名律师那样：在相互冲突的记述之间进行取舍，力图建立事件发生的准确顺序，以冷静、客观的怀疑态度对待“证物”（文献）。我们不妨把他所说的“律师”看作是”侦探“。</p>
<p>所以文艺复兴之后，历史作为一种创作，得到了新的工作和研究方法。如果是以前的历史学家是在创造”真实的故事“，而本章的历史学家则以”真实的故事“为目标。正是从瓦拉到博杜安的时期，形成了使用资料的方法和原则，<strong>力图确定历史”真相“可以通过证据来证明</strong>。</p>
<blockquote>
<p>历史学家总是在”真相“和”讲故事“的两极之间来回摆动。</p>
</blockquote>
<h2 id="启蒙运动"><a href="#启蒙运动" class="headerlink" title="启蒙运动"></a>启蒙运动</h2><p>18世纪，一个与通常所称的”启蒙运动“联系在一起的世纪，历史的”真实故事“与哲学问题发生了关联。历史的这个新目的影响了历史学家对过去时代和历史文献的看法。伏尔泰评论道：</p>
<blockquote>
<p>让细节见鬼去吧！后人会把它们全都抛开。它们是侵蚀宏伟著作的一种寄生虫。</p>
</blockquote>
<p>伏尔泰对历史细节有明确的排斥。需要注意到，18世纪有一种非常不同的驱动力，一种让历史与启蒙思想家所关心的主题——理性、自然和人类——产生关联的愿望。诸如伏尔泰、休谟、维柯、孔多塞等作者，是在通过对过去的研究来探讨”大问题“——<strong>有关人类存在的性质和周围世界的运行</strong>。他们的兴趣为再次逃离修昔底德之塔提供了可能。</p>
<p>对于通晓哲学的历史学家来说，仅仅涉及事实积累和政治事件是不够的。世界——无论是过去还是现在——首先是<strong>复杂多样</strong>的。启蒙运动中的历史学家不仅对统治精英的决定感兴趣，也对地理、气候、经济、社会结构和不同人们的性格感兴趣。如果科学家能够指出自然世界中的让人难以置信的相互联系，历史学家也应该尝试以类似的复杂方式去理解过去。</p>
<p>（与历史编纂的演变和对过去的看法有关的主题）</p>
<p>一、”过去“并非如此简单。植物学和地质学的发展使各种各样的思想家得出结论：世界要比《旧约》所承认的古老得多。上帝六天造物的记述即使是”真实的“，也只是在象征意义上而已。时间本身的延伸必然会挑战过去的假设。上帝在历史中扮演的角色不得不重新确定。</p>
<p>二、对某些作者来说，上帝甚至完全可以忽略不计。另一些人则把上帝的旨意想象为”神圣的天意“——指引人类历史进程的终极原因。对于抛弃了”天意“观念的历史学家来说，他们仍然需要一种<strong>因果关系理论</strong>。两种互相竞争的模式出现在他们面前：偶然性和伟人。</p>
<p>三、启蒙运动还提出了另一个信念：人性具有永恒的普遍性。大卫·休谟写道：</p>
<blockquote>
<p>所有时代和所有地方的人是完全一样的，历史在这一点上没有说出任何新鲜的或奇特的事情。它的主要用途不过是<strong>发现</strong>永恒而普遍的人性准则。</p>
</blockquote>
<p>四、从德国启蒙运动后期阶段开始，历史学家越来越相信，恰当理解历史要做两件互相联系的事情：</p>
<ol>
<li>非常详细地研究档案资料</li>
<li>形成因果关系理论，将地理位置、社会体系、经济力量、文化观念、技术进步的影响与个人意志之间的复杂关系融合起来</li>
</ol>
<p>历史正在从政治学和法学转向经济学和今天所称的社会学。在这种冲击下，修昔底德之塔的确变成了废墟。</p>
<p>五、兰克：“科学“的历史</p>
<p>18世纪许多最著名的作家创作出”哲学式的“历史，它们与事实本身无涉，而与他们试图阐明的某些重大问题有关。另一些历史学家也从西塞罗式的历史中汲取灵感，为读者大众创作出”美丽故事“。</p>
<p>而兰克在暗示不同的东西。他要对文献进行详细的分析，不让富于幻想的灵感”歪曲“结果，服从审查和验证的”科学“观念，从而能够”仅仅说出事实是怎样的“。那么他改变了什么呢？</p>
<p>首先，如果说吉本（其《罗马帝国衰亡史》被认为是第一步”现代“历史著作）标志着历史作为一种使命（因历史本身而选择研究历史）的开端，那么兰克确立了一种作为职业的历史。兰克的一大遗产是历史学家的工作研讨班，这种模式仍在指引大多数年轻的历史学家熟悉这个行当。</p>
<p>其次是一再出现的格言：”仅仅说出事实是怎样的“。这个短小而平淡的句子激发了关于历史实践和历史哲学的许多论著。这是历史学家逃离”真实故事“的范式，让历史仅与”真实“相关的一种尝试。</p>
<p>兰克之后，任何类型的历史学家心中首要的观念就是”真相“，它可以通过忠实于资料而着手进行探究或最终企及。</p>
<p>（之后的历史编纂越来越细分，如今很少有历史学家简单地称自己为历史学家：他们是”社会史学家“、”科学史学家“、”女性史学家“等等。）</p>
<h2 id="历史的职业化"><a href="#历史的职业化" class="headerlink" title="历史的职业化"></a>历史的职业化</h2><p>19和20世纪历史学日益制度化，历史成为工业革命后逐步”职业化“的大量学科中的一个。职业化的结果之一是，出现了历史应该服务于民族国家需要、创作”民族“历史的期望。职业化并未将历史学家从其独特文化的需要和偏见中解救出来，也许还强化了这种需要和偏见。</p>
<p>值得注意的是，历史学家为职业地位付出了某些代价。首先，一般读者与专业历史学家之间存在者越来越多的隔阂。对于每一个读者来说，许多有趣的、重要的内容被隐藏在了令人不快的大片专业注释当中。其次，成为”专业人员“有时会让历史学家假装超然于现在和过去，对其作出客观的判断。但要注意，”专业的“并不意味着”公正的“，它主要表示”有报酬的“。最后，职业化还会导致分裂。这种分裂也许是不可避免的，但这的确意味着”历史“绝不会只是<strong>一个</strong>真实的故事。</p>
<h1 id="四、声音与沉默"><a href="#四、声音与沉默" class="headerlink" title="四、声音与沉默"></a>四、声音与沉默</h1><h2 id="诺里奇档案馆的火灾"><a href="#诺里奇档案馆的火灾" class="headerlink" title="诺里奇档案馆的火灾"></a>诺里奇档案馆的火灾</h2><p>本章与后面两章，将阐明历史学家怎样展开研究历史的工作。我们将<strong>利用原始数据，从历史中探索出一个真实的故事</strong>。</p>
<p>档案馆中重要的东西：赖以运作的<strong>分类系统</strong>。历史学家的工作从档案开始——但只能在档案管理员对那些资料分类、整理之后。</p>
<p>历史学家常常提到<strong>原始证据</strong>。原始数据与”二手“资料的界限可能很难划分，而且”二手“资料也是它们自己时代的”原始“证据。</p>
<p>至少从15世纪开始，诺里奇的公民就注意将与自己历史有关的文献安全地保管下来。因为旧文献是权力的表现，尤其是那些与土地所有权和法律权利有关的文献。</p>
<p>档案馆不仅是仓库，它们也是系统化的信息库，由专业人士照料着。这一点在两方面显得颇为重要：</p>
<ol>
<li>过去的资料不是以一致的格式保留下来的，需要有人整理并有序地存放。</li>
<li>管理员编写出”查档指南“，通常也附有内容摘要，使查阅者（如历史学家）能快速地查找文献</li>
</ol>
<h2 id="什么是”资料“？"><a href="#什么是”资料“？" class="headerlink" title="什么是”资料“？"></a>什么是”资料“？</h2><p>早些时候的资料多是<strong>叙述性</strong>文献：编年记事、回忆录、政府记录、过去的史书。到了19世纪和20世纪，资料开始包含更多的种类，如遗嘱、书信、买卖记录和其它财会项目、税收文件、法庭记录等。</p>
<p>事实上，资料可以是任何为我们留下过去痕迹的东西。</p>
<h2 id="伯德特太太补助金文献（一份市政府记录）"><a href="#伯德特太太补助金文献（一份市政府记录）" class="headerlink" title="伯德特太太补助金文献（一份市政府记录）"></a>伯德特太太补助金文献（一份市政府记录）</h2><p>历史学始于资料，有两个重要步骤：</p>
<ol>
<li>将历史学家推向一系列特定资料的线索。（历史学家在看到证据之前要做出选择，所以也可以说，历史学开始的途径之一是资料）</li>
<li>历史学家本身：他们的兴趣、观念、环境与经历。</li>
</ol>
<p>我们看到伯德特太太将得到一份年金，但它还缺乏一种语境以赋予其意义或重要性，所以它还能称为”历史“。这里，历史学家需要决定他（她）要寻找何种意义，并弄清资料本身能够提供的支持是什么。对同一份《议会记事簿》，我们可以从不同方面来探讨，如对雅茅斯市政府的调查，也可以讨论社会、宗教、政治等等。</p>
<p>还有其它的问题有待解决：</p>
<ul>
<li>我们手头的资料是否是伪造品？</li>
<li>资料中的”偏见“，这一点需要认真对待。寻找”偏见“，似乎暗示着可以找到一种”无偏见“的立场。如果”偏见“意味着每个人的特有风格，那么”偏见“的存在是必然的，也就是是不存在”无偏见“的文献。除了个人风格，文献也可能反映出“时代”风格。需要注意的是，这些“偏见”不是要“抛弃”的；相反，它们是可资利用的内容。</li>
<li>不仅仅考虑资料所说出的，还要考虑它未说出的。关于议会给予伯德特太太年金的决定，是轻易作出的，还是经过了数小时的争论？伯德特太太是否在场？议会为何决定给她一份年金？</li>
</ul>
<p>资料并不是真地“自己会说话”。我们阅读资料时问题会逐一浮现，如：谁是伯德特？他为何要去新英格兰？伯德特太太和她的孩子后来怎样了？要回答它们，我们需要寻找关于伯德特一家的其它资料。此时，我们决定了要探寻的特定路线——从起点开始，将资料所提供的和未提供的以及我们所关注地，一一联结起来。</p>
<p>历史学家依赖彼此的著作，与依赖自己对历史资料的调查一样多。</p>
<p>有时历史学家恰好是这样做的：辛苦而单调地搜寻每一种能够找到的文献，寻找对他（她）关注之事的记载。</p>
<p>大多数历史学家不仅利用原始档案，也会利用已出版的资料。</p>
<p>文献很少打算欺骗历史学家，但它们时刻都会愚弄那些粗心的人。</p>
<p>在一个特定的时刻，资料陷入了沉默，历史学家必须开始做些猜测——对文件进行<strong>解释</strong>。</p>
<p>沿着一条令人满意的道路继续前进的代价，就是也许会阻塞其它可能的道路。</p>
<p>资料时一个起点，但历史学家在此之前和之后都要在场，并使用技巧，做出选择。为什么是这份文献而不是另一份？为什么是这些契据而不是那些？为什么要看契据而不是审判记录？为什么要研究政府报告而不是日记？要探讨哪些问题？采用哪些途径？</p>
<p>资料不会自己说话，它也从来没这样做过。</p>
<p>以完全真实为目标的历史永远无法实现（只能是<strong>一个</strong>真实的故事），因为无数的事情仍然无法得知。这一问题使得“过去”成为一个研究领域而不是一个不证自明的真实。我们可以说：档案必须被烧毁（当然是在象征意义上），历史才得以发生。我们必须拥有资料——我们也必须拥有沉默。</p>
<h1 id="五、千里之行"><a href="#五、千里之行" class="headerlink" title="五、千里之行"></a>五、千里之行</h1><p><strong>重建</strong>伯德特的某些历史，让我们走出了第一步，现在我们要去向何方呢？</p>
<p>我们试图在漫长旅程中的开放空间和在伟大旅程中寻找意义、探求论据。伯德特至少是两个更宏大的故事中的一部分，即英国内战和美洲殖民。</p>
<p>研究历史需要几种类型的猜测。我们已经看到试图在现存证据中“填补空白”的过程。本章将探讨的是一个更深层的过程：<strong>怎样将大量的材料综合起来，以及用宏大故事所呈现的轮廓去构造什么</strong>。</p>
<p>创造一个故事，不止是构造一个孤立的故事，我们还需要确定所描述的事件的原因和结果，处理其它历史学家已经说过的内容，并指出这个故事意味着什么。</p>
<p>人们关注地证据的类型，无疑会影响<strong>被讲述的故事</strong>。以英国内战为例，如果主要关注叙述性的记载、王室的文献和议会的文件，呈现的故事就是政治性的：故事包含了从1642年国王和议会之间爆发战争到1660年查理二世夺回王位发生的重要事件。</p>
<p>在这个“政治”故事中，变化的原因是什么，它又意味着什么？一个看起来较为合理且被广为接受的观点是，<strong>变化</strong>是通过人的能干与否实现的（如无能的查理一世与起初有能力的克伦威尔），并受制于某种偶然性（战争意外失利），还受到意识形态的影响（君主制对共和制）。</p>
<p>在其最原始的状态下，政治史依然坚持着19世纪晚期的模式：叙述“伟大的事件”，评判“伟人”（也包含负面意义上的人，如墨索里尼与希特勒）。这一模式同时也否认了某些人可以称为“伟大”。那么，评判伟大与否的依据与标准是什么却不甚清楚。</p>
<p>还有些理论关注地是那些不那么伟大的人所做的决定，其出发点是，导致事件发生的是掌握权力的个人所做的或好或坏的决定。</p>
<p>过去发生的事情无疑收到人们所做决定的影响——有时还是决定性的。但人们想要做什么与这些想法产生的实际结果，常常不是一回事。</p>
<p>社会史学家与政治史学家关注的证据往往不同，尤其是地方性的政府记录，在其中更有可能找到与普通百姓有关的信息。这种信息有些可用作经济分析。20世纪，经济变迁的图景引起了历史学家越来越多的兴趣，这主要是由于马克思的影响。（马克思主义的一个经典叙述）</p>
<p>事实上，今天所有的历史学家都是马克思主义者（marxists）。马克思思想中的一个关键要素已在历史学家的观念中根深蒂固，以至于已被视为理所当然了：社会和经济环境影响着人们对他们自己、他们的生活及其周围世界进行思考而采取行动的方式。马克思本人写道：</p>
<blockquote>
<p>人类创造自己的历史，但不是随心所欲地创造。他们不是在自己选择的情境之下，而是直接在碰巧遇见、给定，以及从过去流传下来的情境之下创造历史。</p>
</blockquote>
<p>人类学和社会学的影响，使社会史学家能够研究在人们日常生活中所察觉到的行为模式：他们的家庭结构、日常生活中的行为举止、对于周围社会空间的安排并赋予其意义的方式。对这些不同领域的考察会将历史学家引向不同的问题，如婚姻模式的变化、性别感受对社会行为的影响。</p>
<p>近年来，历史学家对文化的兴趣也越来越强烈了，这同样来自人类学观念的影响。人类学、社会学与社会学联结起来，此时的”文化“不仅仅是指音乐、戏剧、文学之类，也用来指称思想和理解的模式、语言形式、生活仪式以及思维方式。</p>
<p>无论学者被贴上“历史学家”、“经济学家”、“社会学家”还是“人类学家”的标签，他们都不过是在分析人们如何生存和互动。不同的方法会有不同的侧重点，但其共通之处有时要比他们愿意承认的多得多。历史学所能做出的一大贡献是推动人们去思考事物为何以及如何随时间变化。</p>
<h2 id="历史中的“因果”"><a href="#历史中的“因果”" class="headerlink" title="历史中的“因果”"></a>历史中的“因果”</h2><p>我们经常发现自己在谈论“原因”，有时则会谈到“起源”。要了解复杂的过程，它们是有用的常识性表达，却也隐含着危险。</p>
<p>如果要描述欧洲人在美洲的殖民过程，我们可以指出导致这一过程的种种因素，但必须要意识到在创造“一个”殖民故事的时候，我们是在综合成千上万的也许并不符合我们整体框架的个人叙述。<strong>综合总是意味着让某些事物缄默</strong>。综合是有用的和不可避免的，但它仍然只是“一个真实的故事”而非整个真实。近年来，历史学家对综合而成的“宏大叙事”产生了怀疑，因为这些故事往往会忽视任何特殊情形的复杂性。</p>
<p>在处理面对的问题时，我们对讲述伟大故事的人们产生了怀疑，因为我们希望更多地关注真实故事中的细节。</p>
<p>“结果”和起源同样复杂。对于历史来说，没有任何事物会终结，故事引发其它的故事。“起源”只是我们选择的这个故事的起始之处，它决定（也被决定）我们想要讲述的是何种类型的故事。</p>
<p>在试图确定是什么“导致”某事发生的时候，历史学家可以采用多种不同的理论，站在各种各样的立场。多数人会承认，除了在最简单的层面上，任何事情都有多重的原因。由于某个原因而发生的事情，又称为其后发生事情的原因，历史学家试图从这些复杂的事件中归纳出模式。过去无疑有许多模式有待发现，但它们多大程度上是已存在的模式，多大程度上是历史学家提炼出来的模式？</p>
<p>不存在，也永远不会存在，对故事的唯一一种解释。期待这样一种解释，也许会错失过去的意义。任何历史都是对过去极度的复杂性试图说些什么。历史学家有一种沉重的责任：决不要声称自己的叙述是讲述故事的唯一方式。但读者也有自己的责任：不要因为它们并不完美而轻忽历史，而要把它们当作真实的故事去处理，它们只能如此。</p>
<p>历史如马克思所说，是由人们在自己无法选择的环境中创造的，但他们在自己的生活中影响着所处的环境。</p>
<p>大多数发生的事情都是人们人们试图实现特定目标的结果，但他们永不具备足以预见其结果的洞察力。人们出于与当下相关之因，行与当下相关之事。他们的所作所为激起波浪，向外扩展，又与无数其他人激起的波浪互相作用。在这些互相碰撞的波浪构成的模式中，历史就在某处发生了。（历史是一种“在别处”）</p>
]]></content>
      <categories>
        <category>History</category>
      </categories>
      <tags>
        <tag>History</tag>
      </tags>
  </entry>
  <entry>
    <title>interesting-python-libraries</title>
    <url>/2020/08/11/interesting-python-libraries/</url>
    <content><![CDATA[<p>偶遇的有趣的 Python 库。</p>
<h1 id="attrs"><a href="#attrs" class="headerlink" title="attrs"></a><a href="https://www.attrs.org/en/stable/index.html">attrs</a></h1><p><code>attrs</code> 将为你找回编写类（classes）的乐趣，能够减轻大量的 <a href="https://nedbatchelder.com/blog/200605/dunder.html">dunder methods</a>。我们写出的类型的代码会更简洁，更少出错。</p>
<h2 id="日常应用"><a href="#日常应用" class="headerlink" title="日常应用"></a>日常应用</h2><ul>
<li>类型标注：编写自文档代码，如借助于 <code>attr.ib</code>。</li>
<li>类型初始化</li>
<li>Hashing</li>
<li>…</li>
</ul>
<p>声明 attributes 后，可以获得：</p>
<ul>
<li>a concise and explicit overview of class’s attribs</li>
<li>a nice human-readable <code>__repr__</code></li>
<li>comparison methods (equality and ordering)</li>
<li>an initializer</li>
<li>…</li>
</ul>
<p>自 Python 3.6 开始，还可以不使用 <code>attr.ib</code> 而是直接用 <a href="https://www.attrs.org/en/stable/types.html">type annotations</a>，当然，前提是你希望将标注所有的属性。</p>
<p>借助于 attrs，可在代码中方便地使用自定义类型而非 tuples，以及令人困惑的 namedtuples。之所以使用 tuples，往往是为了方便省事儿，但有了 attrs，写个自定义类型也不麻烦了。</p>
<h2 id="attrs-不是什么"><a href="#attrs-不是什么" class="headerlink" title="attrs 不是什么"></a>attrs 不是什么</h2><p>attrs 不会偷偷地使用 meta classes、runtime introspection 以及 interdependencies。它所做的是：</p>
<ul>
<li>使用你的声明</li>
<li>为你定义 dunder methods</li>
<li>将这些方法 attach 到你的类型</li>
</ul>
<p>因此不会有任何的性能损失。</p>
<h2 id="attr-s-与-attr-ib"><a href="#attr-s-与-attr-ib" class="headerlink" title="attr.s 与 attr.ib"></a>attr.s 与 attr.ib</h2><p>它们看起来很不自然？把 <code>.</code> 去掉试试。</p>
<h2 id="既然已经有了…，为何还要用-attrs？"><a href="#既然已经有了…，为何还要用-attrs？" class="headerlink" title="既然已经有了…，为何还要用 attrs？"></a>既然已经有了…，为何还要用 <code>attrs</code>？</h2><h3 id="tuples"><a href="#tuples" class="headerlink" title="tuples"></a>tuples</h3><ul>
<li>可读性：无须赘述</li>
<li>可扩展性：增加元素，会导致一系列代码失效</li>
</ul>
<h3 id="namedtuples"><a href="#namedtuples" class="headerlink" title="namedtuples"></a>namedtuples</h3><blockquote>
<p>If you want a tuple with names, by all means: go for a namedtuple. 5 But if you want a class with methods, you’re doing yourself a disservice by relying on a pile of hacks that requires you to employ even more hacks as your requirements expand.</p>
</blockquote>
<h3 id="Data-Class"><a href="#Data-Class" class="headerlink" title="Data Class"></a>Data Class</h3><p><code>attrs</code> 与 <code>Data Class</code> 很像，但 attrs 有功能更多，演进更快速。Data Class 只能用于 py37 之后。</p>
<h3 id="dicts"><a href="#dicts" class="headerlink" title="dicts"></a>dicts</h3><p>如果把值看作kv 对，tuples 可看作是隐藏了 keys；dict 看起来更完备一些，但是此时的 keys 往往是 str。</p>
<blockquote>
<p>if your dict has a fixed and known set of keys, it is an object, not a hash. So if you never iterate over the keys of a dict, you should use a proper class.</p>
</blockquote>
<h1 id="Data-Class-1"><a href="#Data-Class-1" class="headerlink" title="Data Class"></a>Data Class</h1><p>在了解了 attrs 后，感觉<strong>Data Class</strong>可能更可取，因为它属于标准库，更可靠，而且一般不需要考虑py37 之前的版本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from dataclasses import dataclass</span><br><span class="line"></span><br><span class="line">@dataclass</span><br><span class="line">class DataClassCard:</span><br><span class="line">    rank: str</span><br><span class="line">    suit: str</span><br><span class="line"></span><br><span class="line"># init: positional, keywords</span><br><span class="line">queen_of_hearts = DataClassCard(&#x27;Q&#x27;, suit=&#x27;Hearts&#x27;)</span><br><span class="line"># repr</span><br><span class="line">print(queen_of_hearts)</span><br><span class="line"># eq</span><br><span class="line">print(queen_of_hearts == DataClassCard(&#x27;Q&#x27;, &#x27;Hearts&#x27;))</span><br></pre></td></tr></table></figure>

<p>通过这个简单的例子可以看到 dataclass 比常规自定义类型多做的三件事情，同时也优于用作数据容器的 tuple、dict。</p>
<h1 id="pyqtgraph"><a href="#pyqtgraph" class="headerlink" title="pyqtgraph"></a>pyqtgraph</h1><h1 id="pywebview"><a href="#pywebview" class="headerlink" title="pywebview"></a>pywebview</h1><h1 id="colorama"><a href="#colorama" class="headerlink" title="colorama"></a>colorama</h1><h1 id="begins"><a href="#begins" class="headerlink" title="begins"></a>begins</h1><h1 id="arrow"><a href="#arrow" class="headerlink" title="arrow"></a>arrow</h1><h1 id="parsedatetime"><a href="#parsedatetime" class="headerlink" title="parsedatetime"></a>parsedatetime</h1><h1 id="Cython"><a href="#Cython" class="headerlink" title="Cython"></a>Cython</h1><h1 id="https-github-com-vinta-awesome-python"><a href="#https-github-com-vinta-awesome-python" class="headerlink" title="https://github.com/vinta/awesome-python"></a><a href="https://github.com/vinta/awesome-python">https://github.com/vinta/awesome-python</a></h1>]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Mathematica FAQs</title>
    <url>/2017/08/02/mathematica-FAQs/</url>
    <content><![CDATA[<h1 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h1><h2 id="定义函数"><a href="#定义函数" class="headerlink" title="定义函数"></a>定义函数</h2><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="variable">f</span><span class="punctuation">[</span><span class="type">x_</span><span class="punctuation">]</span> <span class="operator">:=</span> <span class="variable">x</span><span class="operator">^</span><span class="variable">x</span></span><br></pre></td></tr></table></figure>

<h1 id="Plotting"><a href="#Plotting" class="headerlink" title="Plotting"></a>Plotting</h1><figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Plot</span><span class="punctuation">[</span><span class="variable">x</span><span class="operator">^</span><span class="variable">x</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">x</span><span class="operator">,</span> <span class="operator">-</span><span class="number">1</span><span class="operator">,</span> <span class="number">1</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>

]]></content>
      <tags>
        <tag>Mathematica</tag>
      </tags>
  </entry>
  <entry>
    <title>nlp-in-action-ch01</title>
    <url>/2019/08/18/nlp-in-action-ch01/</url>
    <content><![CDATA[<h1 id="NLP实战"><a href="#NLP实战" class="headerlink" title="NLP实战"></a>NLP实战</h1><h2 id="Chatbot-Recurrent-Pipeline"><a href="#Chatbot-Recurrent-Pipeline" class="headerlink" title="Chatbot Recurrent Pipeline"></a>Chatbot Recurrent Pipeline</h2><ol>
<li>Parse: tokenizer, NER, extract info., reduce dim</li>
<li>Analyze: spelling, grammar, sentiment, humanness, CNN, GAN</li>
<li>Generate: search, templates, FSM, RNN…</li>
<li>Execute: generate &amp; classify…</li>
</ol>
<h2 id="序"><a href="#序" class="headerlink" title="序"></a>序</h2><p>2013年之后，NLP和聊天机器人的应用变得日益广泛，如愈来愈智能的Google Search、智能手机的自动完成功能。Gmail的<code>Smart Reply</code>令作者印象深刻。</p>
<p>从经典的马尔科夫链（词频、ngrams、条件概率等），可以实现一些颇为有用的功能，如Peter Norvig的<a href="https://norvig.com/spell-correct.html">spelling corrector</a>。</p>
<p>PS：Peter的文章2016年有更新，或许会有新的启发，文章主要涉及传统的基于统计的语言模型。</p>
<p>接下来是<strong>隐语义分析（Latent Semantic Analysis, LSA）</strong>，大致是持续跟踪那些共现的词，从而可将这些词归为<strong>topic</strong>。LSA将句子或文档的意思压缩为一个向量。</p>
<p><strong>gensim</strong>库实现了<code>Word2vec</code>词向量，可将</p>
<h1 id="第一部分-善谈的机器"><a href="#第一部分-善谈的机器" class="headerlink" title="第一部分 善谈的机器"></a>第一部分 善谈的机器</h1><p>1-4章</p>
<h1 id="Ch01-NLP概述"><a href="#Ch01-NLP概述" class="headerlink" title="Ch01 NLP概述"></a>Ch01 NLP概述</h1><h1 id="Ch02-构建词汇表（Tokenizer）"><a href="#Ch02-构建词汇表（Tokenizer）" class="headerlink" title="Ch02 构建词汇表（Tokenizer）"></a>Ch02 构建词汇表（Tokenizer）</h1><h1 id="Ch03-关于词的数学（TF-IDF）"><a href="#Ch03-关于词的数学（TF-IDF）" class="headerlink" title="Ch03 关于词的数学（TF-IDF）"></a>Ch03 关于词的数学（TF-IDF）</h1><h1 id="Ch04-词频蕴含的意义（Semantic-Analysis）"><a href="#Ch04-词频蕴含的意义（Semantic-Analysis）" class="headerlink" title="Ch04 词频蕴含的意义（Semantic Analysis）"></a>Ch04 词频蕴含的意义（Semantic Analysis）</h1><h1 id="第二部分-深度学习"><a href="#第二部分-深度学习" class="headerlink" title="第二部分 深度学习"></a>第二部分 深度学习</h1><p>5-10章</p>
<h1 id="Ch05-初识神经网络（感知机与反向传播）"><a href="#Ch05-初识神经网络（感知机与反向传播）" class="headerlink" title="Ch05 初识神经网络（感知机与反向传播）"></a>Ch05 初识神经网络（感知机与反向传播）</h1><h1 id="Ch06-以词向量推理（Word2Vec）"><a href="#Ch06-以词向量推理（Word2Vec）" class="headerlink" title="Ch06 以词向量推理（Word2Vec）"></a>Ch06 以词向量推理（Word2Vec）</h1><h1 id="Ch07-卷积神经网络（CNN）"><a href="#Ch07-卷积神经网络（CNN）" class="headerlink" title="Ch07 卷积神经网络（CNN）"></a>Ch07 卷积神经网络（CNN）</h1><h1 id="Ch08-循环神经网络（RNN）"><a href="#Ch08-循环神经网络（RNN）" class="headerlink" title="Ch08 循环神经网络（RNN）"></a>Ch08 循环神经网络（RNN）</h1><h1 id="Ch09-LSTM"><a href="#Ch09-LSTM" class="headerlink" title="Ch09 LSTM"></a>Ch09 LSTM</h1><h1 id="Ch10-Seq-to-seq模型"><a href="#Ch10-Seq-to-seq模型" class="headerlink" title="Ch10 Seq-to-seq模型"></a>Ch10 Seq-to-seq模型</h1><h1 id="第三部分-来到现实世界"><a href="#第三部分-来到现实世界" class="headerlink" title="第三部分 来到现实世界"></a>第三部分 来到现实世界</h1><p>11-13章</p>
<h1 id="Ch11-信息提取（NER与问题回答）"><a href="#Ch11-信息提取（NER与问题回答）" class="headerlink" title="Ch11 信息提取（NER与问题回答）"></a>Ch11 信息提取（NER与问题回答）</h1><h1 id="Ch12-对话引擎"><a href="#Ch12-对话引擎" class="headerlink" title="Ch12 对话引擎"></a>Ch12 对话引擎</h1><h1 id="Ch13-Scaling-up"><a href="#Ch13-Scaling-up" class="headerlink" title="Ch13 Scaling up"></a>Ch13 Scaling up</h1>]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>Under the hood of PDF</title>
    <url>/2021/04/30/pdf/</url>
    <content><![CDATA[<p>refs:</p>
<ul>
<li>iText in Action</li>
</ul>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>Different parts of PDF file:</p>
<ul>
<li>header</li>
<li>body</li>
<li>cross-reference table</li>
<li>trailer</li>
</ul>
<p>Also, the Carousel Object System.</p>
<h1 id="PDFs-inside-out"><a href="#PDFs-inside-out" class="headerlink" title="PDFs inside-out"></a>PDFs inside-out</h1><p>from a de facto to an ISO standard.</p>
<h2 id="why-and-how"><a href="#why-and-how" class="headerlink" title="why and how?"></a>why and how?</h2><p>1985年，Adobe 引入了 PostScript Page Description Language。同年，Adobe 也开发了 Adobe Illustrator。这两款产品引发了桌面 publishing 的革命。但 Adobe 的创建者们感觉还缺少了点什么。</p>
<p>1991年，John Warnock 写了 Carmelot Paper，在其中写道：</p>
<p>一个特别的问题是，大多数程序可以打印至不同的打印机，但没有一种通用的方式来通信和查看这些打印信息。行业所亟需的是在不同的机器配置、OS、网络之间的通用通信机制。</p>
<p>作为这个文章的结果，一个新项目启动了，<code>Carousel</code> 是初始代号，之后修改为 <code>Acrobat</code>。新文档格式原称为 IPS，很快就改为 PDF（Potable Document Format）。</p>
<h2 id="The-history-of-PDF"><a href="#The-history-of-PDF" class="headerlink" title="The history of PDF"></a>The history of PDF</h2><p>尽管 Carousel 只是最初代号，但现在仍用于表示<strong>PDF文件的组成方式</strong>。在最低层次，iText 使用继承自 <code>PdfObject</code> 的对象，在 Carousel 中，有一系列基础的 PDF 对象。</p>
<h3 id="Basic-PDF-Objects"><a href="#Basic-PDF-Objects" class="headerlink" title="Basic PDF Objects"></a>Basic PDF Objects</h3><p>共有 8 种（ISO-32000-1）。</p>
<ul>
<li>Boolean</li>
<li>Numeric</li>
<li>String</li>
<li>Name</li>
<li>Array</li>
<li>Dictionary</li>
<li>Stream: like a string object, a stream is a sequence of bytes, mainly used for large amounts of data</li>
<li>Null</li>
</ul>
<p>示例：</p>
<ul>
<li>PdfAction, PdfFormField, PdfOutline: 是 PdfDictionary 的子类</li>
<li>PdfRectangle 是 PdfArray 的特殊类型</li>
<li>PdfDate 是 PdfString 的子类</li>
</ul>
<p>这些类型称为 <code>direct</code>。</p>
<h2 id="The-PDF-file-structure"><a href="#The-PDF-file-structure" class="headerlink" title="The PDF file structure"></a>The PDF file structure</h2><p>通过文本编辑器打开一个 pdf 文件，可以看到 pdf 文件包含以下部分：</p>
<ul>
<li>header: version、comment</li>
<li>body：seq of indirect objects: page、outline、annotation</li>
<li>cross-reference: </li>
<li>trailer: loc of the cross ref table and …</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>practical-nlp-text-repr</title>
    <url>/2020/07/13/practical-nlp-text-repr/</url>
    <content><![CDATA[<h1 id="Text-Representation（文本表示）"><a href="#Text-Representation（文本表示）" class="headerlink" title="Text Representation（文本表示）"></a>Text Representation（文本表示）</h1><h2 id="Distributed-Representations（分布式表示）"><a href="#Distributed-Representations（分布式表示）" class="headerlink" title="Distributed Representations（分布式表示）"></a>Distributed Representations（分布式表示）</h2><p>前述几种基本表示法有着明显的缺陷，比如：</p>
<ul>
<li>它们都是离散化表示，即把语言单位（词、ngrams等）视为原子单位，因此不能捕捉到词之间的关系</li>
<li>特征向量是稀疏和高维的表示，维度与词汇表大小一致，从而导致向量的绝大部分元素为0，这一结果不利于学习，也使得计算过程颇为低效</li>
<li>不能有效处理未登录词</li>
</ul>
<p>因此需要能够学习到低维向量表示的新方法，这些方法在过去六七年（2013年开始）中得到了迅速发展。它们使用NN架构创建出稠密（而非稀疏）的、低维（而非高维）的词与文本的表示。了解这些方法之前，需要先了解分布语义学。</p>
<h2 id="Distributional-Semantics（分布语义学）"><a href="#Distributional-Semantics（分布语义学）" class="headerlink" title="Distributional Semantics（分布语义学）"></a>Distributional Semantics（分布语义学）</h2><p>分布语义学是基于语言项（linguistic items）在大量语言数据上的分布性质，对其相关性进行量化与分类的一系列理论与方法。它的基本思想基于所谓的分布假设：具有相似分布的语言项也具有相似的语义。</p>
<h3 id="Distributional-Hypothesis"><a href="#Distributional-Hypothesis" class="headerlink" title="Distributional Hypothesis"></a>Distributional Hypothesis</h3><p>分布假设背后的思想是：”a word is characterized by the company it keeps“（Firth 1950s）。分布假设是统计语义学的基础。</p>
<p>孩子在学习语言时，对于未见过的词，仍然可以正确使用，也是基于此假设（通过已了解词的用法去泛化）。</p>
<h3 id="Distributional-Similarity（分布相似度）"><a href="#Distributional-Similarity（分布相似度）" class="headerlink" title="Distributional Similarity（分布相似度）"></a>Distributional Similarity（分布相似度）</h3><p>它的要义是：词的语义可通过其上下文来理解。</p>
<p>可以理解为：两个词在分布上越相似，其语义即越相似。</p>
<h3 id="Distributional-Representation（分布表示）"><a href="#Distributional-Representation（分布表示）" class="headerlink" title="Distributional Representation（分布表示）"></a>Distributional Representation（分布表示）</h3><p>获取一个词在”分布“意义上的向量表示。</p>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>关于拖延症与意志力</title>
    <url>/2017/06/28/procrastination/</url>
    <content><![CDATA[<p>误区</p>
<ol>
<li>同时做太多事情</li>
<li>过于相信自己的意志力</li>
<li>或期待一种完美的状态，在此状态下，甚至不需要意志力，自己”应该“知道想做什么（而且是100%地知道）</li>
</ol>
]]></content>
      <tags>
        <tag>Life</tag>
        <tag>Procrastination</tag>
      </tags>
  </entry>
  <entry>
    <title>Programming</title>
    <url>/2017/06/23/programming/</url>
    <content><![CDATA[<h2 id="Languages-I-am-living-with"><a href="#Languages-I-am-living-with" class="headerlink" title="Languages I am living with:"></a>Languages I am living with:</h2><ul>
<li>Python</li>
<li>Scala</li>
<li>C#</li>
</ul>
<h2 id="Languages-I-am-falling-in-love-with"><a href="#Languages-I-am-falling-in-love-with" class="headerlink" title="Languages I am falling in love with:"></a>Languages I am falling in love with:</h2><ul>
<li>Racket&#x2F;Scheme</li>
<li>OCaml</li>
<li>Julia</li>
<li>Rust</li>
</ul>
<h2 id="Syntax-Highlits"><a href="#Syntax-Highlits" class="headerlink" title="Syntax Highlits"></a>Syntax Highlits</h2><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Hello, World!&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">HelloWorld</span> <span class="keyword">extends</span> <span class="title">App</span> </span>&#123;</span><br><span class="line">  println(<span class="string">&quot;Hello, World!&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="MathJax"><a href="#MathJax" class="headerlink" title="MathJax"></a>MathJax</h2><h3 id="Inline"><a href="#Inline" class="headerlink" title="Inline"></a>Inline</h3><p><strong>Euler’s identity</strong>: $e^{i \pi} + 1 &#x3D; 0$.</p>
<h3 id="Block-Euler’s-formula"><a href="#Block-Euler’s-formula" class="headerlink" title="Block (Euler’s formula)"></a>Block (Euler’s formula)</h3><p>$$e^{i \pi} &#x3D; cos x + i sin x$$</p>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Fun</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中的协程</title>
    <url>/2019/05/12/python-coroutines/</url>
    <content><![CDATA[<p>本文主要整理自《Fluent Python》的第16章。</p>
<p>David Beazley（又）尝言，协程是py文档中最语焉不详、模糊的，看起来是一个毫无用处的特性。当然，事实并非如此，他写过关于协程与并发的系列文章：<a href="http://www.dabeaz.com/coroutines/">A Curious Course on Coroutines and Concurrency</a>。</p>
<p><code>yield</code>一次在英语中有两个主要含义：产生和让路。在生成器中，这两个含义都适用：每次产生一个值，生成器都会挂起，“让路”给调用者。</p>
<p>协程的语法看起来像是生成器，但协程一般出现在表达式的右边（如<code>datum = yield</code>），它也不一定需要产生一个值。调用者使用<code>.send()</code>时，协程接受到一个值。</p>
<p>甚至可以完全没有数据从<code>yield</code>进出，所以不妨把<code>yield</code>看作<strong>一个流程控制装置</strong>，可用于实现协作式多任务处理：每个协程交出控制给central scheduler，随后其它协程可被激活。</p>
<h1 id="协程的基本操作"><a href="#协程的基本操作" class="headerlink" title="协程的基本操作"></a>协程的基本操作</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> inspect <span class="keyword">import</span> getgeneratorstate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">simple_coro</span>(<span class="params">a</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Started: a =&#x27;</span>, a)</span><br><span class="line">    b = <span class="keyword">yield</span> a</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Received: b =&#x27;</span>, b)</span><br><span class="line">    c = <span class="keyword">yield</span> a + b</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;-&gt; Received: c =&#x27;</span>, c)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">coro = simple_coro(<span class="number">14</span>)</span><br><span class="line"><span class="built_in">print</span>(getgeneratorstate(coro))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(coro))</span><br><span class="line"><span class="built_in">print</span>(getgeneratorstate(coro))</span><br><span class="line"><span class="built_in">print</span>(coro.send(<span class="number">28</span>))</span><br><span class="line"><span class="built_in">print</span>(coro.send(<span class="number">99</span>))</span><br></pre></td></tr></table></figure>

<p>从调用者角度看，它获取数据的方式与生成器类似，但是它同时多了两次<code>send</code>操作，<code>send</code>比<code>next</code>多了一个方向的数据流转，但对于<code>yield</code>，它依然会挂起当前例程（此处为协程），将执行交给调用者。</p>
<h1 id="协程示例：持续计算均值"><a href="#协程示例：持续计算均值" class="headerlink" title="协程示例：持续计算均值"></a>协程示例：持续计算均值</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">averager</span>():</span><br><span class="line">    total, count = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    average = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        term = <span class="keyword">yield</span> average</span><br><span class="line">        total += term</span><br><span class="line">        count += <span class="number">1</span></span><br><span class="line">        average = total / count</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">co = averager()</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">next</span>(co))</span><br><span class="line"><span class="built_in">print</span>(co.send(<span class="number">10</span>))</span><br><span class="line"><span class="built_in">print</span>(co.send(<span class="number">30</span>))</span><br><span class="line"><span class="built_in">print</span>(co.send(<span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<p>实现这一功能不是非得用协程，也可以用类或闭包，但在协程里，total和count都是简单的局部变量。</p>
<p>在上面两个例子中可以看到，使用协程都需要最开始调用一次<code>next</code>，这次操作一般称为“启动”（prime）。每个协程都需要启动，而协程也是函数，所以装饰器就派上用场了。</p>
<h1 id="启动协程的装饰器"><a href="#启动协程的装饰器" class="headerlink" title="启动协程的装饰器"></a>启动协程的装饰器</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">coroutine</span>(<span class="params">func</span>):</span><br><span class="line"><span class="meta">    @wraps(<span class="params">func</span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">primer</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">        gen = func(*args, **kwargs)</span><br><span class="line">        <span class="built_in">next</span>(gen)</span><br><span class="line">        <span class="keyword">return</span> gen</span><br><span class="line">    <span class="keyword">return</span> primer</span><br></pre></td></tr></table></figure>

<h1 id="协程的终止与异常处理"><a href="#协程的终止与异常处理" class="headerlink" title="协程的终止与异常处理"></a>协程的终止与异常处理</h1><p><code>.throw()</code>与<code>.close()</code>。</p>
<h1 id="协程的返回值"><a href="#协程的返回值" class="headerlink" title="协程的返回值"></a>协程的返回值</h1><p>协程是生成器函数，因此可以有返回值，此时协程必须是正常终止的，比如<code>while</code>break之后。</p>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python中的可迭代类型</title>
    <url>/2019/05/10/python-iterables/</url>
    <content><![CDATA[<p>本文主要整理自《Fluent Python》的第14章。</p>
<p>**迭代（iteration）**在数据处理中不可或缺的。当数据在内存中放不下时，我们需要偷一下懒（lazily），每次按需取一个数据项，这就是所谓的迭代器（iterator）模式。</p>
<p>Python 2.2（2001）添加了<code>yield</code>关键字，用以构造<strong>生成器（generator）</strong>，生成器可达成迭代器的效果。而且，在Python社区中，生成器与迭代器同义。</p>
<p>Python中的每个集合（collection）都是<strong>可迭代的（iterable）</strong>。迭代器在内部用于：</p>
<ul>
<li>for 循环</li>
<li>集合类型的构造与扩展</li>
<li>列表等类型的推导</li>
<li>tuple unpacking</li>
<li>*args的unpacking</li>
</ul>
<p>本章涵盖以下主题：</p>
<ul>
<li><code>iter</code>函数</li>
<li>如何实现经典的迭代器模式</li>
<li>生成器工作机制</li>
<li>经典的迭代器可用生成器替代</li>
<li><code>yield from</code>语句</li>
<li>生成器与**协程（coroutine）**看起来相似，本质上却非常不同</li>
</ul>
<h1 id="序列类型1：词序列"><a href="#序列类型1：词序列" class="headerlink" title="序列类型1：词序列"></a>序列类型1：词序列</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> reprlib</span><br><span class="line"></span><br><span class="line">RE_WORD = re.<span class="built_in">compile</span>(<span class="string">&#x27;r\w+&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Sentence</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sentence = sentence</span><br><span class="line">        <span class="variable language_">self</span>.words = RE_WORD.findall(sentence)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.words[item]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.words)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;Sentence(<span class="subst">&#123;reprlib.<span class="built_in">repr</span>(self.sentence)&#125;</span>)&#x27;</span></span><br><span class="line">        </span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    sent = Sentence(<span class="string">&#x27;&quot;The time has come,&quot; the Walrus said,&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(sent)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> sent:</span><br><span class="line">        <span class="built_in">print</span>(word)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">list</span>(sent))</span><br><span class="line">    <span class="built_in">print</span>(sent[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<h2 id="为何序列是可迭代的？"><a href="#为何序列是可迭代的？" class="headerlink" title="为何序列是可迭代的？"></a>为何序列是可迭代的？</h2><p>当解释器对一个对象<code>x</code>进行迭代时，它会自动调用<code>iter(x)</code>，该内置函数会：</p>
<ul>
<li>检查对象是否实现了<code>__iter__</code>，有则调用之，并获取到一个迭代器；</li>
<li>否则检查<code>__getitem__</code>，有则调用之，并创建一个迭代器；</li>
<li>否则抛出<code>TypeError</code></li>
</ul>
<p>因为<strong>序列</strong>都实现了<code>__getitem__</code>，因此它们同时也是可迭代的，而标准库中的序列类型也会同时实现<code>__iter__</code>，我们实现序列类型时也需要如此。</p>
<p>这一处理方式导致了一个有趣的事实：一个iterable的对象不一定满足<code>isinstance(o, abc.Iterable)</code>。判断对象是否可迭代的准确方式是，对其迭代并捕获异常。</p>
<h1 id="可迭代类型与迭代器类型"><a href="#可迭代类型与迭代器类型" class="headerlink" title="可迭代类型与迭代器类型"></a>可迭代类型与迭代器类型</h1><p>可迭代与迭代器的区别是，Python从iterable获取iterator。</p>
<p>下面的例子演示iterator类型的用法，不使用for循环：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = <span class="string">&#x27;abc&#x27;</span></span><br><span class="line">it = <span class="built_in">iter</span>(s)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="built_in">next</span>(it))</span><br><span class="line">    <span class="keyword">except</span> StopIteration:</span><br><span class="line">        <span class="keyword">del</span> it</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure>

<p><code>StopIteration</code>表明迭代器已经迭代结束，在使用for循环时，该异常在其内部被处理掉了。</p>
<p>Iterator接口有两个方法：<code>__next__</code>、<code>__iter__</code>。</p>
<h1 id="序列类型2：生成器函数"><a href="#序列类型2：生成器函数" class="headerlink" title="序列类型2：生成器函数"></a>序列类型2：生成器函数</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Sentence</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sentence = sentence</span><br><span class="line">        <span class="variable language_">self</span>.words = RE_WORD.findall(sentence)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> <span class="variable language_">self</span>.words:</span><br><span class="line">            <span class="keyword">yield</span> word</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.words)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;Sentence(<span class="subst">&#123;reprlib.<span class="built_in">repr</span>(self.sentence)&#125;</span>)&#x27;</span></span><br></pre></td></tr></table></figure>

<p>这个版本的实现里，使用<code>__iter__</code>代替了<code>__getitem__</code>，因此更“地道”的可迭代实现。</p>
<h2 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h2><p>任何含有<code>yield</code>关键字的函数都是<strong>生成器函数（generator function）</strong>，生成器函数的返回值是生成器对象。</p>
<h1 id="序列类型3：更懒一点"><a href="#序列类型3：更懒一点" class="headerlink" title="序列类型3：更懒一点"></a>序列类型3：更懒一点</h1><p>在前两个版本的实现中，<code>__init__</code>会立即计算出所有的words，不管后面会不会用到，为了性能与占用内存计，我们希望类型能“更懒一点”。</p>
<p>使用Python 3时，每当你考虑“有否更懒的方式”，答案一般是肯定的。这里可以使用<code>re.finditer()</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Sentence</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sentence = sentence</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> RE_WORD.finditer(<span class="variable language_">self</span>.sentence):</span><br><span class="line">            <span class="keyword">yield</span> <span class="keyword">match</span>.group()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;Sentence(<span class="subst">&#123;reprlib.<span class="built_in">repr</span>(self.sentence)&#125;</span>)&#x27;</span></span><br></pre></td></tr></table></figure>

<p>修改之后，原来的<code>self.words</code>不再需要。不过，这还不是最短的实现。</p>
<h1 id="序列类型4：生成器表达式"><a href="#序列类型4：生成器表达式" class="headerlink" title="序列类型4：生成器表达式"></a>序列类型4：生成器表达式</h1><p>生成器表达式可以理解为惰性版的列表推导：如果列表推导是一个列表工厂，那么生成器表达式就是一个生成器工厂。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Sentence</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, sentence</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sentence = sentence</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">match</span>.group() <span class="keyword">for</span> <span class="keyword">match</span> <span class="keyword">in</span> RE_WORD.finditer(<span class="variable language_">self</span>.sentence))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__repr__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&#x27;Sentence(<span class="subst">&#123;reprlib.<span class="built_in">repr</span>(self.sentence)&#125;</span>)&#x27;</span></span><br></pre></td></tr></table></figure>

<p>生成器表达式只是语法糖，它们总是可以被替换为生成器函数，只是有时更为方便。</p>
<h1 id="定义自己的range生成器"><a href="#定义自己的range生成器" class="headerlink" title="定义自己的range生成器"></a>定义自己的range生成器</h1><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ArithmeticProgression</span>:</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, begin=<span class="number">0</span>, step=<span class="number">1</span>, end=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.begin = begin</span><br><span class="line">        <span class="variable language_">self</span>.step = step</span><br><span class="line">        <span class="variable language_">self</span>.end = end</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__iter__</span>(<span class="params">self</span>):</span><br><span class="line">        result = <span class="built_in">type</span>(<span class="variable language_">self</span>.begin+<span class="variable language_">self</span>.step)(<span class="variable language_">self</span>.begin)</span><br><span class="line">        forever = <span class="variable language_">self</span>.end <span class="keyword">is</span> <span class="literal">None</span></span><br><span class="line">        index = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> forever <span class="keyword">or</span> result &lt; <span class="variable language_">self</span>.end:</span><br><span class="line">            <span class="keyword">yield</span> result</span><br><span class="line"></span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line">            result = <span class="variable language_">self</span>.begin + <span class="variable language_">self</span>.step * index</span><br></pre></td></tr></table></figure>

<p>这里的<code>__iter__</code>函数只是返回一个生成器，所以这个类实际上可以简化为生成器函数。</p>
<h1 id="标准库中的生成器函数"><a href="#标准库中的生成器函数" class="headerlink" title="标准库中的生成器函数"></a>标准库中的生成器函数</h1><p>这类函数定义在<code>itertools</code>和<code>functools</code>中，分为以下几类：</p>
<h2 id="Filtering"><a href="#Filtering" class="headerlink" title="Filtering"></a>Filtering</h2><ul>
<li>compress：通过一个iterable对另一个过滤；</li>
<li>dropwhile</li>
<li>filter</li>
<li>filterfalse</li>
<li>islice：对任一iterable实施slice操作</li>
<li>takewhile：</li>
</ul>
<h2 id="Mapping"><a href="#Mapping" class="headerlink" title="Mapping"></a>Mapping</h2><ul>
<li>accumulate</li>
<li>enumerate</li>
<li>map</li>
<li>starmap</li>
</ul>
<h2 id="Merging-Generators"><a href="#Merging-Generators" class="headerlink" title="Merging Generators"></a>Merging Generators</h2><ul>
<li>chain</li>
<li>chain.from_iterable</li>
<li>product</li>
<li>zip</li>
<li>zip_longest</li>
</ul>
<h2 id="Expanding-Generators"><a href="#Expanding-Generators" class="headerlink" title="Expanding Generators"></a>Expanding Generators</h2><ul>
<li>combinations</li>
<li>combinations_with_replacement</li>
<li>count</li>
<li>cycle</li>
<li>permutations</li>
<li>repeat</li>
</ul>
<h2 id="Rearranging-Generators"><a href="#Rearranging-Generators" class="headerlink" title="Rearranging Generators"></a>Rearranging Generators</h2><ul>
<li>groupby</li>
<li>reversed</li>
<li>tee</li>
</ul>
<h1 id="yield-from"><a href="#yield-from" class="headerlink" title="yield from"></a>yield from</h1><p>PS：py3.3引入的新语法。</p>
<h1 id="生成器作为协程"><a href="#生成器作为协程" class="headerlink" title="生成器作为协程"></a>生成器作为协程</h1><p>py2.5引入了协程，协程向生成器对象添加了新的方法——主要是<code>.send()</code>。这一“enhancement”实际上改变了生成器的本质：如此一来，它们变成了协程。David Beazley尝言：</p>
<ul>
<li>生成器产生迭代器（用于迭代）</li>
<li>协程是数据的消费者</li>
<li>不要将两个概念混在一起使用</li>
<li>协程与“迭代”无关</li>
</ul>
]]></content>
      <categories>
        <category>Programming</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark SQL</title>
    <url>/2019/05/31/spark-sql/</url>
    <content><![CDATA[<p>RDD是无结构的，Spark 1.6引入了Structured API，后者是多数场景下更为适用。</p>
<p>Spark SQL基于Spark Core，包含两部分：</p>
<ul>
<li>DataFrame &amp; Dataset</li>
<li>Catalyst optimizer</li>
</ul>
<p>结构化数据结构具有<code>schema</code>定义。</p>
<h1 id="Creating-DataFrames"><a href="#Creating-DataFrames" class="headerlink" title="Creating DataFrames"></a>Creating DataFrames</h1>]]></content>
      <categories>
        <category>Apache Spark</category>
      </categories>
      <tags>
        <tag>Apache Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Text Retrieval and Search Engines(1)</title>
    <url>/2017/07/04/text-retrieval-and-search-engines-part-1/</url>
    <content><![CDATA[<p>此文内容整理自Coursera课程<a href="https://www.coursera.org/learn/text-retrieval/home/welcome">文本检索与搜索引擎（Text Retrieval and Search Engines）</a>。</p>
<h1 id="课程结构"><a href="#课程结构" class="headerlink" title="课程结构"></a>课程结构</h1><p><img src="/images/text-retrieval/text-retrieval-course-schedule.png" alt="Course Schedule"></p>
<h2 id="术语表"><a href="#术语表" class="headerlink" title="术语表"></a>术语表</h2><ul>
<li>Text Retrieval（TR）：文本检索</li>
<li>Information Retrieval（IR）：信息检索</li>
<li>Natural Language Processing（NLP）：自然语言处理</li>
<li>Information Need：信息需求</li>
<li>Document：文档</li>
<li>Query：查询</li>
<li>Relevance：相关度</li>
<li>Similarity：相似度</li>
<li>Ranking Function：排序函数</li>
<li>Vector Space Model（VSM）：向量空间模型</li>
<li>Term：关键词（文档中的基本概念），可以是词、短语或ngram等</li>
<li>Bag of Words（BOW）：词袋</li>
<li>Bit Vector：位向量</li>
<li>Dot Product：点积</li>
</ul>
<h1 id="1、文本检索基本概念"><a href="#1、文本检索基本概念" class="headerlink" title="1、文本检索基本概念"></a>1、文本检索基本概念</h1><p>第一部分将涵盖上图中1-5部分的内容。</p>
<h2 id="1-1-自然语言内容的分析"><a href="#1-1-自然语言内容的分析" class="headerlink" title="1.1 自然语言内容的分析"></a>1.1 自然语言内容的分析</h2><p>这无疑是处理任何文本数据的第一步，本节包含三个小主题：</p>
<ul>
<li>什么是NLP？</li>
<li>NLP领域研究的现状</li>
<li>NLP与文本检索</li>
</ul>
<h3 id="1-1-1-什么是NLP？"><a href="#1-1-1-什么是NLP？" class="headerlink" title="1.1.1 什么是NLP？"></a>1.1.1 什么是NLP？</h3><p>来看一个NLP的简单例子：</p>
<p><img src="/images/text-retrieval/an-example-of-nlp.png" alt="An example of NLP"></p>
<p>如果想让计算机理解这个句子，需要哪些步骤呢？类似于人类的理解过程，首先需要知道它包含哪些词，以及各个词的词性。这个过程称为<strong>词法分析</strong>（Lexical analysis）或<strong>词性标注</strong>（Part-of-speech tagging）。</p>
<p>接下来需要了解句子的语法结构，即这些词如何构成更复杂的语法结构。如A和dog构成名词短语，on、the及playground构成介词短语等等。这个过程称为<strong>语法分析</strong>（Syntactic analysis）。</p>
<p>了解了句子的词法结构和语法结构，计算机仍不足以了解句子的意义。这时需要的是<strong>语义分析</strong>（Semantic analysis）。对计算机来说，需要将词和短语这样的成分对应到某些symbol，同时还要有symbol之间的关系，比如上图中的Chasing就是这样一种关系。更进一步，在关系之上，我们还可以进行<strong>推理</strong>（Inference），比如我们有一条规则：如果某实体被狗追，那么该实体会害怕。在此规则下，我们可以推理出一个结论：the boy is scared。</p>
<p>另外还可以考虑，一个人为何说出这样一句话？ta的意图是什么？一种可能是，ta在提醒另一个人把狗牵回来。这个过程称为<strong>Pragmatic analysis</strong>，即分析“语言行为“本身。</p>
<p>计算机要理解一个如此简单的句子都需要很繁琐的过程。人类理解起来要容易得多，这是因为人的大脑早已有了庞大的”知识“库，而计算机则需要从头学起。</p>
<p>直觉上，人类学习语言并非如洛克的”白板论”那样，一个人对于语言的理解应当有相当的部分来自于遗传。总之，对于可怜的计算机而言，NLP是很难的。</p>
<h3 id="1-1-2-NLP是很难的"><a href="#1-1-2-NLP是很难的" class="headerlink" title="1.1.2 NLP是很难的"></a>1.1.2 NLP是很难的</h3><p>”自然语言“当然是为人类的有效沟通而设计，其结果是：我们会大量的”<strong>常识</strong>“内容，并假设听者或读者是能够理解的；语言中存在大量的<strong>歧义</strong>（ambiguity），我们假设听者或读者能够仔细理解之。</p>
<p>当一个人缺乏<strong>常识</strong>，与ta沟通起来会感觉困难。对NLP来说，以Siri之类的应用为例，我们的感觉不是与它很难沟通，而是完全无法沟通。当一个人说的话有<strong>歧义</strong>，人类也会觉得理解起来有困难，拿不准其准确含义，遑论计算机了。所以，常识的缺乏和歧义使得NLP格外困难。</p>
<p>歧义的常见情况有：</p>
<ul>
<li>词的歧义：不同词性；多义词；</li>
<li>语法结构的歧义：修饰语与被修饰语的不同结合；介词短语附着（PP Attachment），”A man saw a boy <em>with a telescope</em>；</li>
<li>首语重复（Anaphora）解析：John persuaded Bill to buy a TV for <em>himself</em>；</li>
<li>预先假定（Presupposition）：”He has quit smoking”暗示他曾吸过烟。</li>
</ul>
<h3 id="1-1-3-NLP研究现状"><a href="#1-1-3-NLP研究现状" class="headerlink" title="1.1.3 NLP研究现状"></a>1.1.3 NLP研究现状</h3><p><img src="/images/text-retrieval/state-of-the-art-nlp.png" alt="State of the Art NLP"></p>
<p>词性标注准确率较高；语法解析层面，部分解析（Partial Parsing，即句子的一部分，如短语级别）达到90%以上。</p>
<p>语义解析的进展则相当不好。不过在某些特定应用上取得了一些进展，如实体识别、关系提取、情感分析。</p>
<p>推理和语言行为方面的表现则是更差。</p>
<p>值得一提的是，尽管说词性标注和部分解析的准确率已经达到较高的程度，但这些评测都是基于特定的测试数据集，此类测试集常常是新闻类数据，这会导致一定的偏差。因此相应的算法应用到不同领域中可能未必有同样好的效果。</p>
<h3 id="1-1-4-NLP与文本检索"><a href="#1-1-4-NLP与文本检索" class="headerlink" title="1.1.4 NLP与文本检索"></a>1.1.4 NLP与文本检索</h3><p>文本检索通常涉及大量而广泛的文本，如果希望其中的NLP技术是健壮和高效的，那么目前来看只能采用浅层的NLP。文本的<strong>词袋</strong>（Bag of Words）表示是最简单的一种，它无疑丢弃了文本的大量信息，但对于大部分（不是全部）搜索任务而言却是够用的。</p>
<p>某些文本检索技术可以自然地解决NLP问题，如语义消歧。</p>
<p>但是，对于复杂的搜索任务，更深层的NLP技术仍是必需的，比如<strong>知识图谱</strong>（Knowledge Graph）。</p>
<h2 id="1-2-文本访问"><a href="#1-2-文本访问" class="headerlink" title="1.2 文本访问"></a>1.2 文本访问</h2><p>一个文本信息系统该如何让用户访问到他们关心的（或相关的，relevant）数据？这里主要考虑两种模式。</p>
<ul>
<li>Pull模式（搜索引擎）：由用户发起。用户在系统中根据特定的需求开始查询，并浏览相应的结果。此时的需求往往是临时性的，比如查询某个术语、某个作者或一类商品的信息。这种情形下，系统很难预知用户的需求，因此Pull模式较为适合。</li>
<li>Push模式（推荐系统）：由系统发起。如果用户有某种较固定的需求，而且系统对用户比较了解，那么系统可以主动向用户push信息。比如Pocket app在用户使用一段时间后，可以向用户推荐其感兴趣的文章。</li>
</ul>
<p>在pull模式下，也存在两种不同的方式：</p>
<ul>
<li>Querying：用户对自己的需求比较清楚，知道该如何查询。比如当我们知道书名或作者名时，可以直接查询。</li>
<li>Browsing：用户对需求不甚清楚，希望先在系统中漫游一番。当我们遇到某书店的打折信息，满200减100，但暂时并没有特定要买的书，这时往往从分类或主题开始浏览。</li>
</ul>
<p>尽管说Browsing属于pull模式，但仔细想想，当用户不太清楚想要什么时，不正是推荐系统发挥作用的地方吗？</p>
<h2 id="1-3-TR中的问题"><a href="#1-3-TR中的问题" class="headerlink" title="1.3 TR中的问题"></a>1.3 TR中的问题</h2><p>本节包含三个小主题：</p>
<ul>
<li>什么是文本检索？</li>
<li>文本检索 vs. 数据库检索</li>
<li>文档选择（Selection） vs. 文档排序（Ranking）</li>
</ul>
<h3 id="1-3-1-什么是文本检索？"><a href="#1-3-1-什么是文本检索？" class="headerlink" title="1.3.1 什么是文本检索？"></a>1.3.1 什么是文本检索？</h3><p>对于使用过搜索引擎的人来说，这甚至算不上是一个问题：）</p>
<p>系统已收集大量（具体的量级视具体问题而定）文档。用户发起查询，表达自己的<strong>信息需求</strong>（Information Need）。系统返回相关文档给用户。这就是high level的文本检索过程。</p>
<p>文本检索也被称为<strong>信息检索</strong>（Information Retrieval，IR），但实际上IR的范围更广，因为其数据可能是非文本的。文本检索在业界被称为“搜索技术”。</p>
<h3 id="1-3-2-文本检索-vs-数据库检索"><a href="#1-3-2-文本检索-vs-数据库检索" class="headerlink" title="1.3.2 文本检索 vs. 数据库检索"></a>1.3.2 文本检索 vs. 数据库检索</h3><p>这里将两者简称为TR和DR，并从不同的角度来看：</p>
<ol>
<li>信息：TR是非结构化的、模糊的；DR是结构化的、具有良好语义的；</li>
<li>查询：TR是模糊的、不完整的；DR是具有良好语义的、完整的；</li>
<li>返回结果：TR是<strong>相关的文档</strong>，DR是<strong>匹配的记录</strong>；</li>
<li>TR是基于经验的，不能以数学的方式精确判断一直方法的好坏，因此需要借助于用户的介入以评测方法的表现。比如通过用户对于查询结果的后续操作来判断其好坏。</li>
</ol>
<p>下图是TR的正式定义：</p>
<p><img src="/images/text-retrieval/formal-formulation-of-tr.png" alt="Formal formulation of TR"></p>
<p><code>R(q)</code>是一次用户查询的相关文档构成的集合，但一般情况下，它是不可知的，同时也依赖于具体的用户。在此前提下，我们的任务是<strong>计算它的近似值</strong>。</p>
<h3 id="1-3-3-文档选择-vs-文档排序"><a href="#1-3-3-文档选择-vs-文档排序" class="headerlink" title="1.3.3 文档选择 vs. 文档排序"></a>1.3.3 文档选择 vs. 文档排序</h3><p>上述任务的两种策略是：</p>
<ul>
<li>文档选择：通过某个函数或二元分类器来确定一个文档是否属于目标集合。对于<code>C</code>中的每一个文档，它的结果只能是属于或不属于。这里的结果是<strong>绝对相关度</strong>（absolute relevance）。</li>
<li>文档排序：选择某个相关度度量函数，对每个文档判断它在多大程度上与当前用户查询是相关的。这里的结果是<strong>相对相关度</strong>（relative relevance）。</li>
</ul>
<p>文档选择必须要严格确定出，一个文档是否是相关的；而文档排序则只需要给出相对的相关对，由用户来决定阈值。现实中，后者也确实更可取的方法。</p>
<p>文档选择法存在固有的问题。其分类器很难达到特别准确的程度，要么过于严格而返回过少的文档，要么过于宽松而返回过多的文档。另一方面，即使它是准确的，所返回的”相关文档“的相关度理应是不同的，而分类器没办法确定出来。</p>
<p>文档排序法的依据来自于<strong>概率排序原理</strong>（Probability ranking principle），即在如下两个假设下，按文档对于查询的相关度降序排列的列表是最佳策略：</p>
<ul>
<li>文档对于用户的价值（utility）相互之间是不相关的</li>
<li>用户会顺序浏览结果</li>
</ul>
<p>实际上，这两个假设都不一定为真。比如，如果两个文档内容接近，那么用户看过一个后，对于第二个就没有太大兴趣了；用户会跳过部分文档。这两种情况在使用Google之类的搜索引擎时都会遇到。</p>
<h2 id="1-4-文本检索方法"><a href="#1-4-文本检索方法" class="headerlink" title="1.4 文本检索方法"></a>1.4 文本检索方法</h2><p>文本检索的定义可见于1.3.2中的图片。简言之，我们需要找到一个合适的<strong>排序函数</strong>（ranking function）。当前常见的检索模型有：</p>
<ul>
<li>基于相似度（similarity）的模型：Vector space model</li>
<li>概率模型：经典概率模型；Language model；Divergence-from-randomness模型</li>
<li>Probabilistic inference model</li>
<li>Axiomatic model</li>
</ul>
<p>本课程主要涉及<strong>向量空间模型</strong>（VSM）和语言模型（Language model）。有趣的是，尽管上述诸方法的思路颇不相同，但其最终的模型形式却是很相似的。</p>
<p>那么，哪一种模型是最好的？答案是，在优化之后，下面几种模型的表现同样好：</p>
<ul>
<li>Pivoted length normalization</li>
<li>BM25</li>
<li>Query likelihood</li>
<li>PL2</li>
</ul>
<p>BM25是其中最流行。这些模型涉及到的重要概念有：词袋表示、TF、DF和文档长度。</p>
<h2 id="1-5-向量空间模型"><a href="#1-5-向量空间模型" class="headerlink" title="1.5 向量空间模型"></a>1.5 向量空间模型</h2><p>VSM是基于相似度的一种模型。所谓基于相似度，是指它以文档和查询之间的<strong>相似度</strong>来度量<strong>相关度</strong>。</p>
<p>为计算相似度，我们把文档和查询都<strong>表示为向量空间中的向量</strong>，如下图所示：</p>
<p><img src="/images/text-retrieval/vsm.png" alt="Vector space model"></p>
<p>文档$d_1$表示为Library和Presidential两个关键词（term），$d_2$表示为Programming和Library两个term（很可能，这里的Library是指编程中的”库“），而查询$q$看起来与$d_2$最相似，那么按VSM模型，与该查询相关度最高的文档是$d_2$。</p>
<p>下面给出VSM更正式的定义。VSM是一个框架：</p>
<ul>
<li>将文档和查询表示为term vector<ul>
<li>Term：关键词（文档中的基本概念），可以是词、短语或ngram</li>
<li>每个term定义为一个维度</li>
<li>N个term就定义了一个N维空间</li>
<li>查询向量：$q &#x3D; (x_1, \dots, x_N), x_i \in R$，这里的$x_i$表示查询在相应维度上的权重（weight）</li>
<li>文档向量：$d &#x3D; (y_1, \dots, y_N), y_i \in R$，这里的$y_i$表示文档在相应维度上的权重（weight）</li>
</ul>
</li>
<li>相关度$relevance(q, d)$转化为$similarity(q, d) &#x3D; f(q, d)$</li>
</ul>
<p>之所以说VSM是一个框架，是因为这里实际上没有给出任何与具体实现相关的细节。要找到这里的$f$我们还需要考虑：</p>
<ul>
<li>如何定义或选择关键词？<ul>
<li>它们需要是正交的（orthogonal）</li>
</ul>
</li>
<li>如何为查询和文档向量设置合适的权重？</li>
<li>如何度量相似度？</li>
</ul>
<h2 id="1-6-VSM的最简单实现"><a href="#1-6-VSM的最简单实现" class="headerlink" title="1.6 VSM的最简单实现"></a>1.6 VSM的最简单实现</h2><p>VSM的最简单实现是位向量（Bit Vector），即用一个布尔值表示一个term是否出现在了文档中。如果term$w_i$未出现，那么$y_i &#x3D; 0$，否则$y_i &#x3D; 1$。而查询也以同样的方式表示。</p>
<p>这种方式的特点之一是，它忽略了一个term在文档中出现的具体次数。另外，当文档集较大（一般都是如此）时，向量维度变得较高，从而使得文档和查询的向量变得很稀疏，即出现大量的0。</p>
<p>这样，文档与查询的相似度可表示为两者向量的<strong>点积</strong>（Dot Product）：</p>
<p>$$Sim(q, d) &#x3D; q.d &#x3D; \sum_{i&#x3D;1}^{N}x_i y_i$$</p>
<p><img src="/images/text-retrieval/bit-vector.png" alt="Vector space model"></p>
<p>在这个例子中，$V$表示文档集中所有term构成的”词汇表“。然后我们列出查询与文档的位向量，然后计算其点积。从结果来看，d2的相似度高于d1。看起来还蛮合理的，这就是我们”最简单的VSM“，它可以总结为：BOW + Bit Vector + Dot Product，编程实现足够简单，只要一个类似于jieba之类的分词工具即可。</p>
<p>那么这里点积的结果作何解释呢？点积的计算结果恰好表示了，同时出现在文档和查询中的term的数量。虽然它有时比较合理，但也会产生一些问题。比如，它只计数共同出现的term数量，数量相同的就没法区分了，也就是说对所有term一视同仁，这与我们的直觉不符，因为某些term应该是更重要的，而像the、about这样的term则不能对相似度提供什么帮助。</p>
<p>后续的课程会介绍不这么简单的VSM：）</p>
]]></content>
      <categories>
        <category>Text Retrieval</category>
        <category>Information Retrieval</category>
      </categories>
      <tags>
        <tag>Text Retrieval</tag>
        <tag>Information Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title>spacy</title>
    <url>/2019/08/15/spacy/</url>
    <content><![CDATA[<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>spaCy的核心数据结构是<code>Doc</code>和<code>Vocab</code>。<code>Doc</code>对象持有<strong>token序列</strong>及其标注（annotation）信息，<code>Vocab</code>对象则持有一个<strong>查找表（look-up table）</strong>，从而可在文档间共享信息。集中管理字符串、词向量与词法属性，避免了反复copy数据。</p>
<p>文本标注也是类似，<code>Doc</code>持有数据，<code>Span</code>和<code>Token</code>只是它的视图。<code>Doc</code>由<code>Tokenizer</code>构建，之后通过pipeline原地修改（modified in place）。<code>Language</code>对象协调以上诸组件，它接受原始文本，将其送入pipeline，返回一个标注了的文档，同时也参与了模型训练和序列化过程。</p>
<h2 id="容器对象"><a href="#容器对象" class="headerlink" title="容器对象"></a>容器对象</h2><ul>
<li>Doc：包含语言标注的容器</li>
<li>Span：表示Doc的一个切片</li>
<li>Token：单个token，如词、标点、空格等</li>
<li>Lexeme：词位，词汇表的一个entry，不带任何上下文信息，因此也没有POS。</li>
</ul>
<h2 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h2><ul>
<li>Language</li>
<li>Tokenizer</li>
<li>Lemmatizer</li>
<li>Tagger</li>
<li>Matcher</li>
<li>PhraseMatcher</li>
<li>EntityRuler</li>
<li>…</li>
</ul>
<h2 id="其它类"><a href="#其它类" class="headerlink" title="其它类"></a>其它类</h2><ul>
<li>Vocab</li>
<li>StringStore</li>
<li>Vectors</li>
<li>…</li>
</ul>
]]></content>
      <categories>
        <category>NLP</category>
      </categories>
      <tags>
        <tag>NLP, Spacy</tag>
      </tags>
  </entry>
  <entry>
    <title>RDDs and in Spark</title>
    <url>/2019/05/31/spark-rdds/</url>
    <content><![CDATA[<h1 id="Rich-Set-of-Operations"><a href="#Rich-Set-of-Operations" class="headerlink" title="Rich Set of Operations"></a>Rich Set of Operations</h1><p>RDD提供了丰富的数据处理操作API，如transformation、filtering、grouping、joining、aggregation、sorting和counting。</p>
<p>PS：这些操作均是粗粒度的（coarse-grained），即同一操作被应用于多行，而非特定的一行。</p>
<p>RDD表示对数据的抽象，包含五部分信息：</p>
<ul>
<li>partition集合，亦为整个数据集的chunk；</li>
<li>对父级RDD的依赖关系</li>
<li>对所有row进行计算的函数</li>
<li>partition scheme的元数据</li>
<li>集群中数据的位置信息</li>
</ul>
<p>Spark使用前三种信息以实现：确定RDD执行的顺序；失败恢复。</p>
<h1 id="RDD-Operations"><a href="#RDD-Operations" class="headerlink" title="RDD Operations"></a>RDD Operations</h1><p>RDD操作是粗粒度的，每一row表示为一个Java对象。Spark不关心row的结构，RDD的使用者负责如何处理每一行。更高层次的抽象如Spark SQL则在此基础上提供了其它计算。</p>
<p>RDD操作可分为两类：</p>
<ul>
<li>Transformation（lazy）：一个新的RDD</li>
<li>Action（eager）：返回结果或将结果写入磁盘</li>
</ul>
<h1 id="Creating-RDDs"><a href="#Creating-RDDs" class="headerlink" title="Creating RDDs"></a>Creating RDDs</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> strs = <span class="type">Array</span>(<span class="string">&quot;Spark&quot;</span>, <span class="string">&quot;RDDs&quot;</span>)</span><br><span class="line"><span class="keyword">val</span> strRDD = spark.sparkContext.parallelize(strs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> fileRDD = spark.sparkContext.textFile(<span class="string">&quot;/dev/spark-2.4.3-bin-hadoop2.7/README.md&quot;</span>)</span><br></pre></td></tr></table></figure>

<h1 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h1>]]></content>
      <categories>
        <category>Apache Spark</category>
      </categories>
      <tags>
        <tag>Apache Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Text Retrieval and Search Engines(2)</title>
    <url>/2017/07/09/text-retrieval-and-search-engines-part-2/</url>
    <content><![CDATA[<p>此文内容整理自Coursera课程<a href="https://www.coursera.org/learn/text-retrieval/home/welcome">文本检索与搜索引擎（Text Retrieval and Search Engines）</a>。<a href="https://anderscui.github.io/2017/07/04/text-retrieval-and-search-engines-part-1/">Part 1笔记在此</a></p>
<p>这一部分将更详细地了解VSM，考虑它的不同优化思路，以及借助于倒排索引实现信息检索系统（即搜索引擎）。</p>
<p>主要概念：</p>
<ul>
<li>关键词词频（Term Frequency，TF）</li>
<li>文档频率（Document Frequency，DF）与逆向文档频率（Inverse DF， IDF）</li>
<li>TF transformation</li>
<li>Pivoted length normalization</li>
<li>BM25</li>
<li>倒排索引（Inverted Index）与posting</li>
<li>Binary coding，unary coding，gamma-coding和d-gap</li>
<li>Zipf法则</li>
</ul>
<p>在<a href="https://anderscui.github.io/2017/07/04/text-retrieval-and-search-engines-part-1/">Part 1</a>中介绍了”最简单的VSM“（以下简称SVSM），看下图，考虑该模型是否存在问题？</p>
<p><img src="/images/text-retrieval/problems-of-svsm.png" alt="Two Problems of the SVSM"></p>
<p>三个文档的相似度计算结果相同，但直觉上，它们应当是有差别的，比如：</p>
<ul>
<li>d4匹配到了更多关键词，应获得更高的相似度</li>
<li>d2的匹配关键词中有一个是about，d3中则有presidential，d3应该与查询更相似</li>
</ul>
<p>出现这两个问题，是因为我们使用了词袋模型和位向量，首先词频被忽略，这样高频词对相似度的贡献被忽略，接着关键词之间也被同等看待，原本贡献更高的词也泯然众“词”矣。要改进模型，可以从这两方面入手。</p>
<p>先把词频（TF）考虑进去，得到如下的向量表示法：</p>
<p><img src="/images/text-retrieval/add-tf-to-svsm.png" alt="Two Problems of the SVSM"></p>
<p>这个新的相似度计算方式可以如何解释？它是否解决了上面的两个问题？</p>
<p>计入词频后，高频词相比于低频词对相似度的贡献会更大，这符合我们的直觉。因为一个文档内，词的频率越高，它就更可能作为该文档的“主题”，而如果一个词频率太低，说不定只是凑巧“混”进了文档而已。</p>
<p>现在重新计算上面的三个文档，会发现$f(q, d2) &#x3D; 3$，$f(q, d3) &#x3D; 3$，$f(q, d4) &#x3D; 4$，它的相似度确实比d2和d3高了，而。这样我们解决了第一个问题，但第二个问题依然存在。</p>
<p>如何给不同的词赋予不同的权重呢？为什么我们会认为presidential要比about重要呢？大致可以这样理解，对于about或the这样的词，它们有很高的频率出现在各种不同主题的文档中，那么查询和文档同时出现这样的词——我们不会感到意外。可以说它们携带的信息很少，不足以区分不同的文档。但presidential就很不一样，介绍信息检索的文章（本文除外）很少会出现。</p>
<p>about这样的词，常常被称为<strong>停用词</strong>（Stopword）。我们可以考虑用某种方法来“惩罚”停用词。不过首先的问题是，如何确定哪些词属于停用词？可以统计整个文档集的所有词，如果一个词出现在了很高比例的文档中（如80%），那么它很可能是停用词。另一方面，对于像presidential这样的词，我们考虑“奖励”它，因为它们可以更好地区分文档。实现这里惩罚和奖励的常见方法是<strong>逆向文档频率</strong>（IDF）。标准的IDF实现如下：</p>
<p><img src="/images/text-retrieval/idf.png" alt="IDF"></p>
<p>$M$是文档集中的文档数量，$k$是包含词$W$的文档总数，即DF，取到数后就成了IDF。通过函数图像（曲线）可知，一个词出现在越多的文档中，其IDF越低，即得到了越多的惩罚，反之出现在越少的文档中，则会得到奖励。</p>
<p>当$k$很小时，IDF值很大，也就是说如果一个词只出现在了少数几个文档中，那么他们就会有很高的权重。当$k$逐渐增大时，IDF下降得很快，直到越过中间的转折点后，IDF就变得相当小，此时该词对于相似度而言就不甚重要了。对于about这样的词，$k$可能是接近于$M$的，它的IDF值接近于$0$。</p>
<p>引入IDF后，文档的向量公式变为：</p>
<p>$$d &#x3D; (y_1, \cdots, y_N，y_i &#x3D; c(W_i, d) * IDF(W_i)$$</p>
<p>这时再计算的话，d3的相似度就高于d2了，这样就解决了问题2。然而新的问题又出现了，看下图，d5的相似度好像有点过高了，如何解决呢：</p>
<p><img src="/images/text-retrieval/vsm-after-tfidf.png" alt="VSM after TFIDF"></p>
]]></content>
      <categories>
        <category>Text Retrieval</category>
        <category>Information Retrieval</category>
      </categories>
      <tags>
        <tag>Text Retrieval</tag>
        <tag>Information Retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 微分</title>
    <url>/2017/07/23/thomas-calculus-derivative/</url>
    <content><![CDATA[<p>《<a href="https://book.douban.com/subject/1231399/">托马斯微积分</a>》，以前看过前八章，内容大致包括导数、积分和无穷级数。最近想更系统的学习数学分析，从本书开始，先补完后面几章，尤其是多元函数的微分和重积分，然后是科朗的《<a href="https://book.douban.com/subject/1281343/">微积分和数学分析引论</a>》，增强一下理论基础。</p>
<p>另外，edX上有公开课<a href="https://courses.edx.org/courses/course-v1:MITx+18.01.1x+2T2017/info">18.01.1x Calculus 1A: Differentiation</a>，它源自更早的<a href="https://ocw.mit.edu/courses/mathematics/18-01sc-single-variable-calculus-fall-2010/">MIT 18.01 on OCW</a>，后者在网易公开课上早已有翻译。大概浏览过一遍，其思路与托马斯微积分接近。从数学上来说强调直观理解，难度不算高，适合自学。但如果想获得关于微积分的坚实理论基础，托马斯微积分和公开课无疑是缺失了很多的。</p>
<p>所以这一关于微积分的系列文章，将从两种角度来了解微积分，先从托马斯微积分开始，之后是科朗的。</p>
<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><ul>
<li>了解函数、参数方程的概念</li>
<li>以函数或参数方程为现实世界的问题建立模型</li>
</ul>
<h2 id="直线"><a href="#直线" class="headerlink" title="直线"></a>直线</h2><h3 id="增量"><a href="#增量" class="headerlink" title="增量"></a>增量</h3><p><strong>定义</strong>：当平面上一个质点从一点移动到另一点，其坐标的纯改变或增量通过把终点坐标减去起点坐标而求得。从点$(x_1, y_1)$到$(x_2, y_2)$，其坐标增量为：</p>
<p>$$\Delta x &#x3D; x_2 - x_1, \Delta y &#x3D; y_2 - y_1$$</p>
<p>后面会多次看到“增量”的使用。</p>
<h3 id="斜率（Slope）"><a href="#斜率（Slope）" class="headerlink" title="斜率（Slope）"></a>斜率（Slope）</h3><p>每条非垂直的直线$L$都有斜率（垂直于$x$轴的就“不斜”了），若$(x_1, y_1)$和$(x_2, y_2)$是$L$上两点，那么$L$的斜率是：$\frac{\Delta y}{\Delta x}$。</p>
<p>斜率的直接意义是，$x$每行进单位距离时，高度的变化。又可以看做直线与横轴夹角的正切值，这也从另一方面说明垂直于横轴的直线没有斜率。</p>
<p>注意：斜率对于“导数”的定义有着根本的重要性，导数的几何意义即曲线在一点的切线斜率。</p>
<h3 id="方程"><a href="#方程" class="headerlink" title="方程"></a>方程</h3><ul>
<li>点斜式：$y &#x3D; m(x - x_1) + y_1$</li>
<li>斜截式：$y &#x3D; mx + b$</li>
<li>一般式：$Ax + By &#x3D; C$，（$A$和$B$不全为0）</li>
</ul>
<p>点斜式和斜截式预设了斜率是存在的，一般式不是，但前两种使用起来更方便。</p>
<p>点$(a, b)$到直线$Ax + By &#x3D; C$的距离是：$\frac{|Aa + Bb - C|}{\sqrt{A^2+B^2}}$</p>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>可使用scikit-learn或R之类的工具。</p>
<h2 id="函数与图形"><a href="#函数与图形" class="headerlink" title="函数与图形"></a>函数与图形</h2><h3 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h3><p>定义：从集合$D$到集合$R$的一个函数是对$D$中每个元素指定$R$中唯一确定的元素的一种<strong>规则</strong>。</p>
<p>我最喜欢的数学家<strong>欧拉（Leonhard Euler）<strong>首先使用一种符号表示函数的方法：$y &#x3D; f(x)$。这也是我们最熟悉的一种记法了。根据函数的定义，函数本质上由</strong>规则</strong>与<strong>定义域</strong>决定，因为一旦二者确定，其值域也就确定下来了。这也符合<strong>自变量</strong>和<strong>因变量</strong>两个名称的含义。</p>
<h3 id="基本性质"><a href="#基本性质" class="headerlink" title="基本性质"></a>基本性质</h3><ul>
<li>单调性：增函数、减函数</li>
<li>奇偶性：奇函数、偶函数，注意两者图像之特征</li>
</ul>
<h3 id="分段函数"><a href="#分段函数" class="headerlink" title="分段函数"></a>分段函数</h3><p>绝对值函数$y &#x3D; |x|$定义如下：</p>
<p>$$[ f(n) &#x3D;<br>  \begin{cases}<br>    -x &amp; \quad \text{if } x &lt; 0\<br>    x  &amp; \quad \text{if } x \geq 0 \<br>  \end{cases}<br>]$$</p>
<p>该函数定义颇简单，但可作为连续而不可导的基本示例。$|x|$等价于$\sqrt{x^2}$。绝对值相关的一个基本不等式是：$|a + b| \leq |a| + |b|$。</p>
<h3 id="函数图像的移位"><a href="#函数图像的移位" class="headerlink" title="函数图像的移位"></a>函数图像的移位</h3><ul>
<li>水平移位：$y &#x3D; f(x + h)$与$y &#x3D; f(x)$的关系</li>
<li>垂直移位：$y &#x3D; f(x) + k$与$y &#x3D; f(x)$的关系</li>
</ul>
<h3 id="复合函数"><a href="#复合函数" class="headerlink" title="复合函数"></a>复合函数</h3><p>复合函数无处不在，毕竟基本函数就那么几个。</p>
<h2 id="指数函数"><a href="#指数函数" class="headerlink" title="指数函数"></a>指数函数</h2><p>在科学和工程应用中<strong>指数函数</strong>$y &#x3D; a^x$特别重要。其中对自然、物理和经济现象的建模中用到的最重要的指数函数是<strong>自然指数函数</strong>$y &#x3D; e^x$，后面将会看到为何该函数是”自然的“。</p>
<p>存款的复利是指数增长的一个例子，碳-14原子的衰减是放射性衰减的一个例子。</p>
<h2 id="反函数与对数函数"><a href="#反函数与对数函数" class="headerlink" title="反函数与对数函数"></a>反函数与对数函数</h2><p>如果一个函数是<strong>一对一</strong>的，那么可以定义其反函数，即原函数规则的<strong>逆</strong>。反函数与原函数的图像关于直线$y &#x3D; x$对称。反函数与原函数的复合函数形成<strong>恒等式</strong>。</p>
<p>指数函数的反函数称为<strong>对数函数</strong>。两个重要的恒等式：</p>
<p>$$a^{log_a x} &#x3D; x, log_a a^x &#x3D; x$$</p>
<p>对数的乘积法则、商法则、幂法则和换底公式都是很常用的。</p>
<p>速算技巧：70法则：$ln2 \approx 0.70$，如果连续复利率为$r%$，那么其翻倍的年数为$\frac{70}{r}$。</p>
<h2 id="三角函数"><a href="#三角函数" class="headerlink" title="三角函数"></a>三角函数</h2><p>由于三角函数的周期性，很多自然发生的<strong>周期过程</strong>可以用三角函数建模，如脑电波、心跳、家用的电流与电压，有强烈的证据表明冰河期是周期性的，其周期为9万年到10万年。</p>
<p>进一步地，一个令人惊讶且优美的高等微积分的定理（哪一个呢？）说明，每个周期函数都可以表示为正弦与余弦的代数组合。</p>
<p>一般的三角函数的图像往往是基本三角函数的移位、伸缩、反射。</p>
<h2 id="参数方程"><a href="#参数方程" class="headerlink" title="参数方程"></a>参数方程</h2><p>有时候一条曲线不能用形如$y &#x3D; f(x)$的形式表示，但可以借助于<strong>参数</strong>变量描述。</p>
<p>定义：如果$x$和$y$由$t$值的区间上的函数<br>$$x &#x3D; f(t), y &#x3D; g(t)$$<br>给出，那么由这些方程定义的点集$(x, y) &#x3D; (f(t), g(t))$是一条<strong>参数曲线</strong>。方程称为曲线的<strong>参数方程</strong>。</p>
<p>例：$x &#x3D; acost, y &#x3D; bsint, 0 \leq t \leq 2 \pi$，定义了一个椭圆。</p>
<h1 id="极限和连续"><a href="#极限和连续" class="headerlink" title="极限和连续"></a>极限和连续</h1><p>极限无疑是微积分诸概念的基础，是微积分有别于初等代数与三角的诸多概念之一。</p>
<h2 id="变化率和极限"><a href="#变化率和极限" class="headerlink" title="变化率和极限"></a>变化率和极限</h2><h3 id="平均变化率"><a href="#平均变化率" class="headerlink" title="平均变化率"></a>平均变化率</h3><p>运动物体在一段时间内的平均速度是我们熟悉的概念，应该在小学时就接触到了。以<strong>自由落体运动</strong>为例，物体位移与时间的关系为$y &#x3D; \frac{1}{2}gt^2$。依此可知，物体在一段时间行进距离和平均速度。如果时间改变量$\Delta t$很小，那么我们可以认为物体在某一<strong>时刻</strong>的速度大致是多少。事实上，汽车时速表的**瞬时速度（当前速度）**即是以这种方式计算得来。</p>
<p>平均速度涉及到函数的<strong>平均变化率</strong>：</p>
<p>定义：$y &#x3D; f(x)$关于$x$在区间$[x_1, x_2]$上的平均变化率是：</p>
<p>$$\frac{\Delta y}{\Delta x} &#x3D; \frac{f(x_2) - f(x_1)}{x_2 - x_1} &#x3D; \frac{f(x_1+h) - f(x_1)}{h}$$</p>
<p>几何上，平均变化率就是割线的斜率。注意，这里数学上的平均变化率在几何上和物理上分别对应到了割线斜率和平均速度。那么瞬时速度对应到什么呢？由上面介绍可知，它的近似值是当$\Delta t$很小很小时的平均速度，但”很小很小“显然不是一个严谨的术语，要给出瞬时速度的严格定义，需要借助于<strong>极限</strong>的概念。</p>
<h3 id="函数的极限"><a href="#函数的极限" class="headerlink" title="函数的极限"></a>函数的极限</h3><p>考虑下面函数在$x &#x3D; 1$附近的性态：</p>
<p>$$f(x) &#x3D; \frac{x^2 - 1}{x - 1}$$</p>
<p>此函数在$x &#x3D; 1$处无定义，对于$x \neq 1$则可以简化为$f(x) &#x3D; x + 1$，因此$f$的图形就是抠掉了点$(1, 2)$的直线$y &#x3D; x + 1$。</p>
<p>尽管$f(1)$无定义，但我们仍可以说，当$x$<strong>充分靠近</strong>1时，函数值能够<strong>任意靠近</strong>2。换言之，不管你希望$f(x)$多么靠近，通过选择足够靠近1的$x$，就是可以做到的。由此例可引出一般的<strong>极限的非正式定义</strong>：</p>
<p>设$f(x)$除了可能在点$x_0$没有定义外，在$x_0$的一个开区间内均有定义。如果对充分靠近$x_0$的$x$，$f(x)$能够任意靠近$L$，那么我们就说当$x$趋于$x_0$时$f$趋于极限$L$，记作：</p>
<p>$$\lim_{x \to x_0} f(x) &#x3D; L$$</p>
<p>这里用到了<strong>充分靠近</strong>和<strong>任意靠近</strong>这样的词，很不严谨，因此说是<strong>非正式定义</strong>，但我们通过上例可以得到直观的概念。值得特别注意的是，极限的判断与求值与$x_0$处是否有定义及值为多少没有任何关系。</p>
<p>极限的定义中，要求函数值要能够任意靠近某值，若当$x \to x_0$时，不能满足这一点，那么极限就不存在了。常见的几种情况是：</p>
<ul>
<li>函数跳跃：如单位阶梯函数、下取整函数</li>
<li>函数无限增大：如$y &#x3D; 1&#x2F;x$</li>
<li>振荡：如$y &#x3D; sin \frac{1}{x}$</li>
</ul>
<h3 id="极限的正式定义"><a href="#极限的正式定义" class="headerlink" title="极限的正式定义"></a>极限的正式定义</h3><p>下面的定义说明<strong>充分靠近</strong>和<strong>任意靠近</strong>的精确含义是什么：</p>
<p>设$f(x)$除了可能在点$x_0$没有定义外，在$x_0$的一个开区间内均有定义。我们说当$x$趋于$x_0$时$f$趋于极限$L$，记作：</p>
<p>$$\lim_{x \to x_0} f(x) &#x3D; L$$</p>
<p>如果，对充分任何数$\epsilon &gt; 0$，存在相应的数$\delta &gt; 0$使得对所有满足$0 &lt; |x - x_0| &lt; \delta $的$x$，有$|f(x) - L| &lt; \epsilon$。</p>
<p>如果选取的$\epsilon$非常小，那么$|f(x) - L| &lt; \epsilon$意味着$f(x)$在某邻域内离$L$非常近，而“某邻域”有赖于找到相应的$\delta$。总之，不管你希望函数值离$L$多么近，总能找到$\delta$保证之，就可以确保极限是存在的，且值为$L$。</p>
<h2 id="极限的求值与单侧极限"><a href="#极限的求值与单侧极限" class="headerlink" title="极限的求值与单侧极限"></a>极限的求值与单侧极限</h2><h3 id="极限法则"><a href="#极限法则" class="headerlink" title="极限法则"></a>极限法则</h3><p>通过图像和极限定义，我们可以求出一下简单函数的极限，如$y &#x3D; c$，$y &#x3D; x$。在此基础上，通过若干极限法则，我们可以求得更复杂函数的极限。这些法则是：若$\lim_{x \to c} f(x) &#x3D; L$，$\lim_{x \to c} g(x) &#x3D; M$</p>
<ul>
<li>和法则：$\lim_{x \to c} (f(x)+g(x)) &#x3D; L + M$</li>
<li>差法则</li>
<li>积法则</li>
<li>商法则：$\lim_{x \to c} \frac{f(x)}{g(x)} &#x3D; \frac{L}{M}, if M \neq 0$</li>
<li>幂法则：若$r$和$s$都是整数，$s \neq 0$，那么$\lim_{x \to c} f(x)^{\frac{r}{s}} &#x3D; L^{\frac{r}{s}}$</li>
</ul>
<p>通过这些法则，我们就立即了解了如何求得有理函数的极限（除了分母极限为$0$的情况）。对于分母为$0$的情况，一般先考虑能否消去零分母。</p>
<h3 id="三明治（夹逼）定理"><a href="#三明治（夹逼）定理" class="headerlink" title="三明治（夹逼）定理"></a>三明治（夹逼）定理</h3><p>设在包含$c$在内的某个开区间中除$x &#x3D; c$外所有的$x$，有$g(x) \leq f(x) \leq h(x)$，又设</p>
<p>$$\lim_{x \to c} g(x) &#x3D; \lim_{x \to c} h(x) &#x3D; L$$</p>
<p>那么，$\lim_{x \to c} f(x) &#x3D; L$。</p>
<p>由此定理可求得：$\lim_{x \to 0} sin(x) &#x3D; 0$，$\lim_{x \to 0} cos(x) &#x3D; 1$</p>
<h3 id="双侧极限"><a href="#双侧极限" class="headerlink" title="双侧极限"></a>双侧极限</h3><p>当$x \to c$时，若只查看在$c$一侧的$x$，则得到<strong>单侧极限</strong>，相应地上面所说的极限即<strong>双侧极限</strong>，两者的关系是：当$x \to c$时，函数$f(x)$有极限当且仅当$f$的左侧极限和右侧极限存在且相等。</p>
<p>例：$\lim_{x \to 0} \frac{sin \theta}{\theta } &#x3D; 1$</p>
<h2 id="与无穷有关的极限"><a href="#与无穷有关的极限" class="headerlink" title="与无穷有关的极限"></a>与无穷有关的极限</h2><p>无穷（$\infty$）的记号并非表示它是一个实数，它用来描述函数的性态，即定义域或值域中的值会超过任意有限的界限。</p>
<h3 id="当-x-to-pm-infty-时的极限"><a href="#当-x-to-pm-infty-时的极限" class="headerlink" title="当$x \to \pm \infty$时的极限"></a>当$x \to \pm \infty$时的极限</h3><p>此时极限的定义与趋于某点是一致，只是此时寻找的不是某个邻域了。</p>
<p>另外，此时的极限也遵循与有限值相同的极限法则。</p>
<h3 id="当-x-to-pm-infty-时有理函数的极限"><a href="#当-x-to-pm-infty-时有理函数的极限" class="headerlink" title="当$x \to \pm \infty$时有理函数的极限"></a>当$x \to \pm \infty$时有理函数的极限</h3><p>当分子次数不大于分母次数时有极限，否则无。</p>
<h3 id="水平和垂直渐近线：无穷极限"><a href="#水平和垂直渐近线：无穷极限" class="headerlink" title="水平和垂直渐近线：无穷极限"></a>水平和垂直渐近线：无穷极限</h3><p>当函数图像愈来愈远离原点地移动时和某条固定直线见的距离趋于零时，我们说该图像渐进地趋于该直线，该直线是该图像的一条<strong>渐近线</strong>（即字面意思）。图像可在水平和垂直方向上移动，相应地有水平渐近线与垂直渐近线。</p>
<p>注意：这里是说图像移动，而非自变量。</p>
<p>例：函数$f(x) &#x3D; \frac{1}{x}$，水平渐近线是$x$轴，垂直渐近线是$y$轴。</p>
<p>对于函数$f(x) &#x3D; \frac{2 x^2 - 3}{7x+4}$，有$f(x) &#x3D; (\frac{2}{7}x - \frac{8}{49}) - \frac{115}{49 * (7x+4)}$，左边部分所表示的直线是函数的一条<strong>斜渐近线</strong>。</p>
<h3 id="无穷极限的精确定义"><a href="#无穷极限的精确定义" class="headerlink" title="无穷极限的精确定义"></a>无穷极限的精确定义</h3><p>无穷极限与有限极限有非常类似的正式定义，在此不再赘述。</p>
<h2 id="连续性"><a href="#连续性" class="headerlink" title="连续性"></a>连续性</h2><p>现在对极限有了基本的认识。如果我们把考虑的极限限定在<strong>有界的极限</strong>上，并且关注该<strong>极限值</strong>与函数在该点<strong>函数值</strong>的关系，会得到什么有趣的结果呢？</p>
<p>在我们手绘函数图像时，会选择用一条不间断的、光滑曲线来表示。这里的不间断和光滑属于直观的感觉，同时也有其数学基础。先看<strong>不间断的</strong>，所谓不间断，我们就假设了函数是<strong>连续的</strong>，即函数的取值不会发生跳跃。</p>
<p>在经典力学领域内，连续函数是最主要的一类函数，在如此大的尺度下，我们足可以认为函数是连续的。但在量子力学和计算机科学内就不如此了。无论如何，连续函数都是具有重要意义的一类函数。函数<strong>在一点的连续性</strong>是如下定义的：</p>
<p>函数$f(x)$在其定义域的<strong>内点</strong>$c$处是连续的，如果：</p>
<p>$$\lim_{x \to c} f(x) &#x3D; f(c)$$</p>
<p>在<strong>端点</strong>处的定义类似，只需要双侧极限替换为单侧极限。（实际上，不管是内点还是端点，我们都可以考虑其单侧连续性，此时称为左连续或右连续）</p>
<p>上述为函数在内点与端点的连续性定义。此定义符合我们的直觉，若函数在$c$点有极限，那么函数值在该点附近靠近其极限值，如果极限值不等于函数值，那么必然就出现了<strong>跳跃</strong>情况。另外，此定义也给出了检验函数连续性的基本方法。</p>
<h3 id="间断点"><a href="#间断点" class="headerlink" title="间断点"></a>间断点</h3><p>如果函数$f$在点$c$处不是连续的，我们就说$f$在$c$<strong>间断</strong>，而$c$是$f$的一个<strong>间断点</strong>。间断点有如下几种情况：</p>
<ul>
<li>可去间断点：如果改变在该点的函数值，函数就变为连续的了，故曰<strong>可去</strong>。可去间断点又有两种情况，一是函数值无定义，一是函数值不等于极限值。</li>
<li>跳跃间断：函数出现了跳跃，单侧极限都存在但不相等，故极限不存在</li>
<li>无穷间断：此时极限不存在</li>
<li>振荡间断：此时极限不存在</li>
</ul>
<h3 id="连续函数"><a href="#连续函数" class="headerlink" title="连续函数"></a>连续函数</h3><p>函数在一个<strong>区间上连续</strong>当且仅当它在该区间的每一点连续。<strong>连续函数</strong>是在<strong>定义域内每一点</strong>连续的函数。</p>
<p>我们最熟悉的那些函数（多项式函数、有理函数、三角函数、反三角函数、指数函数、对数函数）都是连续函数，从中学就开始接触这些函数，并不令人意外：）</p>
<p>连续函数的<strong>反函数</strong>也是连续函数，这一点从图像的对称性可以得知。另外，它们也有自然的运算法则。</p>
<p>连续函数的<strong>复合函数</strong>也是连续函数。</p>
<h3 id="连续函数的中间值定理"><a href="#连续函数的中间值定理" class="headerlink" title="连续函数的中间值定理"></a>连续函数的中间值定理</h3><p>在区间上连续的函数具有在数学上和应用中特别有用的性质。其中之一是<strong>中间值性质</strong>——<strong>连续函数的中间值定理</strong>：</p>
<p>在闭区间$[a, b]$上连续的函数一定取到$f(a)$和$f(b)$之间的每一个值。</p>
<p>几何上，用一支笔不离开纸面从$a$画到$b$，连续性保证函数值不会跳跃，从而画出的线是不间断的，这一点称为<strong>连通性</strong>。也可以说，在数$f(a)$和$f(b)$之间与$y$轴相交的任何水平直线$y &#x3D; y_0$与曲线$y &#x3D; f(x)$至少相交一次。</p>
<p>某些情况下，这一点也可以用来判断方程<strong>根的存在性</strong>。看下面的例子：</p>
<p><strong>不动点定理</strong>：设函数$f$在闭区间$[0, 1]$上连续并且对$[0, 1]$上任一点有$0 \leq f(x) \leq 1$，试证明$[0, 1]$中一定存在一点$c$使得$f(c) &#x3D; c$（$c$称为$f$的不动点）</p>
<p>证明：令$g(x) &#x3D; f(x) - x$，考察$g(0)与g(1)$的值，以及何处有零点。</p>
<h2 id="切线"><a href="#切线" class="headerlink" title="切线"></a>切线</h2><p>在第一节曾从图像上简单地讨论过曲线的割线与切线，彼时我们通过割线斜率的极限来求得曲线的切线斜率。</p>
<h3 id="什么是曲线的切线？"><a href="#什么是曲线的切线？" class="headerlink" title="什么是曲线的切线？"></a>什么是曲线的切线？</h3><p>如果是初次接触“曲线的切线”这一说法，也许你会想到的是中学里圆的切线。圆的切线垂直于过切点的半径（或者说切点与曲线中心的连线），与圆恰好有一个交点，而且切线位于圆的一侧。但对于一般的曲线来说，上述三个特点不足以表达切线的含义。</p>
<p>就是说，满足上述某一特点的未必是切线，反过来一条切线未必满足上述特点。那么，怎样定义一般曲线的切线呢？回想1.1中提到的平均速度和瞬时速度，这里以同样的思路考察割线之变化，其斜率的极限就是切线斜率。</p>
<p><strong>历史</strong>：<strong>求曲线的切线</strong>这个问题是17世纪早期首要的数学问题。光学中，切线决定着光线射入弯曲的镜头的角度；力学中，切线揭示了物体沿其运动路径每一点的运动方向。</p>
<h3 id="切线的定义"><a href="#切线的定义" class="headerlink" title="切线的定义"></a>切线的定义</h3><p>现在看上面所说从割线斜率到<strong>切线斜率</strong>，有如下定义：</p>
<p>曲线$y &#x3D; f(x)$在点$P(x_0, f(x_0))$的斜率是数：</p>
<p>$$m &#x3D; \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}，若该极限存在$$</p>
<p>从而有，曲线在点$P$的切线是过点$P$且以$m$为斜率的直线。</p>
<p>上面极限的函数表示的就是过点$P$的割线的斜率，当$h$趋于零时，如果极限存在，我们就认为它是切线的斜率。</p>
<p>例：如果我们把此定义应用在直线$y &#x3D; mx +b$上，那么会得到，过直线上一点的切线就是其自身。首先从切线定义来看，这是自然的结果；另外，若从割线斜率之变化来看，割线的斜率等于直线自身的斜率，也就是说上面的极限中，所求的乃是一个常数函数的极限，其结果就是常数本身，也就是直线自身的斜率。</p>
<p>需要注意的是，切线定义中的极限里，变化的是$h$（也就是自变量的增量）而不是自变量本身，即我们关心的增量变化时的结果，这在初次接触时可能会觉得有点绕。我们把$x$作为固定下来的常量，把增量作为自变量，就很自然了——这只是一个普通的函数极限求值。</p>
<h3 id="变化率：在一点的导数"><a href="#变化率：在一点的导数" class="headerlink" title="变化率：在一点的导数"></a>变化率：在一点的导数</h3><p>表达式</p>
<p>$$\frac{f(x_0 + h) - f(x_0)}{h}$$ </p>
<p>称为$f$在$x_0$处增量为$h$的差商。如果$h \to 0$时差商有极限，那么该极限就称为$f$在$x_0$的导数。如果我们把差商解释为割线的斜率，那么导数就给出了函数在$x &#x3D; x_0$处<strong>曲线的斜率</strong>和<strong>切线的斜率</strong>。如果把差商解释为1.1中讨论过的平均变化率，那么导数就给出了函数在$x &#x3D; x_0$处关于$x$的<strong>变化率</strong>。而如果把差商解释为平均速度，那么导数就给出了物体在一时刻的瞬时速度。</p>
<p>此时，我们应该能感觉到<strong>导数</strong>的重要性，它是微积分所考虑的两个最重要的对象之一，另一个是<strong>积分</strong>。</p>
<h2 id="习题"><a href="#习题" class="headerlink" title="习题"></a>习题</h2><p><strong>给$0^0$指定值</strong>：指数法则告诉我们如果$a$不等于$0$，那么$a^0 &#x3D; 1$，如果$n$是正数，那么$0^n &#x3D; 0$，那么$0^0$的值应该是什么比较合理呢？</p>
<p>提示：方法1：计算当$x$趋于$0$时，$x^x$如何变化；方法2：做函数$y &#x3D; x^x$的图形，比如在Mathematica中，然后考虑连续性。</p>
<p><strong>只在一点连续的函数</strong>：设有函数定义如下</p>
<p>$$[ f(x) &#x3D;<br>  \begin{cases}<br>    x       &amp; \quad \text{如果 } x \text{ 是有理数}\<br>    0  &amp; \quad \text{如果 } x \text{ 是无理数}\<br>  \end{cases}<br>]$$</p>
<p>那么，函数只在$x &#x3D; 0$处连续。</p>
<p><strong>狄利克雷（Dirichlet）直尺函数</strong>：$f(x)$定义域为$[0, 1]$，且定义为</p>
<p>$$[ f(x) &#x3D;<br>  \begin{cases}<br>    \frac{1}{n}       &amp; \quad \text{如果 } x &#x3D; \frac{m}{n}，以最低项表示的有理数 \<br>    0  &amp; \quad \text{如果 } x \text{ 是无理数}\<br>  \end{cases}<br>]$$</p>
<p>那么，$f$在每个有理数处间断；$f$在每个无理数处连续。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>本章先是定义了<strong>极限</strong>，借助于极限我们可以考察函数在趋于某个值（或$\pm \infty$）时变化的<strong>趋势</strong>。很重要的一点是，这里不止是趋势，它最终还是一个确定的数值。要定义出这个数值，我们需要实数连续统，加之严格的极限定义，如此方可确信我们确实拿到了一个有效定义的数值。</p>
<p>有了极限，考察函数在趋于一点时的变化趋势——即它的极限——与函数值本身的关系，我们得到的是<strong>连续性</strong>的概念。通过连续性可以考察函数值变化的性态。</p>
<p>然后考察平均变化率（或割线斜率&#x2F;平均速度）的极限，便得到瞬时变化率（或切线斜率&#x2F;瞬时速度）。瞬时变化率称为导数，导数与它在几何和物理上的解释都是极为基础和重要的。</p>
<h1 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h1><h2 id="作为函数的导数"><a href="#作为函数的导数" class="headerlink" title="作为函数的导数"></a>作为函数的导数</h2><h3 id="导函数"><a href="#导函数" class="headerlink" title="导函数"></a>导函数</h3><p>导数定义在函数定义域内的一点上。对于导数存在的一点来说，可认为是定义了从$x$到其导数的一个映射，或者说一个函数，这个函数称为<strong>导函数</strong>：</p>
<p>$$f’(x) &#x3D; \frac{f(x+h) - f(x)}{h}$$</p>
<p>计算导数的过程称为<strong>微分</strong>。如果在一点$x$处$f’$存在，我们就说$f$在$x$是<strong>可微的</strong>（有导数）。如何函数$f$在定义域内每一点都可微，那么就说$f$是可微的。</p>
<h3 id="记号"><a href="#记号" class="headerlink" title="记号"></a>记号</h3><p>记号$f’(x)$来自于牛顿，$\frac{dy}{dx}$来自于莱布尼兹。</p>
<h3 id="常见函数之导函数"><a href="#常见函数之导函数" class="headerlink" title="常见函数之导函数"></a>常见函数之导函数</h3><p>$f$定义了与$x$的对应关系，那么理论上可由此得出$f’$与$x$的对应关系，而无须逐一求值。</p>
<ul>
<li>常数函数$f(x) &#x3D; c$，$f’(x) &#x3D; 0$，常数函数的变化率为0，在任一点的”切线“斜率为0。</li>
<li>正整数幂函数：$\frac{d}{dx} x^n &#x3D; n x^{n-1}$</li>
<li>乘常数法则：$\frac{d}{dx} (cu) &#x3D; c \frac{du}{dx}$</li>
<li>导数和法则</li>
</ul>
<h3 id="区间上的可微性"><a href="#区间上的可微性" class="headerlink" title="区间上的可微性"></a>区间上的可微性</h3><p>与连续性一样，我们同样可考察函数在一个区间上的可微性，并且在端点上可以判断其单侧导数。</p>
<p>例：绝对值函数$y &#x3D; |x|$在$x &#x3D; 0$处不可微。其图像说明此处有一”角“，那么在该点没有切线，故不可微。因此<strong>可微性是一种”光滑性“条件</strong>。</p>
<h3 id="可微与连续"><a href="#可微与连续" class="headerlink" title="可微与连续"></a>可微与连续</h3><p>可以证明：<strong>可微性蕴含着连续性</strong>。</p>
<p>该结论同时也给出了一个函数不可微的一种原因：不连续。</p>
<p>函数在一点不连续的情形：</p>
<ul>
<li>角点：单侧导数不相等</li>
<li>尖点：一侧趋于$\infty$，另一侧趋于$-\infty $</li>
<li>垂直切线：（无斜率）</li>
<li>间断：不连续</li>
</ul>
<h3 id="导数的中间值性质"><a href="#导数的中间值性质" class="headerlink" title="导数的中间值性质"></a>导数的中间值性质</h3><p><strong>中间值定理</strong>：如果$a$和$b$是$f$在其上可微的区间中的两个点，那么$f’$一定取到$f’(a)$和$f’(b)$中间的每个值。</p>
<p>该定理实际上是对导函数做出了限定，这意味着并非每个函数都能成为某个的导函数。这个中间值定理看起来与连续函数的中间值定理颇相关，至于连续函数、导函数与原函数的关系，等后面学习积分时能了解到。</p>
<h3 id="二阶与高阶导数"><a href="#二阶与高阶导数" class="headerlink" title="二阶与高阶导数"></a>二阶与高阶导数</h3><p>导函数可看作函数的一阶导数，而一阶导数作为函数，亦有自己的函数，成为二阶导数，以此类推。</p>
<h2 id="作为变化率的导数"><a href="#作为变化率的导数" class="headerlink" title="作为变化率的导数"></a>作为变化率的导数</h2><h3 id="瞬时变化率"><a href="#瞬时变化率" class="headerlink" title="瞬时变化率"></a>瞬时变化率</h3><p>定义：<strong>瞬时变化率</strong>就是导数</p>
<p>$$f’(x_0) &#x3D; \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}$$</p>
<p>倘若该极限存在。</p>
<p>习惯上，即使$x$不表示时间，我们也说<strong>瞬时变化率</strong>。同时，常常将“瞬时”二字略去，当我们说<strong>变化率</strong>时，就是在说瞬时变化率。</p>
<p>例：圆面积$A$和直径的关系由方程$A &#x3D; \frac{\pi}{4} D^2$表示，当直径为10米时，面积关于直径的变化率有多大？</p>
<p>考虑面积关于直径的平均变化率，它表示当直径增加1个单位长度时，面积的增量。而关于一点的变化率，则是其极限情况。后面学习线性近似时会了解到此变化率的作用。</p>
<h3 id="直线运动"><a href="#直线运动" class="headerlink" title="直线运动"></a>直线运动</h3><ul>
<li>位移：$s &#x3D; f(t)$</li>
<li>速度：$v(t) &#x3D; \frac{ds}{dt} &#x3D; \lim_{\Delta t \to 0} \frac{f(t + \Delta t) - f(t)}{\Delta t}$，速度除了告诉我们速率，还告诉我们方向。</li>
<li>速率：速度的绝对值</li>
<li>加速度：$a(t) &#x3D; \frac{dv}{dt}$</li>
<li>急推：$j(t) &#x3D; \frac{da}{dt}$</li>
</ul>
<p>急推是位移函数的三阶导数。这意味着，对于自由落体运动来说，急推为0。</p>
<h3 id="经济学中的导数"><a href="#经济学中的导数" class="headerlink" title="经济学中的导数"></a>经济学中的导数</h3><p>工程师用速度和加速度描述运动，经济学家则用<strong>边际</strong>来指称他们的变化率。生产的<strong>边际成本</strong>是成本关于生产水平的变化率。若产品成本$c(x)$是所生产单位产品数量$x$的函数，边际成本是$\frac{dc}{dx}$。</p>
<p>有时把生产的边际成本<strong>近似为</strong>多生产一个单位产品的超值成本：</p>
<p>$$\frac{\Delta c}{\Delta x} &#x3D; \frac{c(x+1) - c(x)}{1}$$</p>
<p>注：经济学家一般用低次的多项式来说明成本和收入这样复杂的现象。这是一种权衡，三次多项式容易处理，又不至于过于简单。考虑奥卡姆剃刀。</p>
<h2 id="积、商以及负幂的导数"><a href="#积、商以及负幂的导数" class="headerlink" title="积、商以及负幂的导数"></a>积、商以及负幂的导数</h2><p>2.1里给出了导函数的定义，从而可以从整体上求得导函数，不需要逐点计算。本节将给出几个导数的运算法则，进一步简化导函数之求解。</p>
<ul>
<li>积法则：$\frac{d}{dx} (uv) &#x3D; u \frac{dv}{dx} + v \frac{du}{dx}$</li>
<li>商法则：$\frac{d}{dx} (\frac{u}{v}) &#x3D; \frac{v \frac{du}{dx} - u \frac{dv}{dx}}{v^2}$</li>
<li>负整数次幂法则：$\frac{d}{dx} (x^n) &#x3D; n x^{n-1}$，可由商法则证明</li>
<li>倒数法则：$\frac{d}{dx} (\frac{1}{v}) &#x3D; - \frac{1}{v^2} \frac{dv}{dx}$</li>
</ul>
<h2 id="三角函数的导数"><a href="#三角函数的导数" class="headerlink" title="三角函数的导数"></a>三角函数的导数</h2><p>使用极限定义、弧度、和角恒等式和导数法则，我们能求得六个三角函数的导数。</p>
<ul>
<li>$\frac{d}{dx} (sinx) &#x3D; cosx$</li>
<li>$\frac{d}{dx} (cosx) &#x3D; -sinx$</li>
<li>$\frac{d}{dx} (tanx) &#x3D; sec^2x$</li>
<li>$\frac{d}{dx} (secx) &#x3D; secx \quad tanx$</li>
<li>$\frac{d}{dx} (cotx) &#x3D; -csc^2x$</li>
<li>$\frac{d}{dx} (cscx) &#x3D; -\csc x \cot x$</li>
</ul>
<h3 id="简谐运动"><a href="#简谐运动" class="headerlink" title="简谐运动"></a>简谐运动</h3><p>在弹簧或蹦极绳索端点的物体的上下自由摆动就是<strong>简谐运动</strong>的一个例子。</p>
<h2 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h2><p>用定义求导数可能会很繁琐，各个导数法则大大简化了某些求导，但这些法则只是针对函数间的四则运算。现在来学习非常强大有效的<strong>链式法则</strong>。</p>
<p>例：函数$y &#x3D; 6x - 10 &#x3D; 2(3x-5)$是函数$y &#x3D; 2u$和$u &#x3D; 3x - 5$的复合函数，于是$\frac{dy}{dx} &#x3D; \frac{dy}{du} \cdot \frac{du}{dx}$。</p>
<p>此公式在一般情况下是否成立？答案是肯定的。导数表示变化率，$y$和$u$对复合函数的变化率都有贡献。直观上，$\frac{dy}{du}$是建立在$\frac{du}{dx}$基础之上的。</p>
<p>链式法则即是：</p>
<p>$$(f \circ g)’(x) &#x3D; f’(g(x)) \cdot g’(x)$$</p>
<p>或以莱布尼兹的记号：</p>
<p>$$\frac{dy}{dx} &#x3D; \frac{dy}{du} \cdot \frac{du}{dx}$$</p>
<p>简单的理解是，先把$u$看作自变量求导，再乘以$u’$。</p>
<h3 id="参数化曲线的斜率"><a href="#参数化曲线的斜率" class="headerlink" title="参数化曲线的斜率"></a>参数化曲线的斜率</h3><p>$$\frac{dy}{dx} &#x3D; \frac{dy&#x2F;dt}{dx&#x2F;dt}$$</p>
<h2 id="隐函数微分法"><a href="#隐函数微分法" class="headerlink" title="隐函数微分法"></a>隐函数微分法</h2><p>方程$x^3 + y^3 - 9xy &#x3D; 0$的图像称为叶形线，在1638年由笛卡尔所作。它确定的不是一个函数，但该曲线可以分割为几条弧线，每条都是$x$的函数的图像。</p>
<p>在曲线上的每一点，我们都可以求其切线斜率（或导数），而且并不需要求出一个显式的函数解析式。我们使用的是各个求导法则与链式法则。这种求解导数的过程称为<strong>隐函数微分法</strong>。</p>
<p>例：若$y^2 &#x3D; x$，求$dy&#x2F;dx$。</p>
<p>我们可以求出$y$的显式解析式，这样得到两个函数，再分别求导。不过这里还是看一下如何隐式地求导。首先需要明确的是，无论是否有显式解析式，$y$都是$x$的函数。所以$y^2$就是一个复合函数了，对方程两边求导有：</p>
<p>$$2y \frac{dy}{dx} &#x3D; 1$$</p>
<p>$$\frac{dy}{dx} &#x3D; \frac{1}{2y}$$</p>
<p>就是这么简单。</p>
<p>类似地，隐函数也可以定义和求解其高阶导数。</p>
<h2 id="相关变化率"><a href="#相关变化率" class="headerlink" title="相关变化率"></a>相关变化率</h2><p>链式法则与隐函数微分法之应用。</p>
<h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>先由极限给出导数的定义，然后导数有其重要的几何、物理意义，同时导数在各领域都有重要应用，比如经济学。可微着蕴含着连续性。各个求导法则与链式法则、隐函数微分法结合起来，我们已经能够求出很多函数的导数。</p>
<h1 id="导数的应用"><a href="#导数的应用" class="headerlink" title="导数的应用"></a>导数的应用</h1><p>已经看到许多导数的应用，本章将会继续给出导数应用的例子。</p>
<h2 id="函数的极值"><a href="#函数的极值" class="headerlink" title="函数的极值"></a>函数的极值</h2><p>导数的最重要应用之一是求函数的<strong>极值</strong>。中学时一般用函数的单调性和基本的不等式来求极值，很快就可以看到，使用导数要简单得多。</p>
<h3 id="绝对极值"><a href="#绝对极值" class="headerlink" title="绝对极值"></a>绝对极值</h3><p>定义：<strong>绝对极值</strong></p>
<p>设$f$是定义域为$D$的函数，$c \in D$，则$f(c)$是</p>
<ul>
<li>$f$在$D$上的<strong>绝对最大值</strong>，当且仅当对一切$x \in D$，有$f(x) \leq f(c)$</li>
<li>$f$在$D$上的<strong>绝对最小值</strong>，当且仅当对一切$x \in D$，有$f(x) \geq f(c)$</li>
</ul>
<p>绝对最大值和最小值也称为<strong>绝对极值</strong>，绝对之意为<strong>全局的</strong>。”绝对“两字常常省去。</p>
<p>例：$f(x) &#x3D; \sin x$在$[-\pi&#x2F;2, \pi&#x2F;2]$上有最大值1，最小值-1。</p>
<p>一般来说，一个函数在一个区间上，可能没有最大值或最小值。但对于<strong>有限闭区间</strong>上的<strong>连续函数</strong>来说，其最大值和最小值是必然存在的。这就是<strong>连续函数的极值定理</strong>。该定理的证明需要用到<strong>实数连续统</strong>的知识。</p>
<h3 id="相对极值"><a href="#相对极值" class="headerlink" title="相对极值"></a>相对极值</h3><p>与绝对极值相对应的是<strong>相对极值</strong>，所谓相对是说该极值仅对于邻近的某开区间而言，不需要是全局上的极值。</p>
<p><strong>绝对极值必然也是相对极值</strong>，所以我们要求绝对极值，可以列出所有的相对极值，再从中选择。</p>
<h3 id="求极值"><a href="#求极值" class="headerlink" title="求极值"></a>求极值</h3><p><strong>局部极值定理</strong>：如果函数$f$在定义域的<strong>内点</strong>$c$点取得局部极值，又若其导数存在，那么$f’(c) &#x3D; 0$。</p>
<p>如果函数在某内点取得极值，且在该点可导，那么其导数为0。那么考虑区间上所有的点，取得局部极值的点只可能是：</p>
<ul>
<li>使$f’ &#x3D; 0$的内点（内点，可导）</li>
<li>不可导的内点（内点，不可导）</li>
<li>端点</li>
</ul>
<p>由本节提到的两个定理，连续函数极值定理保证极值是<strong>存在的</strong>，局部极值定理说明到哪里去寻找极值。</p>
<p>又，如果函数在一点导数为0或导数不存在，那么该点成为<strong>临界点</strong>（Critical Point）。</p>
<p>综上，<strong>若有极值，那么只能在临界点和端点出取到</strong>。需要特别注意的是，临界点和端点处不一定取得极值。</p>
<h2 id="中值定理和微分方程"><a href="#中值定理和微分方程" class="headerlink" title="中值定理和微分方程"></a>中值定理和微分方程</h2><p>现在已经了解如何由运动物体的位置函数求得其速度与加速度。但是，如果我们只知道加速度，能否回过来求得其速度与位置函数呢？</p>
<p>这里的问题是，什么样的函数可以有另一个函数作为自己的导数？什么样的位置函数其导数恰好是给定的速度函数？<strong>中值定理</strong>的推论给出了答案。中值定理把函数在区间上的平均变化率和该区间内一点处的瞬时变化率联系起来。</p>
<h3 id="罗尔（Rolle）定理"><a href="#罗尔（Rolle）定理" class="headerlink" title="罗尔（Rolle）定理"></a>罗尔（Rolle）定理</h3><p>假设$y &#x3D; f(x)$在$[a, b]$的每一点上连续，又假设在$(a, b)$上每一点可微，如果$f(a) &#x3D; f(b) &#x3D; 0$，那么$(a, b)$中至少有一个数$c$，$f’(c) &#x3D; 0$。</p>
<p>如果做出这样一个函数的图像，会发现这个定理相当符合我们的直观。</p>
<p>证：闭区间上的连续函数必有绝对极值。极值点只可能在临界点和端点，而内点皆可微，故极值点只有两种可能：</p>
<ul>
<li>可微的内点：此内点满足所需</li>
<li>端点：这意味着该函数在区间上为常数函数，故每一内点皆满足所需。故得证。</li>
</ul>
<h3 id="中值定理（The-Mean-Value-Theorem）"><a href="#中值定理（The-Mean-Value-Theorem）" class="headerlink" title="中值定理（The Mean Value Theorem）"></a>中值定理（The Mean Value Theorem）</h3><p>如果函数仍满足罗尔定理的假设，即闭区间连续，内点可微，那么有什么结论呢？这就是主要的<strong>中值定理</strong>（好像有好多的中值定理）：</p>
<p>假设$y &#x3D; f(x)$在$[a, b]$的每一点上连续，又假设在$(a, b)$上每一点可微，那么$(a, b)$中至少有一个数$c$，使得$f’(c) &#x3D; \frac{f(b) - f(a)}{b - a}$。</p>
<p>证：等式的右边是函数在区间上的平均变化率。如罗尔定理一样，作一个函数的图像观察一下，发现它很像倾斜了的罗尔定理。那么把它摆正试试看。</p>
<p>中值定理是说，函数在区间内至少有一点的瞬时变化率等于区间上的平均变化率。物理上即是说，某一刻的速度必然等于平均速度。直观上想一想：物体从一点运动到另一点，速度在变化之中，或快或慢，那么平均速度将是最快速度与最慢速度之间，同时物体的速度也不会发生跳跃式变化，从而必然在某时刻恰好等于平均速度。</p>
<h3 id="中值定理的推论（Corollary）"><a href="#中值定理的推论（Corollary）" class="headerlink" title="中值定理的推论（Corollary）"></a>中值定理的推论（Corollary）</h3><p><strong>推论1</strong>：如果在区间$I$的每一点上$f’(x) &#x3D; 0$，那么对$I$上的一切$x$有$f(x) &#x3D; C$，其中$C$是常数。</p>
<p><strong>推论2</strong>：如果在区间$I$的每一点上$f’(x) &#x3D; g’(x)$，那么存在常数$C$，使得对$I$中一切$x$，$f(x) &#x3D; g(x) + C$成立。</p>
<p>即<strong>具有相同导函数的函数必然仅相差一个常数</strong>。</p>
<h3 id="微分方程以及抛射体的高度"><a href="#微分方程以及抛射体的高度" class="headerlink" title="微分方程以及抛射体的高度"></a>微分方程以及抛射体的高度</h3><p><strong>微分方程（Differential Equation）<strong>就是把未知函数及其一个或多个导数联系在一起的方程，一个函数称为微分方程的一个</strong>解</strong>。</p>
<p>例：$y &#x3D; - \cos t + 3$是微分方程$dy&#x2F;dx &#x3D; \sin x$的一个解。</p>
<h2 id="图像的形状"><a href="#图像的形状" class="headerlink" title="图像的形状"></a>图像的形状</h2><p>中学时经常要手工作图，先找几个点，然后再以”光滑曲线“连接之，现在知道所谓光滑是指可微。那么一般来说，为确定图形的形状，我们需要知道什么信息？需要知道它的单调性，以及图形是如何弯曲的。这些可以从一阶与二阶导数获得。</p>
<p>根据上节的中值定理，容易得到如下<strong>重要推论</strong>：</p>
<p>假设$f$在$[a, b]$上连续并且在$(a, b)$上可微，则有</p>
<ul>
<li>如果在$(a, b)$上每一点$f’ &gt; 0$，那么$f$在$[a, b]$上是（严格）增函数</li>
<li>如果在$(a, b)$上每一点$f’ &lt; 0$，那么$f$在$[a, b]$上是（严格）减函数</li>
</ul>
<p>这时<strong>临界点</strong>的重要性体现了出来，找出临界点，那么定义域可以划分为几部分，每一部分里函数可能是递增或递减的。</p>
<p>例：求函数$f(x) &#x3D; x^3 - 12x - 5$的单调区间。</p>
<p>$f’(x) &#x3D; 3x^2 - 12 &#x3D; 3(x+2)(x-2)$，这样找到了临界点为$\pm 2$，单调区间也就找到了。</p>
<h3 id="局部极值与导数的关系"><a href="#局部极值与导数的关系" class="headerlink" title="局部极值与导数的关系"></a>局部极值与导数的关系</h3><p>如果在一<strong>临界点</strong>的左侧有$f’ &lt; 0$，右侧有$f’ &gt; 0$，那么可知函数在左侧递减，右侧递增，从而在这一点取得局部极小值。这一结论可以推广为：</p>
<p>在临界点$x &#x3D; c$处，</p>
<ul>
<li>$f$有局部极小值，如果$f’$在$c$从负变到正；</li>
<li>$f$有局部极大值，如果$f’$在$c$从正变到负；</li>
<li>$f$没有局部极值，如果$f’$在$c$两边正负号相同；</li>
</ul>
<p>端点处的检验法与此类似，但只需要考虑一侧的情形。</p>
<p>至此，我们对于单调区间、极值有了一定的了解，接下来考虑如何了解函数图像<strong>弯曲的方式</strong>。</p>
<h3 id="凹性"><a href="#凹性" class="headerlink" title="凹性"></a>凹性</h3><p>对于$y &#x3D; x^3$的图像，可以看到它在$x &#x3D; 0$处以不同的方式转向。先是凹向下，再是凹向上。凹向下的部分曲线位于切线下面，凹向上的部分曲线位于切线上面（故曰向上、向下）。</p>
<p>定义：<strong>凹性</strong></p>
<p>可微函数$y &#x3D; f(x)$的图形是</p>
<ul>
<li>在开区间$I$上是凹向上的，如果$y’$在$I$上递增</li>
<li>在开区间$I$上是凹向下的，如果$y’$在$I$上递减</li>
</ul>
<p>观察凹向上的曲线，其切线位于曲线之下，切线斜率递增，而凹向下者则是切线斜率递减。</p>
<p>$y’$的符号可以决定$y$的单调性，凹性定义中涉及到$y’$的单调性，那么自然地，可以借助于$y’’$考察函数的凹性。这就是<strong>凹性的二阶导数检验法</strong>：</p>
<p>二次可微函数$y &#x3D; f(x)$的图形</p>
<ul>
<li>在$y’’ &gt; 0$的任何区间上是凹向上的</li>
<li>在$y’’ &lt; 0$的任何区间上是凹向下的</li>
</ul>
<p>注：凹向上和凹向下在图形上与我们的直观理解一致。以前看过的数学教材中，将两者情形分别称为凸的和凹的。这个定义相较而言更容易有歧义。凹性定义中的向上和向下总是与曲线与切线的位置关系一致。</p>
<p>例：$y &#x3D; x^2$在$(-\infty, \infty)$上是凹向上的，因为其二阶导数总是为正。</p>
<h3 id="拐点（Inflection-point）"><a href="#拐点（Inflection-point）" class="headerlink" title="拐点（Inflection point）"></a>拐点（Inflection point）</h3><p>一点称为函数的<strong>拐点</strong>，如果函数在该点<strong>有切线</strong>而且在该点<strong>改变函数的凹性</strong>。</p>
<p>在拐点处，$y’’$或为零，或没有定义（所以，<strong>拐点是一阶导数的临界点</strong>）。如果在该点二阶可微，那么在拐点处$y’’ &#x3D; 0$且$y’$在拐点处取得局部极值。</p>
<h3 id="局部极值的二阶导数检验法"><a href="#局部极值的二阶导数检验法" class="headerlink" title="局部极值的二阶导数检验法"></a>局部极值的二阶导数检验法</h3><ul>
<li>如果$f’(c) &#x3D; 0$且$f’’(c) &lt; 0$，那么$f$在$x &#x3D; c$取到局部最大值</li>
<li>如果$f’(c) &#x3D; 0$且$f’’(c) &gt; 0$，那么$f$在$x &#x3D; c$取到局部最小值</li>
</ul>
<p>$f’’(c) &lt; 0$意味着$f’$在$c$的某个邻域内递减，从而函数先增后减，即取得局部最大值。</p>
<h3 id="从函数的导数了解函数"><a href="#从函数的导数了解函数" class="headerlink" title="从函数的导数了解函数"></a>从函数的导数了解函数</h3><p>通过函数的一阶和二阶导数我们可以理解函数的大量信息：</p>
<ul>
<li>可微：光滑、连通</li>
<li>$y’ &gt; 0$：递增</li>
<li>$y’ &lt; 0$：递减</li>
<li>$y’’ &gt; 0$：凹向上，且没有波动</li>
<li>$y’’ &lt; 0$：凹向下，且没有波动</li>
<li>拐点：$y’’$改变正负号</li>
<li>$y’$改变正负号：局部极值</li>
<li>在一点$y’ &#x3D; 0$且$y’’ &lt; 0$，局部最大值</li>
<li>在一点$y’ &#x3D; 0$且$y’’ &gt; 0$，局部最小值</li>
</ul>
<h2 id="自治微分方程的图形解"><a href="#自治微分方程的图形解" class="headerlink" title="自治微分方程的图形解"></a>自治微分方程的图形解</h2><p>我们可以把有关导数怎样确定图形的形状的知识作为图形地求解微分方程的基础。这基于<strong>相直线</strong>和<strong>平衡点</strong>的概念。</p>
<p>至此已了解临界点在确定函数的性态以及函数极值中的重要作用。现在来看以不同的角度考察当函数导数为零时会发生什么。对于下面的函数隐式地求其导数：</p>
<p>$$y^2 &#x3D; x + 1$$</p>
<p>得到$\frac{dy}{dx} &#x3D; \frac{1}{2y}$</p>
<p>注意到此导数仅与$y$有关，故此类方程称为<strong>自治微分方程</strong>。</p>
<h3 id="平衡点或静止点"><a href="#平衡点或静止点" class="headerlink" title="平衡点或静止点"></a>平衡点或静止点</h3><p>如果$dy&#x2F;dx &#x3D; g(y)$是自治微分方程，那么使$dy&#x2F;dx &#x3D; 0$的$y$值称为<strong>平衡点</strong>或<strong>静止点</strong>。</p>
<p>可以看到平衡点意味着导数为零，这又对应着临界点。由于导数为零，故因变量在这些点不发生变化（变化率为零），认为$y$处于静止状态。这是平衡点和静止点得名之由来。</p>
<p>例：求自治微分方程$\frac{dy}{dx} &#x3D; (y+1)(y-2)$的图形解。</p>
<p>为构造图形解，需要先作出方程的<strong>相直线</strong>，<strong>在y轴</strong>上找出平衡点位置和一阶、二阶导数的正负区域。如此就可以了解什么地方的解释递减和递增的，以及解曲线的凹性。</p>
<p>一般而言，一阶、二阶导数由$x$表示，但这里却是通过$y$表示的。在了解了单调性与凹性之后，我们可以画出函数解的略图。</p>
<h2 id="建模与最优化"><a href="#建模与最优化" class="headerlink" title="建模与最优化"></a>建模与最优化</h2><p>最优化某个量意即极大化或极小化该量的某一方面。如最小成本、最大利润等等。其步骤是：</p>
<ul>
<li>了解问题：什么是未知量？什么是给定的？什么是要求的？</li>
<li>建立模型</li>
<li>确定定义域</li>
<li>识别临界点与端点：这是极值可能发生的地方</li>
<li>求解模型</li>
<li>对解进行解释</li>
</ul>
<h3 id="Fermat原理和Snell定律"><a href="#Fermat原理和Snell定律" class="headerlink" title="Fermat原理和Snell定律"></a>Fermat原理和Snell定律</h3><p>光速依赖于光所经过的介质，在稠密介质中会慢下来。真空中其速度$c &#x3D; 3 \times 10^8 m&#x2F;s$行进，在大气层会稍慢，在玻璃会更慢。</p>
<p>Fermat原理说光永远以速度最快（时间最短）的路径行进。这样，当光从介质一中的A点出发，到达介质二中的B点，其路径可以确定下来。所谓路径确定下来，实际上是说其入射点可以确定下来。</p>
<p>依此思路所得的结果称为Snell定律或折射定律。</p>
<h3 id="最大利润"><a href="#最大利润" class="headerlink" title="最大利润"></a>最大利润</h3><p>在给出最大利润的生产水平上，边际收入等于边际成本（即边际利润的临界点）。</p>
<h3 id="用可微函数对离散现象建模"><a href="#用可微函数对离散现象建模" class="headerlink" title="用可微函数对离散现象建模"></a>用可微函数对离散现象建模</h3><p>对于成本与收入这样的函数，自变量只能取整数。但我们仍然“假装”它们可以取到一般的实数以建模。当$x$较大时，这样是没问题的，只是需要注意，如何舍入到合适的整数。</p>
<p>此时需要考虑对于不同的舍入值，函数的变化有多敏感，然后取较不敏感的那个值。</p>
<h2 id="线性化（Linearization）和微分（Differential）"><a href="#线性化（Linearization）和微分（Differential）" class="headerlink" title="线性化（Linearization）和微分（Differential）"></a>线性化（Linearization）和微分（Differential）</h2><p>有时候我们需要处理复杂的函数，而在一定的精度要求内，可以考虑较为简单的函数近似之。本节讨论的近似方法是<strong>线性化</strong>，以后会介绍其它近似方法。</p>
<p>我们会看到莱布尼兹的$dy&#x2F;dx$记法可被赋予新的含义，而$dy$可用于估计函数变化的度量的误差和敏感度。</p>
<h3 id="线性化"><a href="#线性化" class="headerlink" title="线性化"></a>线性化</h3><p>以$y &#x3D; x^2$为例，作出它的图像，在其上一点作出切线来。如果我们放大图像到足够的程度，会发现曲线很接近于切线，既然如此，在很小的区间内，我们可以考虑使用直线上的值来近似函数值。</p>
<p>一般来说，在$f(x)$可微的点$x &#x3D; a$处$y &#x3D; f(x)$的切线方程为：</p>
<p>$$y &#x3D; f(a) + f’(a)(x-a)$$</p>
<p>这条切线是线性函数</p>
<p>$$L(x) &#x3D; f(a) + f’(a)(x-a)$$</p>
<p>如果区间足够小，切线与函数曲线足够接近，$L(x)$就给出了$f(x)$足够好的近似。这称为函数$f$在$a$的<strong>线性化</strong>。</p>
<p>例：根式和幂函数的线性化为：</p>
<p>$$(1+x)^k \approx 1 + kx，x在0附近$$</p>
<p>类似地，在0附近，还有：$\sin x \approx x$，$\cos x \approx 1$，$\tan x \approx x$。</p>
<h3 id="微分"><a href="#微分" class="headerlink" title="微分"></a>微分</h3><p>莱布尼兹的记法中，$dy&#x2F;dx$表示导数，它并不表示一个比值。现在我们引入新的（两个）变量$dx$和$dy$，如果它们的比存在，其比值就等于导数。</p>
<p>定义：<strong>微分</strong></p>
<p>设$y &#x3D; f(x)$是一个可微函数。微分$dx$是一个自变量，微分$dy$是</p>
<p>$$dy &#x3D; f’(x)dx$$</p>
<p>注意，这里有两个微分，其中$dx$是自变量，$dy$是因变量。</p>
<p>微分有一个很直观的几何解释，即函数线性化的变化。</p>
<h3 id="绝对、相对和百分比变化"><a href="#绝对、相对和百分比变化" class="headerlink" title="绝对、相对和百分比变化"></a>绝对、相对和百分比变化</h3><p>当我们从$a$移动到邻近点$a + dx$时，可以用三种方式描述$f$的变化：</p>
<ul>
<li>绝对变化：$\Delta f &#x3D; f(a + dx) - f(a)$</li>
<li>相对变化：$\frac{\Delta f}{f(a)}$</li>
<li>百分比变化：$\frac{\Delta f}{f(a)} \times 100$</li>
</ul>
<p>若以线性化近似，那么估计的变化是</p>
<ul>
<li>绝对变化：$df &#x3D; f’(a) dx$</li>
<li>相对变化：$\frac{df}{f(a)}$</li>
<li>百分比变化：$\frac{df}{f(a)} \times 100$</li>
</ul>
<p><strong>敏感度</strong>：在$x$处的$f’$越大，给定的变化$dx$的影响越大。</p>
<p><strong>误差</strong>：如果$y &#x3D; f(x)$在$x &#x3D; a$可微而$x$从$a$变到$a + \Delta x$，那么$\Delta y$由形为</p>
<p>$$\Delta y &#x3D; f’(a) \Delta x + \varepsilon \Delta x$$</p>
<p>的等式给出，当$\Delta x \to 0$时，$\varepsilon \to 0$</p>
<p>例：<strong>质能转换</strong></p>
<p>牛顿第二定律$F &#x3D; ma$假定质量是不变的，后来被爱因斯坦修订为</p>
<p>$$m &#x3D; \frac{m_0}{\sqrt {1 - v^2&#x2F;c^2}}$$</p>
<p>当$v$远小于$c$时，我们可使用如下的近似式：</p>
<p>$$\frac{1}{\sqrt {1 - v^2&#x2F;c^2}} \approx 1 + \frac{1}{2} (\frac{v^2}{c^2})$$</p>
<h2 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h2><p>一元一次、二次方程有简单的公式解，而三次和四次则有更为复杂的公式。人们一度希望对五次和更高次方程也可能求得类似的公式，但阿贝尔（Abel）证明了次数大于四的多项式方程不可能有类似地求解公式。</p>
<p>在没有确切公式时，我们考虑使用<strong>数值方法</strong>在求得近似解。最经典的方法之一是牛顿法（或Newton-Raphson法）。其思路是，在$f &#x3D; 0$的$x$值附近用$f$的切线来替代$f(x)$的切线，其中<strong>线性化</strong>是求解的关键。</p>
<h3 id="牛顿法的步骤"><a href="#牛顿法的步骤" class="headerlink" title="牛顿法的步骤"></a>牛顿法的步骤</h3><p>方程的根对应于函数的<strong>零点</strong>。牛顿法使用函数的线性化近似其零点。在合适的情况下，线性化的零点会快速<strong>收敛</strong>到要求的零点精确近似值。其大概步骤如下：</p>
<p>首先通过作图或简单猜测找出初始估计值$x_0$，然后用函数在点$(x_0, f(x_0))$的切线近似函数曲线，把切线和$x$轴的交点记作$x_1$。$x_1$通常是比$x_0$更好的近似。</p>
<p>重复上述过程，以在点$(x_1, f(x_1))$处的切线近似函数曲线，寻找下一个交点。如此下去，直到充分接近零点。</p>
<p>由于每次求得下一个近似值的方法完全一样，可以得出它们的递推公式，即</p>
<p>$$x_{n+1} &#x3D; x_n - \frac{f(x_n)}{f’(x_n)}$$</p>
<p>例：求$\sqrt 2$。</p>
<p>解：所求值即函数$f(x) &#x3D; x^2 - 2$正的零点。采用牛顿法，从$x_0 &#x3D; 1$开始，经过少数几步就得到相当精确的近似解。</p>
<p>多数计算器可用牛顿法求根，因为它收敛得特别快。经过三步就可以得到$\sqrt 2$的5位精确数字的解。</p>
<h3 id="牛顿法的收敛性"><a href="#牛顿法的收敛性" class="headerlink" title="牛顿法的收敛性"></a>牛顿法的收敛性</h3><p>牛顿法看起来是如此简单高效，那么它是否总是如此呢？答案是否定的，详情此处暂略。</p>
<p>如果$f’(x_n) &#x3D; 0$，那么上面的递推公式无效。有时牛顿法是不收敛的，它会在几个点之间来回跳跃。</p>
<p>如果牛顿法是收敛的，那么它一定会收敛到一个零点。</p>
<p>如果从很远的地方开始牛顿法，最终得到的可能是另一个零点，而不是所求的。</p>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 无穷级数</title>
    <url>/2017/09/05/thomas-calculus-infinite-series/</url>
    <content><![CDATA[<p><strong>无穷级数</strong>的求和这一无穷过程曾困扰数学家们长达几个世纪，因为它有多种不同的情况，有时是一个有限值，有时是无穷大的，有时则可能取到多个值。</p>
<p>尽管如此，像欧拉和拉普拉斯这样伟大的数学家还是使用无穷级数推导出了很多前人难以接受的结果。若干年后柯西建立了级数计算的理论基础。</p>
<p>无穷级数是一个强大工具的基础，这个工具能使我们把许多函数表示成<strong>无穷多项式（幂级数）</strong>，并告诉我们把它截断成有限多项式时有多少误差。称为<strong>傅里叶级数</strong>的三角函数项无穷级数在科学和工程中有颇为重要的应用。无穷级数提供了一个有效的方法来计算非初等积分的值。</p>
<h1 id="无穷序列的极限"><a href="#无穷序列的极限" class="headerlink" title="无穷序列的极限"></a>无穷序列的极限</h1><p>序列是事物的<strong>有序列表</strong>，本章这些事物都是数，故可称为<strong>数列</strong>。中学中接触过数列，当时主要是关注有穷数列，而本章主要关注的是<strong>无穷序列</strong>。</p>
<p>定义：数的<strong>无穷序列</strong>是一个<strong>函数</strong>，它的定义域是大于或等于某个整数$n_0$的整数集。</p>
<p>$n_0$通常是1，此时定义域是正整数集。此定义的核心是序列是一个<strong>函数</strong>，即一种对应关系。</p>
<h2 id="记号"><a href="#记号" class="headerlink" title="记号"></a>记号</h2><p>此函数同一般函数一样，可以表示为解析式，如$a(n) &#x3D; \sqrt{n}$。值得注意的是，函数名一般用$a$而不是$f$，自变量则一般用字母表中间的$n$而不是末端的$x$等。我们说$a(n)$是序列的<strong>第$n$项</strong>，也经常表示为$a_n$。</p>
<p>我们把第$n$项为$a_n$的序列表示成${a_n}$，具体表达式的例子则是${ \frac{1}{n} }$。</p>
<h2 id="收敛与发散"><a href="#收敛与发散" class="headerlink" title="收敛与发散"></a>收敛与发散</h2><p>序列的变化趋势有不同的情况，比如：</p>
<ul>
<li>${ 3 }$、${ 1&#x2F;n }$、${ (n-1)&#x2F;n }$，这三个序列都在$n$增加是趋向于唯一的极限值</li>
<li>${ \frac{(-1)^{n+1}(n-1)}{n} }$的项则集中在两个不同的值周围</li>
<li>${ \sqrt{n} }$的项不断增加而不集中在任何值的周围。</li>
</ul>
<p>定义：（收敛、发散和极限）</p>
<p>序列${ a_n }$<strong>收敛</strong>到数$L$，如果对于每个正数$\epsilon$，都对应一个整数$N$，使得对所有$n$：</p>
<p>$$n &gt; N \Rightarrow |a_n - L| &lt; \epsilon$$</p>
<p>这里的数$L$称为序列的<strong>极限</strong>。直观上来说，就是不管给一个如何小的数，在某一项之后，序列的项到$L$的距离都不会超过这个数，换言之，都集中在$L$附近。此定义与一般函数的极限是很接近的。</p>
<p>若这样的数$L$不存在，我们说${ a_n }$<strong>发散</strong>。</p>
<h2 id="计算序列极限的三个定理"><a href="#计算序列极限的三个定理" class="headerlink" title="计算序列极限的三个定理"></a>计算序列极限的三个定理</h2><p>有三个关于序列极限的定理，使得极限计算大为简化。一是四则运算。</p>
<p>二是<strong>夹逼定理</strong>，夹逼定理还有一个推论：若$|b_n| \leq c_n$且$c_n \to 0$，则$b_n \to 0$。</p>
<p>例：$\frac{1}{2^n} \leq \frac{1}{n}$，故$\frac{1}{2^n} \to 0$。同理，$\frac{\cos n}{n} \to 0$。</p>
<p>三是<strong>序列的连续函数定理</strong>：</p>
<p>若${ a_n }$是一个实数序列，若${ a_n } \to L$，且$f$是一个在$L$连续，并对所有$a_n$有定义的函数，那么有$f(a_n) \to f(L)$。</p>
<p>例：$\sqrt{(n+1)&#x2F;n} \to \sqrt{1} &#x3D; 1$，$2^{1&#x2F;n} \to 2^{0} &#x3D; 1$。</p>
<h2 id="洛必达法则的应用"><a href="#洛必达法则的应用" class="headerlink" title="洛必达法则的应用"></a>洛必达法则的应用</h2><p>洛必达应用于一般的函数，而非序列。要应用洛必达法则，需要先了解这个定理：</p>
<p>假定$f(x)$是一个对于所有$x \geq n_0$有定义的函数，而${a_n}$是一个对$n \geq n_0$满足$a_n &#x3D; f(n)$的序列，则有</p>
<p>$$\lim_{x \to \infty} f(x) &#x3D; L \Rightarrow lim_{n \to \infty}a_n &#x3D; L$$</p>
<p>直观上这是很容易理解的，因为序列实际上定义在函数定义域的子集上，函数有极限，那么序列必然也有等值的极限。通过这个定理，序列极限转换为函数极限，然后就可以应用洛必达法则了。</p>
<h2 id="常用极限简表"><a href="#常用极限简表" class="headerlink" title="常用极限简表"></a>常用极限简表</h2><ol>
<li>${ k } \to k$</li>
<li>${ \frac{1}{n} } \to 0$</li>
<li>${ \frac{\ln n}{n} } \to 0$</li>
<li>${ \sqrt[n]{n} } \to 1$</li>
<li>${ x^{1&#x2F;n} } \to 1 (x &gt; 0)$</li>
<li>${ x^{n} } \to 0 (|x| &lt; 1)$</li>
<li>${ (1+\frac{x}{n})^{n} } \to e^x, \forall x \in R$</li>
<li>${ \frac{x^n}{n!} } \to 0, \forall x \in R$</li>
</ol>
<p>注：在#7，$x$可以是任意实数，包括0和负数。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p><strong>拉链定理</strong>：</p>
<p>若${ a_n }$和${ b_n }$都收敛到$L$，则序列</p>
<p>$$a_1, b_1, a_2, b_2, \cdots, a_n, b_n, \cdots$$</p>
<p>也收敛到$L$。</p>
<h1 id="子序列、有界序列和皮卡方法"><a href="#子序列、有界序列和皮卡方法" class="headerlink" title="子序列、有界序列和皮卡方法"></a>子序列、有界序列和皮卡方法</h1><pre><code>- Subsequences, Bounded Sequences, and Picard&#39;s Method
</code></pre>
<p>本节继续对序列收敛性的讨论。</p>
<h2 id="子序列"><a href="#子序列" class="headerlink" title="子序列"></a>子序列</h2><p>如果一个序列保持其次序出现在另一序列中，则称第一个序列为第一个序列的<strong>子序列</strong>。常见的例子，正偶整数序列是自然数序列的子序列。</p>
<p>基于两个原因，子序列是重要的：</p>
<ol>
<li>如果一个序列收敛到$L$，则它的每个子序列收敛到$L$。如果我们知道一个序列收敛，那么它的极限也可以通过一个特殊的子序列来求得。</li>
<li>如果序列的某个子序列发散，或者有两个子序列收敛到不同极限，那么该序列必发散。</li>
</ol>
<p>子序列的重要情形是序列的<strong>尾部</strong>，即一个序列从某个指标$N$开始的项组成的子序列。<strong>一个序列的收敛性与其开头部分无关，仅依赖于尾部的状况</strong>。</p>
<h2 id="单调有界序列"><a href="#单调有界序列" class="headerlink" title="单调有界序列"></a>单调有界序列</h2><p>序列是一种特殊的函数，因此也可以定义其单调性，并可称序列是<strong>非减的（递增的）<strong>和</strong>非增的（递减的）</strong>。</p>
<p>同时，也可依函数的方式定义序列的有界性，并可称序列是<strong>有上界的</strong>、<strong>有下界的</strong>和<strong>有界的</strong>。</p>
<p>并非每个有界序列都收敛，也不是每个单调序列都收敛，那如果序列同时是有界的和单调的呢？看下面的定理。</p>
<h3 id="单调序列定理"><a href="#单调序列定理" class="headerlink" title="单调序列定理"></a>单调序列定理</h3><p><strong>每个单调有界序列是收敛的</strong>。</p>
<p>例：序列${ \frac{n}{n+1} }$是非减的，因此有下界，同时也有上界1，因此它必定收敛。</p>
<h2 id="递归地定义序列"><a href="#递归地定义序列" class="headerlink" title="递归地定义序列"></a>递归地定义序列</h2><p>这个已经属于常见内容了，尤其是接触过编程的话。常见的递归定义当属阶乘序列与斐波那契数列，之前在应用牛顿法时，实际上也以递归的方式定义了序列。</p>
<h2 id="皮卡方法"><a href="#皮卡方法" class="headerlink" title="皮卡方法"></a>皮卡方法</h2><p>一种求方程解的计算方法，与函数的<strong>不动点</strong>相关。之所以要在序列这里提到，是因为它同牛顿法类似，以递归方式定义了一个序列，该序列在满足某些前提条件是会逼近方程的解。</p>
<h1 id="无穷级数"><a href="#无穷级数" class="headerlink" title="无穷级数"></a>无穷级数</h1><pre><code>- Infinite Series
</code></pre>
<p>在数学和科学中，我们时常把函数写成无穷多项式，比如</p>
<p>$$ \frac{1}{1-x} &#x3D; 1 + x + x^2 + \cdots + x^n + \cdots, |x| &lt; 1$$</p>
<p>稍后我们会看到这么做的重要性。对$x$的任何允许值，我们把<strong>无穷多个数的和</strong>作为多项式的值，这个<strong>和</strong>我们成为一个<strong>无穷级数</strong>。</p>
<h2 id="级数与部分和"><a href="#级数与部分和" class="headerlink" title="级数与部分和"></a>级数与部分和</h2><p>级数是无穷多个数的和，因此它与一般的有限个数的加法不同。有限个数的加法满足一些运算律，而无穷级数则未必满足。我们该怎样界定像</p>
<p>$$1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \cdots$$</p>
<p>这样的表达式的意义呢？这里采用的方式不可能是诸项相加以求其值，我们转而计算<strong>部分和</strong>，然后考察部分和的变化模式。</p>
<p>对上面这个级数来说，其<strong>部分和构成一个序列</strong>，第$n$项为$s_n &#x3D; 2 - \frac{1}{2^{n-1}}$，部分和的极限为2，这样我们称该<strong>无穷级数的和</strong>为2。</p>
<p>极限再一次发挥了重要作用。注意到没有任何一个部分和确切地等于2，但我们把它的极限定义为级数的和，就像在求切线斜率和曲边梯形面积时一样。</p>
<p>总结一下，我们把<strong>无穷多个数的和</strong>称为无穷级数，它的收敛性通过其<strong>部分和序列的收敛性</strong>决定。</p>
<p>例：级数$\frac{3}{10} + \frac{3}{100} + \cdots + \frac{3}{10^n} + \cdots$是否收敛？</p>
<p>解：把部分和写成小数形式，可以识别出部分和序列的极限是$0.\bar{3}$，即$\frac{1}{3}$。</p>
<p>在研究级数$a_1 + a_2 + \cdots + a_n + \cdots$时，我们通常用求和符合来表示之，如$\sum_{n&#x3D;1}^{\infty} a_n$。</p>
<h2 id="几何级数"><a href="#几何级数" class="headerlink" title="几何级数"></a>几何级数</h2><p>上例的级数是一个<strong>几何级数</strong>，因为它每一项都是由前一项乘以同一常数$r$得到，其中的$r &#x3D; 1&#x2F;10$。这对应于中学里的<strong>等比数列</strong>。</p>
<p><strong>几何级数</strong>是形如</p>
<p>$$a + ar + ar^2 + \cdots + ar^{n-1} + \cdots &#x3D; \sum_{n&#x3D;1}^{\infty}$$</p>
<p>的级数，$a$和$r$都不为零，<strong>公比</strong>$r$正负皆可。</p>
<p>现在来看它的收敛性。若$|r| \neq 1$，部分和为$s_n &#x3D; \frac{a(1-r^n)}{1-r}$，因此若$|r| &lt; 1$，则级数收敛至$\frac{a}{1-r}$，否则发散。若$|r| &#x3D; 1$，级数同样发散。</p>
<p>因此，几何级数仅在$|r| &lt; 1$时收敛，和为$\frac{a}{1-r}$，而区间$-1 &lt; r &lt; 1$称为<strong>收敛半径</strong>。</p>
<p>可以发现，几何级数是一类比较<strong>单纯</strong>的级数，它的收敛性与和很容易判断。但一般的级数并非如此。</p>
<h2 id="发散级数的第-n-项判别法"><a href="#发散级数的第-n-项判别法" class="headerlink" title="发散级数的第$n$项判别法"></a>发散级数的第$n$项判别法</h2><p>若级数收敛，那么部分和序列在某项之后将会任意接近极限，那么将有$s_n - s_{n-1} &#x3D; a_n \to 0$，也就是<strong>若级数收敛，则其第$n$项必然趋于0</strong>，这一结论的逆否命题就可以用来判定发散级数。此所谓发散级数的第$n$项判别法。</p>
<p>但该结论的逆命题不成立，即第$n$项趋于0，级数未必收敛，如$a_n &#x3D; \frac{1}{n}$。</p>
<h2 id="添加或取消项"><a href="#添加或取消项" class="headerlink" title="添加或取消项"></a>添加或取消项</h2><p>对级数添加或删除有限项，不改变其收敛性，虽然收敛的时候，级数和可能会改变。</p>
<h2 id="级数的组合"><a href="#级数的组合" class="headerlink" title="级数的组合"></a>级数的组合</h2><p>收敛级数的组合满足和、差与常倍数规则。</p>
<p>对于发散级数而言，它的非零常数倍依然是发散的；收敛级数与发散级数之和或差都发散。</p>
<h2 id="扩展-1"><a href="#扩展-1" class="headerlink" title="扩展"></a>扩展</h2><p>雪花曲线：8.3习题51</p>
<h1 id="非负项级数"><a href="#非负项级数" class="headerlink" title="非负项级数"></a>非负项级数</h1><p>本节考虑没有负项的级数。这类级数的一个重要特点是部分和序列是递增的，因此若确定它有上界，则它收敛。是为非负项级数收敛性的最基础的判别法：</p>
<p><strong>若非负项级数$\sum_{n&#x3D;1}^{\infty} a_n$的部分和有上界，则它收敛。</strong></p>
<p>因此可通过分析级数有上界来判定其收敛性，上界可通过多种不同的方法来判断，比如积分。</p>
<h2 id="积分判别法"><a href="#积分判别法" class="headerlink" title="积分判别法"></a>积分判别法</h2><p>之所以可通过积分判定，是因为级数可转换为某个对应函数的黎曼和，此时的<strong>分割</strong>点在每个正整数上，级数就是每个小区间上矩形的面积之和，将此面积和与积分值比较，可能会确定出级数是否有上界。<strong>积分判别法</strong>具体如下：</p>
<p>设${ a_n }$是一个正数项序列，假定对$x \geq N$，$a_n &#x3D; f(n)$，$f$是$x$的一个连续、正的递减函数，则级数$\sum_{n&#x3D;1}^{\infty} a_n$和积分$\int_{N}^{\infty}f(x)dx$同时收敛或同时发散。</p>
<p>注：两者虽收敛性相同，但极限未必是一致的。</p>
<h2 id="调和级数和p-级数"><a href="#调和级数和p-级数" class="headerlink" title="调和级数和p-级数"></a>调和级数和p-级数</h2><p>形如$\sum_{n&#x3D;1}^{\infty} \frac{1}{n^p}$的级数称为<strong>p-级数</strong>，它的收敛性可以方便地由积分判别法来断定。当$p &gt; 1$时积分收敛，当$p \leq 1$时积分发散，此结论亦适用于相应的p-级数。</p>
<p>$p &#x3D; 1$时的p-级数称为<strong>调和级数</strong>，它或许是数学中最著名的发散级数。在p-级数家族中，调和级数是收敛与发散者的分界点，或者说是“勉强发散的”。</p>
<p>注：调和级数收敛极慢，比如若要它的部分和$H_n &gt; 20$，则$n$需要超过1亿。</p>
<h2 id="比较判别法"><a href="#比较判别法" class="headerlink" title="比较判别法"></a>比较判别法</h2><p>现在了解了几何级数、调和级数两类级数，然后还有积分判别法助阵，已经颇可以判断一些级数的收敛性了。但实际上这些仍只是很狭窄的几类，我们需要更多判别法。这里讨论一类判别法，这些判别法通过不同的比较方法，将级数收敛性的判定转化为已知级数的收敛性判定。</p>
<h3 id="直接比较判别法"><a href="#直接比较判别法" class="headerlink" title="直接比较判别法"></a>直接比较判别法</h3><p>设$\sum_{n&#x3D;1}^{\infty} a_n$是非负项级数</p>
<ul>
<li>若存在收敛级数$\sum_{n&#x3D;1}^{\infty} c_n$和一个整数$N$，使得对所有$n &gt; N$有$a_n \leq c_n$，则$\sum_{n&#x3D;1}^{\infty} a_n$也收敛。</li>
<li>若存在非负项发散级数$\sum_{n&#x3D;1}^{\infty} d_n$和一个整数$N$，使得对所有$n &gt; N$有$a_n \geq d_n$，则$\sum_{n&#x3D;1}^{\infty} a_n$也发散。</li>
</ul>
<p>这两部分可通过有界性判别法证明。只要注意，级数的的收敛性不受前面有限项的影响，因此可以仅考察$n &gt; N$的项的情况。</p>
<p>例：当$n \geq 2$时，$\frac{1}{n!} \leq \frac{1}{2^n}$，而$\sum_{n&#x3D;1}^{\infty} (1&#x2F;2^n)$收敛，故$\sum_{n&#x3D;1}^{\infty} \frac{1}{n!}$也收敛。</p>
<h3 id="极限比较判别法"><a href="#极限比较判别法" class="headerlink" title="极限比较判别法"></a>极限比较判别法</h3><p>考察两个级数项之比的极限，我们可以了解两者项的<strong>接近程度</strong>，从而可以借由其中一个推出另一个的情况。<strong>极限比较判别法</strong>具体如下：</p>
<ol>
<li>若$\lim_{n \to \infty} \frac{a_n}{b_n} &#x3D; c, c &gt; 0$，则两者收敛性同。</li>
<li>若$\lim_{n \to \infty} \frac{a_n}{b_n} &#x3D; 0$，而$\sum b_n$收敛，则$\sum a_n$也收敛。</li>
<li>若$\lim_{n \to \infty} \frac{a_n}{b_n} &#x3D; \infty$，而$\sum b_n$发散，则$\sum a_n$也发散。</li>
</ol>
<p>该判别法的证明可通过直接判别法证明。</p>
<h2 id="比值判别法"><a href="#比值判别法" class="headerlink" title="比值判别法"></a>比值判别法</h2><p>比较判别法是通过已知级数判定未知者的收敛性，比值判别法则比较相邻项之大小以考察级数项的增长速度。对于几何级数来说，任一项与前面一项之比为常数$r$，当$|r|$小于1时，级数收敛。比值判别法是对此结论的推广。</p>
<p><strong>比值判别法</strong>：</p>
<p>设$\sum_{n&#x3D;1}^{\infty} a_n$是正项级数，假定$\lim_{n \to \infty} \frac{a_{n+1}}{a_n} &#x3D; \rho$，则</p>
<ol>
<li>若$\rho &lt; 1$，级数收敛；</li>
<li>若$\rho &gt; 1$或$\infty$，级数发散；</li>
<li>若$\rho &#x3D; 1$，则级数收敛性不能确定。</li>
</ol>
<p>直观上，对于1，存在某个收敛的几何级数，$\sum a_n$项的减小速度比之更快，从而收敛；对于2，与1类似；对于3，考虑$\sum \frac{1}{n}$与$\sum \frac{1}{n^2}$。</p>
<h2 id="n-次根判别法"><a href="#n-次根判别法" class="headerlink" title="$n$次根判别法"></a>$n$次根判别法</h2><p>$n$次根判别法与比值判别法思路类似：</p>
<p>设$\sum_{n&#x3D;1}^{\infty} a_n$是非负项级数，假定$\lim_{n \to \infty} \sqrt[n]{a_n} &#x3D; \rho$，则</p>
<ol>
<li>若$\rho &lt; 1$，级数收敛；</li>
<li>若$\rho &gt; 1$或$\infty$，级数发散；</li>
<li>若$\rho &#x3D; 1$，则级数收敛性不能确定。</li>
</ol>
<h1 id="交错级数、绝对收敛与条件收敛"><a href="#交错级数、绝对收敛与条件收敛" class="headerlink" title="交错级数、绝对收敛与条件收敛"></a>交错级数、绝对收敛与条件收敛</h1><pre><code>- Alternating Series, Absolute and Conditional Convergence
</code></pre>
<p>上节我们讨论的级数都属于非负项级数，本节会讨论带有负项的级数，一个重要的例子是<strong>交错级数</strong>，它的项符号正负交替。</p>
<h2 id="交错级数"><a href="#交错级数" class="headerlink" title="交错级数"></a>交错级数</h2><p>如果一个级数的各项交替地是正和负的，那么它是<strong>交错级数</strong>。</p>
<p>例：$\sum \frac{(-1)^{n+1}}{n} &#x3D; 1 - \frac{1}{2} + \frac{1}{3} - \cdots + \frac{(-1)^{n+1}}{n} + \cdots$称为<strong>交错调和级数</strong>。</p>
<p>定理：<strong>交错级数判别法（Leibniz定理）</strong></p>
<p>级数</p>
<p>$$\sum (-1)^{n+1} u_n &#x3D; u_1 - u_2 + u_3 - u_4 + \cdots$$</p>
<p>收敛，如果下列条件满足：</p>
<ol>
<li>$u_n$全是正的；</li>
<li>对某个$N$，对所有$n \geq N$，$u_n &gt;&#x3D; u_{n+1}$；</li>
<li>$u_n \to 0$</li>
</ol>
<p>证：先看级数的前面偶数项，设$n &#x3D; 2m$，前$n$项和为</p>
<p>$$s_{2m} &#x3D; (u_1 - u_2) + (u_3 - u_4) + \cdots + (u_{2m-1} - u_{2m}) \<br>&#x3D; u_1 - (u_2 - u_3) - \cdots - (u_{2m-2} - u_{2m-1}) - u_{2m}$$</p>
<p>第一个等式说明$s_{2m}$为$m$个非负项之和，因此${ s_{2m} }$是递增的；第二个等式说明$s_{2m} \leq u_1$，因此有上界，所有${ s_{2m} }$有极限，记为$L$。</p>
<p>再看级数的前面奇数项，设$n &#x3D; 2m + 1$，则$s_{2m+1} &#x3D; s_{2m} + u_{2m+1}$，因为$u_n \to 0$，故$u_{2m+1} \to 0$，故$\lim_{m \to \infty} s_{2m+1} &#x3D; \lim_{m \to \infty} s_{2m} &#x3D; L$</p>
<p>综合这两种情形，即有$\lim_{n \to \infty} s_n &#x3D; L$。</p>
<p>再仔细点看一下这里的交错级数。</p>
<p>$$s_{2m} &#x3D; (u_1 - u_2) + (u_3 - u_4) + \cdots + (u_{2m-1} - u_{2m})$$<br>$$s_{2m+1} &#x3D; u_1 - (u_2 - u_3) - (u_4 - u_5) - \cdots - (u_{2m} - u_{2m+1})$$</p>
<p>可以发现，偶数项部分和递增趋于极限，奇数项部分和递减趋于极限，两者位于极限两侧，因此部分和序列会不断的穿越极限值。这可以给我们关于<strong>截断误差</strong>的启示。</p>
<p>定理：<strong>交错级数估计定理</strong></p>
<p>若交错级数$\sum (-1)^{n+1} u_n$满足上面判别法之条件，则部分和的截断误差$|L - s_n| &lt; u_{n+1}$，且$L - s_n$与第$n+1$项有相同的符号。</p>
<p>注：该定理给出了误差的一个<strong>界</strong>，这个估计一般来说是相当保守的。</p>
<h2 id="绝对收敛"><a href="#绝对收敛" class="headerlink" title="绝对收敛"></a>绝对收敛</h2><p>一个级数$\sum a_n$<strong>绝对收敛</strong>，如果对应的绝对值级数$\sum |a_n|$收敛。</p>
<p>交错调和级数收敛，它的绝对值级数是调和级数不收敛。直觉上，绝对收敛比收敛是更强的条件。</p>
<h2 id="条件收敛"><a href="#条件收敛" class="headerlink" title="条件收敛"></a>条件收敛</h2><p>如果一个级数收敛但不是绝对收敛的，称之为<strong>条件收敛</strong>。</p>
<p>因此交错调和级数条件收敛。</p>
<p>定理：<strong>绝对收敛判别法</strong></p>
<p>若一个级数绝对收敛，则其自身收敛。</p>
<p>例：交错p级数，由莱布尼兹定理，p级数总是收敛的，当$p &gt; 1$时绝对收敛，其它时候条件收敛。</p>
<h2 id="重排级数"><a href="#重排级数" class="headerlink" title="重排级数"></a>重排级数</h2><p>定理：<strong>绝对收敛级数的重排定理</strong></p>
<p>若$\sum a_n$绝对收敛，而$\sum b_n$是$\sum a_n$的任意重排，则$\sum b_n$也绝对收敛，且两个级数收敛于同一值。</p>
<p>注：若重排的是<strong>条件收敛级数</strong>的<strong>无穷多项</strong>，我们可能得到远远不同于原级数和的结果，一般的结论是<a href="https://zh.wikipedia.org/wiki/%E9%BB%8E%E6%9B%BC%E7%BA%A7%E6%95%B0%E5%AE%9A%E7%90%86#.E5.8F.82.E8.80.83.E6.9D.A5.E6.BA.90">黎曼级数定理-Riemann’s Rearrangement Theorem</a>。见下例。</p>
<p>例：交错调和级数重排后可以发散或收敛到任何预先指定的和。详见8.5 例8。</p>
<h2 id="级数敛散性判别法一览"><a href="#级数敛散性判别法一览" class="headerlink" title="级数敛散性判别法一览"></a>级数敛散性判别法一览</h2><p><img src="/images/t-calculus/converges.png" alt="converges"></p>
<h1 id="幂级数"><a href="#幂级数" class="headerlink" title="幂级数"></a>幂级数</h1><pre><code>- Power Series
</code></pre>
<p>若$|x| &lt; 1$，则由几何级数公式可知</p>
<p>$$1 + x + x^2 + \cdots &#x3D; \frac{1}{1-x}$$</p>
<p>等式右端定义了一个函数，左端也是一个函数，尽管它的形式有点“奇怪”——无穷多项的和。在本节，我们将讨论像$\sum_{n&#x3D;0}^{\infty} x^n$这样的<strong>无穷多项式</strong>。</p>
<h2 id="幂级数及收敛"><a href="#幂级数及收敛" class="headerlink" title="幂级数及收敛"></a>幂级数及收敛</h2><p>表达式$\sum_{n&#x3D;0}^{\infty} c_n x^n$像是一个多项式，但多项式仅包含有限阶，故此表达式不能认为是一个简单的多项式，正如无穷级数不是一个简单的和。</p>
<p>定义：<strong>幂级数</strong></p>
<p>形如</p>
<p>$$\sum_{n&#x3D;0}^{\infty} c_n x^n &#x3D; c_0 + c_1x + \cdots + c_nx^n + \cdots$$</p>
<p>的表达式是一个<strong>中心在$x &#x3D; 0$的幂级数</strong>。形如</p>
<p>$$\sum_{n&#x3D;0}^{\infty} c_n (x-a)^n &#x3D; c_0 + c_1(x-a) + \cdots + c_n(x-a)^n + \cdots$$</p>
<p>的表达式是一个<strong>中心在$x &#x3D; a$的幂级数</strong>。项$c_n(x-a)^n$是第$n$项，数$a$是中心。</p>
<h3 id="多项式估计"><a href="#多项式估计" class="headerlink" title="多项式估计"></a>多项式估计</h3><p>我们把等式$1 + x + x^2 + \cdots &#x3D; \frac{1}{1-x}$右端看作左端的级数和的公式。也可以从那个另一个角度来看：设想左端级数的部分和来逼近右端的函数。对于靠近$x &#x3D; 0$的点，只要去少数几项就得到一个好的逼近，当靠近1或-1时，则需要取更多项来逼近。</p>
<p>这样，我们是<strong>以多项式函数来逼近一个函数</strong>。</p>
<h2 id="收敛半径和区间"><a href="#收敛半径和区间" class="headerlink" title="收敛半径和区间"></a>收敛半径和区间</h2><p>本节开头提到的幂级数在$(-1, 1)$上收敛，对于一般的幂级数$\sum_{n&#x3D;0}^{\infty} c_n x^n$来说，它总是在$x &#x3D; a$处收敛，这保证幂级数至少在一点上收敛。除了这两种情况，幂级数还可能对所有实数收敛，下面的定理说明，这三种情形就是幂级数收敛的所有可能。</p>
<p>定理：<strong>幂级数收敛定理</strong></p>
<p>$\sum_{n&#x3D;0}^{\infty} c_n x^n$的收敛有三种可能：</p>
<ol>
<li>存在一个正数$R$，使得级数当$|x - a| &gt; R$时发散，$|x - a| &lt; R$时收敛，在两个端点处则既可能收敛也可能发散；</li>
<li>级数对每个$x$收敛（$R &#x3D; \infty$）；</li>
<li>级数在$x &#x3D; a$收敛，其它点发散（$R &#x3D; 0$）。</li>
</ol>
<p>$R$称为<strong>收敛半径</strong>，所有使级数收敛的点集是<strong>收敛区间</strong>。</p>
<p>例：通过比值判别法可知：</p>
<ul>
<li>$\sum_{n&#x3D;0}^{\infty} (-1)^{n-1} \frac{x^n}{n}$收敛区间为$(-1, 1]$</li>
<li>$\sum_{n&#x3D;0}^{\infty} (-1)^{n-1} \frac{x^{2n-1}}{2n-1}$收敛区间为$[-1, 1]$</li>
<li>$\sum_{n&#x3D;0}^{\infty} \frac{x^n}{n!}$收敛区间为$(-\infty, \infty)$</li>
<li>$\sum_{n&#x3D;0}^{\infty} {x^n}{n!}$仅在$x &#x3D; 0$处收敛。</li>
</ul>
<h3 id="收敛区间求解步骤"><a href="#收敛区间求解步骤" class="headerlink" title="收敛区间求解步骤"></a>收敛区间求解步骤</h3><ul>
<li>先使用比值判别法或n次根判别法求解级数的<strong>绝对收敛区间</strong></li>
<li>若收敛半径有限，检查其端点</li>
<li>级数在收敛半径之外的点发散，因为其第n项不趋于零。</li>
</ul>
<h2 id="逐项求导"><a href="#逐项求导" class="headerlink" title="逐项求导"></a>逐项求导</h2><p>定理：<strong>逐项求导定理</strong></p>
<p>级数$\sum_{n&#x3D;0}^{\infty} c_n (x-a)^n$的收敛为$R &gt; 0$，则它在$(-R, R)$上定义了一个函数$f(x)$，$f$在收敛区间内部有所有阶的导数，此导数可通过对原级数<strong>逐项求导</strong>而得，而且这些经求导所得的级数在原级数收敛区间的每一点收敛。</p>
<h2 id="逐项积分"><a href="#逐项积分" class="headerlink" title="逐项积分"></a>逐项积分</h2><p>从略。</p>
<h2 id="幂级数的乘法"><a href="#幂级数的乘法" class="headerlink" title="幂级数的乘法"></a>幂级数的乘法</h2><p>绝对收敛级数可以像多项式那样相乘，所得的新级数也绝对收敛，且其和为原来的两个级数之乘积。</p>
<h1 id="泰勒级数与麦克劳林级数"><a href="#泰勒级数与麦克劳林级数" class="headerlink" title="泰勒级数与麦克劳林级数"></a>泰勒级数与麦克劳林级数</h1><p>我们借由对级数的了解来分析幂级数，求出幂级数的和，可以认为是以幂级数表示函数，也可以用幂级数来近似函数。在本节，我们将讨论使用更一般的技术来构造幂级数，充分地使用微积分工具。多数情况下，这些级数提供了原函数的<strong>多项式逼近</strong>。</p>
<h2 id="构造一个级数"><a href="#构造一个级数" class="headerlink" title="构造一个级数"></a>构造一个级数</h2><p>现在已经知道，在幂级数的收敛区间内部，<strong>幂级数的和是一个具有各阶导数的连续函数</strong>。那么反过来是否成立？即如果一个函数$f$在区间$I$上具有各阶导数，它能够表示成一个幂级数吗？如果能，它的系数是什么？</p>
<p>这是两个问题，先看后一个，它的各项系数会是什么呢？</p>
<p>设$f$是一个有正收敛半径的幂级数之和：$f(x) &#x3D; \sum_{n&#x3D;0}^{\infty} a_n(x-a)^n$，在收敛区间$I$内重复使用逐项求导，对于一阶导数，有：</p>
<p>$$f’(x) &#x3D; a_1 + 2a_2(x-a) + \cdots + na_n(x-a)^{n-1} + \cdots$$</p>
<p>此时，令$x &#x3D; a$，得到$f’(a) &#x3D; a_1$</p>
<p>重复此过程，可得到各系数的值，一般的有$f^{(n)}(a) &#x3D; n!a_n$。此结论说明，如果存在这样一个级数（这是第一个问题，尚未解决），则该级数是唯一确定的。</p>
<p>那么，如果我们从任意一个以$a$为中心的区间$I$上无穷次可微的函数出发，用它按上述结论<strong>生成</strong>一个级数，那么在$I$的内部的每个点，该级数都收敛到$f$吗？答案是两可的。</p>
<p>目前的结论是，如果该级数存在，其各系数是唯一确定的，而级数的存在性尚未确定。那么我们先放下存在性不管，以上述方式<strong>生成</strong>一个级数，然后来考察该级数的收敛性，如果它收敛，我们就得到了需要的级数。</p>
<h2 id="泰勒级数与麦克劳林级数-1"><a href="#泰勒级数与麦克劳林级数-1" class="headerlink" title="泰勒级数与麦克劳林级数"></a>泰勒级数与麦克劳林级数</h2><p>注：泰勒级数是由英国数学家布鲁克·泰勒在1715年发表的。</p>
<p>定义：<strong>泰勒级数</strong></p>
<p>设$f$是一个在包含$a$为内点的区间$I$内存在所有阶导数的函数，由$f$生产的泰勒级数是</p>
<p>$$\sum_{k&#x3D;0}^{\infty} \frac{f^{(k)}(a)}{k!}(x-a)^k &#x3D; f(a) + f’(a)(x-a) + \frac{f’’(a)}{2!}(x-a)^2 + \cdots$$</p>
<p>若$a &#x3D; 0$，则生成的级数称为麦克劳林级数。</p>
<p>例：$f(x) &#x3D; 1&#x2F;x$在$a &#x3D; 2$生成的泰勒级数为$\frac{1}{2} - \frac{(x-2)}{2^2} + \frac{(x-2)^2}{2^3} - \cdots + (-1)^n \frac{(x-2)^n}{2^{n+1}} + \cdots$，该级数是一个几何级数，在$0 &lt; x &lt; 4$收敛到$\frac{1}{x}$。</p>
<h2 id="泰勒多项式"><a href="#泰勒多项式" class="headerlink" title="泰勒多项式"></a>泰勒多项式</h2><p>一个可微函数在点$a$的线性化是多项式</p>
<p>$$P_1(x) &#x3D; f(a) + f’(a)(x-a)$$</p>
<p>可以看到，线性化<strong>在形式上</strong>恰好是泰勒级数的前两项。如果$f$在$a$有更高阶的导数，那么它就有更高阶的多项式逼近，这些多项式称为$f$的<strong>泰勒多项式</strong>。</p>
<p>定义：<strong>$n$阶泰勒多项式</strong></p>
<p>设$f$在一个包含$a$作为内点的一个区间内对$k &#x3D; 1, 2, \cdots, N$有$k$阶导数。则对任何从0到$N$的整数$n$，由$f$在$x &#x3D; a$生成的$n$阶泰勒多项式是：</p>
<p>$$P_n(x) &#x3D; \sum_{k&#x3D;0}^{n} \frac{f^{(k)}(a)}{k!}(x-a)^k$$</p>
<p>它在形式上是泰勒级数的前$n+1$项。恰如线性化提供了$f$的最佳线性逼近，高阶泰勒多项式提供了相应阶的最佳多项式逼近。</p>
<p>例：$f(x) &#x3D; e^x$在$x &#x3D; 0$的$n$阶泰勒多项式是</p>
<p>$$P_n(x) &#x3D; 1 + x + \frac{x^2}{2} + \cdots + \frac{x^n}{n!}$$</p>
<h2 id="泰勒多项式的余项"><a href="#泰勒多项式的余项" class="headerlink" title="泰勒多项式的余项"></a>泰勒多项式的余项</h2><p>当我们用泰勒多项式$P_n(x)$来逼近函数时，需要度量其精确程度。使用等式</p>
<p>$$f(x) &#x3D; P_n(x) + R_n(x)$$</p>
<p>定义了<strong>余项</strong>这一概念，余项$R_n(x)$的绝对值称为<strong>逼近</strong>的<strong>误差</strong>。下面的定理提供了估计泰勒多项式余项的途径。</p>
<p>定理：<strong>泰勒定理</strong></p>
<p>若$f$在一个包含$a$的开区间$I$内是$n+1$阶可微的，则对$I$内的每个$x$，存在一个介于$x$和$a$之间的一个数$c$，使得</p>
<p>$$f(x) &#x3D; P_n(x) + R_n(x)$$</p>
<p>$P_n(x)$即是$n$阶泰勒多项式，而（重点是）$R_n(x) &#x3D; \frac{f^{(n+1)}(c)}{(n+1)!}(x-a)^{n+1}$。</p>
<p>也就是对任何满足前提条件的函数，泰勒多项式近似的误差都可以如此表示出来。分母增长很快，若$x$离$a$较近，那么泰勒多项式很快就可以给出相当好的近似。泰勒定理是中值定理的推广。</p>
<p>若对$I$内所有$x$，当$n \to \infty$时$R_n \to 0$，我们就说$f$生成的泰勒级数在$I$上收敛到$f$。</p>
<h2 id="估计余项"><a href="#估计余项" class="headerlink" title="估计余项"></a>估计余项</h2><p>定理：<strong>余项估计定理</strong></p>
<p>如果存在正数$M$和$r$，使得对$a$和$x$之间所有$t$均有$|f^{(n+1)}(t)| \leq Mr^{n+1}$，则由泰勒定理可知余项满足不等式</p>
<p>$$|R_n(x)| \leq M \frac{r^{n+1}|x-a|^{n+1}}{(n+1)!}$$</p>
<p>在最简单的情形下，若$f$及其所有导数的绝对值都以$M$为界，那么我们可以去$r &#x3D; 1$。其它情况下，则需要考虑其它值。</p>
<p>例：证明$\sin x$的麦克劳林级数对所有$x$收敛到$\sin x$。</p>
<p>证：$\sin x$的麦克劳林级数仅有奇次幂项，对$n &#x3D; 2k+1$，泰勒定理给出</p>
<p>$$\sin x &#x3D; x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots + \frac{(-1)^k x^{2k+1}}{(2k+1)!} + R_{2k+1}(x)$$</p>
<p>在余项估计定理中取$M &#x3D; 1, r &#x3D; 1$，得到</p>
<p>$$|R_{2k+1}(x)| \leq \frac{|x|^{2k+2}}{(2k+2)!}$$</p>
<p>$R_{2k+1}(x) \to 0$，由此可知，对每个$x$，$\sin x$的麦克劳林级数收敛到$\sin x$。</p>
<h2 id="截断误差"><a href="#截断误差" class="headerlink" title="截断误差"></a>截断误差</h2><p>由余项及余项估计定理，我们可以了解要达到某个期望的误差，泰勒多项式需要取到多少项。</p>
<h2 id="组合泰勒级数"><a href="#组合泰勒级数" class="headerlink" title="组合泰勒级数"></a>组合泰勒级数</h2><p>泰勒级数在它们的收敛区间的公共部分上可以进行加、减、常数乘、$x$的幂运算。从略。</p>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 积分</title>
    <url>/2017/08/14/thomas-calculus-integral/</url>
    <content><![CDATA[<h1 id="积分"><a href="#积分" class="headerlink" title="积分"></a>积分</h1><p>我们已经看到计算<strong>瞬时变化率</strong>的需要是如何导致人们研究切线的斜率，并引出我们称之为<strong>微分运算</strong>的<strong>导数</strong>。但导数揭示的仅仅是故事的一半，微积分除了描述函数在给定时间如何变化，还要描述那些瞬时的变化如何在一段时间内累积而产生该函数。也就是<strong>通过研究行为的改变来了解行为本身</strong>。例如，运动物体的速度能够决定作为时间函数的位置，人们还研究了曲边梯形的面积，这些研究导致产生了我们称之为<strong>积分学</strong>。</p>
<p>曾经，人们觉得求切线斜率和曲边梯形没有任何联系。牛顿和莱布尼兹却证明了凭直观发现的两者之间的内在联系。这个联系（微积分基本定理）的发现使得微分和积分运算<strong>一起成为数学家总能得到认识宇宙万物的最有力的工具</strong>。	</p>
<h2 id="不定积分、微分方程和建模"><a href="#不定积分、微分方程和建模" class="headerlink" title="不定积分、微分方程和建模"></a>不定积分、微分方程和建模</h2><p>第一部分主要讨论的是求一个函数的导函数，一个自然的问题是，给定一个函数，如何求得它的<strong>反导数（原函数）</strong>，即以它为导数的函数。</p>
<p>第一步是给出一个公式，该公式被称为<strong>不定积分</strong>，它给出了所有可能的反导数。第二步则是利用手头已知的函数值来选定一个特殊的反导数。</p>
<p>看起来这只是一个“理论上”的思路，因为要以一个公式给出所有反导数，似乎不大可能。但根据3.2的中值定理的推论，只要找到一个反导数，就能确定出<strong>不定积分</strong>了。</p>
<h3 id="不定积分"><a href="#不定积分" class="headerlink" title="不定积分"></a>不定积分</h3><p>一个函数$F(x)$称为另一个函数$f(x)$的<strong>反导数</strong>，如果</p>
<p>$$F’(x) &#x3D; f(x)$$</p>
<p>对$f$定义域中的$x$成立。$f$的全体反导数组成的集合称为其关于$x$的<strong>不定积分</strong>，记作</p>
<p>$$\int f(x)dx$$</p>
<p>其中$f$称为<strong>被积函数</strong>，$x$称为<strong>积分变量</strong>。</p>
<p>按3.2中值定理推论，已知一个反导数$F(x)$，那么其它反导数与其仅相差一个常数，故有</p>
<p>$$\int f(x)dx &#x3D; F(x) + C$$</p>
<p>其中$C$称为<strong>积分常数</strong>或<strong>任意常数</strong>。</p>
<p>例：$\int 2xdx &#x3D; x^2 + C$</p>
<p>我们可以把导数公式表反过来作为初始的“反导数公式”表使用。</p>
<h3 id="初值问题"><a href="#初值问题" class="headerlink" title="初值问题"></a>初值问题</h3><p>已知函数的导数以及在一点$x_0$处的值$y_0$，求$x$的函数$y$的问题称为<strong>初值问题</strong>。</p>
<p>例：已知曲线在点$(x, y)$处的斜率为$3x^2$，并通过点$(-1, 1)$，求该曲线。</p>
<p>解：$\int 3x^2dx &#x3D; x^3 + C$，又因为曲线通过点$(-1, 1)$，可知$C &#x3D; -2$，故所求曲线为$y &#x3D; x^3 - 2$。</p>
<p>如上，不定积分给出了微分方程的<strong>一般解</strong>，借由初值我们可以确定出<strong>特解</strong>。</p>
<h3 id="数学建模"><a href="#数学建模" class="headerlink" title="数学建模"></a>数学建模</h3><p>一般步骤：</p>
<ul>
<li>观察现实世界行为</li>
<li>为确定变量及其关系作出假设，建立模型</li>
<li>求解模型得到数学解</li>
<li>解释模型并将其与现实世界的观察对照</li>
</ul>
<h2 id="积分法则与替换积分法"><a href="#积分法则与替换积分法" class="headerlink" title="积分法则与替换积分法"></a>积分法则与替换积分法</h2><p>现在知道，要求不定积分，就是找出”一个“反导数，再加上积分常数即可。寻找反导数时，最简单的情形就是直接对应导数表的情形。略复杂的则是采用反导数的代数法则，这个可以通过导数的代数法则推导而来。</p>
<p>例：求$\sin^2x$的积分</p>
<p>解：$\int \sin^2xdx &#x3D; \int \frac{1-\cos2x}{2}dx &#x3D; \frac{x}{2} - \frac{\sin2x}{4} + C$</p>
<h3 id="积分形式的幂法则"><a href="#积分形式的幂法则" class="headerlink" title="积分形式的幂法则"></a>积分形式的幂法则</h3><p>若$u$是$x$的可微函数，那么由链式法则有$\frac{d}{dx} (\frac{u^{n+1}}{n+1}) &#x3D; u^n \frac{du}{dx}$，反过来即有</p>
<p>$$\int (u^n \frac{du}{dx})dx &#x3D; \frac{u^{n+1}}{n+1} + C$$</p>
<p>等式左边可以用更简单的<strong>微分</strong>形式：$\int u^ndu$，这里将$\frac{du}{dx} dx$写成$du$像是把$dx$给抵消了。也可以这样理解，$du &#x3D; u’dx &#x3D; \frac{du}{dx}dx$。关键是，转化为这种形式后，就可以看作是直接求关于$u$的积分。</p>
<p>例：$\int \sqrt{1+y^2} \cdot 2ydy &#x3D; \int u^{1&#x2F;2}du &#x3D; \frac{2}{3}u^{3&#x2F;2} + C &#x3D; \frac{2}{3}(1+y^2)^{3&#x2F;2} + C$</p>
<p>此法则实际上给出了一种更通用的积分法，即链式法则的逆用。其关键是找出一个合适的中间函数$u$，将原积分转换为关于$u$的积分，而且后者更容易求解。这就是<strong>替换法</strong>。</p>
<h3 id="替换积分法"><a href="#替换积分法" class="headerlink" title="替换积分法"></a>替换积分法</h3><p>上述思想之推广。</p>
<h2 id="用有限和估计（Estimating-with-finite-sums）"><a href="#用有限和估计（Estimating-with-finite-sums）" class="headerlink" title="用有限和估计（Estimating with finite sums）"></a>用有限和估计（Estimating with finite sums）</h2><p>用有限和估计，我们最熟悉的大概是求曲线所围的图形之面积，或是求圆的面积，球体的体积之类的问题。另外，考虑通过速度函数求位移，和面积本质上也是一样的。这些问题都是先将区间切分为几个小区间，然后在每个小区间上取某个点的函数值，求其于区间长度之乘积，然后再求和。这个”和“是真实值的近似值，而且当切分地越来越细时，误差也会减少。这就是为什么称之为<strong>有限和估计</strong>。</p>
<p>再来看一个不那么明显的问题。假设有一个非负函数，比如$y &#x3D; x^2$，那么它在闭区间$[-1, 1]$上是否有<strong>平均值</strong>？</p>
<p>一般而言，平均值所涉乃是有限个值的算数平均值，那么对于连续区间上的值来说，平均是什么意思呢？如果我们考虑对函数值随机抽样，从值域中随机抽取相当多个值，那它们的平均值是不是可以算作<strong>平均值</strong>的近似呢？这样，我们不妨认为平均值是有意义的。一旦有了意义，那么实际上函数平均值还可以有更直观的理解。我们把原曲线与数轴所围之图形归约为同面积的矩形，平均值就是该矩形的<strong>宽</strong>，矩形的长已知，而矩形的面积等于曲线梯形的面积，此面积可由上述有限和估计的思路求得，如此一来，平均值可用面积除以区间长度而得到！这确实是很让人意外的结果：）</p>
<p>综上，不论是面积、位移还是平均值，我们都把问题归结为同一个问题：<strong>函数值乘以子区间长度之和</strong>。该有限和随着子区间的细分而越发精确。在位移问题中，一段时间的位移，可以通过先求速度函数的反导数，在代入反导数求值得到。那么这一类问题与反导数的关系是巧合吗？反导数是否也可用于面积与平均值问题？答案当然是肯定的：）</p>
<p>例：通过正多边形面积估计圆的面积，圆取单位圆，其面积为$\pi$，多边形的边数取4、8、16这样。</p>
<p>解：圆的内接正多边形面积可用下面的函数表示（Python）</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">s</span>(<span class="params">n</span>):</span><br><span class="line">    theta = <span class="number">2</span> * math.pi/n</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0.5</span> * n * math.sin(theta)</span><br><span class="line">     </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">16</span>):</span><br><span class="line">    n = <span class="number">2</span> ** i</span><br><span class="line">    <span class="built_in">print</span>(n, area(n))</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">4 2.0</span><br><span class="line">8 2.82842712474619</span><br><span class="line">16 3.0614674589207183</span><br><span class="line">32 3.121445152258052</span><br><span class="line">64 3.1365484905459393</span><br><span class="line">128 3.140331156954753</span><br><span class="line">256 3.141277250932773</span><br><span class="line">512 3.141513801144301</span><br><span class="line">1024 3.1415729403670913</span><br><span class="line">2048 3.1415877252771596</span><br><span class="line">4096 3.1415914215111997</span><br><span class="line">8192 3.1415923455701176</span><br><span class="line">16384 3.1415925765848725</span><br><span class="line">32768 3.1415926343385627</span><br></pre></td></tr></table></figure>

<p>可以看到多边形的面积确实是越来越接近圆面积的。</p>
<h2 id="黎曼和与定积分"><a href="#黎曼和与定积分" class="headerlink" title="黎曼和与定积分"></a>黎曼和与定积分</h2><p>上述的<strong>有限和估计</strong>中，和中的项由选择的函数值乘以子区间长度而得。那么怎样让估计的误差越来越小？甚至是能否求出准确值？本节来考虑这些问题，由有限和的定义出发，所考虑的两点是：让子区间越来越小趋近于零，选择的函数值对最终值有何影响？</p>
<h3 id="黎曼和"><a href="#黎曼和" class="headerlink" title="黎曼和"></a>黎曼和</h3><p>我们感兴趣的<strong>有限和</strong>是<strong>黎曼和</strong>，以伟大的数学家黎曼（Riemann）命名。现在给出黎曼和的准确定义。</p>
<p>$f(x)$是定义在闭区间$[a, b]$上的任意连续函数。将区间分割为$n$个子区间，$a$和$b$之间的分点记作$x_1, x_2, \cdots,x_{n-1}$，它们依次递增。为统一起见，记$a$为$x_0$，$b$为$x_n$，那么集</p>
<p>$${ x_0, x_1, \cdots, x_n }$$</p>
<p>称为$[a, b]$的一个<strong>划分</strong>。划分$P$定义$n$个闭子区间</p>
<p>$$[x_0, x_1], [x_1, x_2], \cdots, [x_{n-1}, x_n]$$</p>
<p>$[x_{k-1}, x_k]$称为$P$的<strong>第$k$个子区间</strong>，其长度为$\Delta x_k &#x3D; x_k - x_{k-1}$。</p>
<p>在每个子区间中，我们选择某个数，以$c_k$表示从第$k$个子区间中所选者。在每个子区间上，竖起一个垂直矩形，立于$x$轴，在$(c_k, f(x_k))$点接触曲线（与曲线相交，但在子区间上并不限于此一交点）。</p>
<p>在每个子区间上，作乘积$f(c_k) \cdot \Delta x_k $，乘积符号取决于$f(c_k)$。</p>
<p>最后，对乘积求和，$s_n &#x3D; \displaystyle\sum_{k&#x3D;1}^{n} f(c_k) \cdot \Delta x_k$。这个依赖于<strong>划分</strong>$P$和数$c_k$的选择的<strong>和</strong>是$f$在区间$[a, b]$上的<strong>黎曼和</strong>。</p>
<p>其中步骤可以总结为：</p>
<ol>
<li>作<strong>划分</strong></li>
<li>在每个子区间上<strong>选择数</strong></li>
<li>在每个子区间上<strong>作乘积</strong></li>
<li>对乘积求和</li>
</ol>
<p>随着划分不断变细，我们期望由划分确定的诸举行逼近$x$轴与$f$曲线之间区域的精度随之提高。与正多边形逼近圆的面积类似，<strong>我们期望该黎曼和有一个极限值</strong>。</p>
<p>求函数极限时，我们说$x$与$x_0$距离越来越小，那么对于黎曼和来说，我们需要<strong>划分不断变细</strong>。定义最长子区间的长度为划分的<strong>模</strong>，记为$||P||$，那么要求黎曼和的极限，我们需要$||P||$趋于零。如果该极限确实存在，那么称为<strong>定积分</strong>。</p>
<h3 id="定积分"><a href="#定积分" class="headerlink" title="定积分"></a>定积分</h3><p><strong>定义</strong>：设$f(x)$是定义在闭区间$[a, b]$上的一个函数，对于区间上的任意划分$P$，设$c_k$是$P$的第$k$个子区间上任意选取的数。如果存在一个数$I$，使得不论$P$和$c_k$如何选择，都有</p>
<p>$$\lim_{||P|| \to 0} \displaystyle\sum_{k&#x3D;1}^{n} f(c_k) \Delta x_k &#x3D; I$$</p>
<p>则称$f$在$[a, b]$上是<strong>可积的</strong>，而$I$称为$f$在区间$[a, b]$上的<strong>定积分</strong>。</p>
<p>黎曼和和定积分的定义没有告诉我们如何确定定积分是否存在，故下面的定理非常有用：</p>
<p><strong>定积分的存在性</strong>：</p>
<p>所有连续函数是可积的，即如果一个函数在$[a, b]$上是连续的，那么它在该区间上的定积分存在。</p>
<h3 id="定积分表示"><a href="#定积分表示" class="headerlink" title="定积分表示"></a>定积分表示</h3><p>按莱布尼兹的记号，上述由黎曼和极限表示的定积分可以表示为</p>
<p>$$\int_{a}^{b} f(x)dx$$</p>
<p>读作”从$a$到$b$，$f(x)dx$的积分“，或”从$a$到$b$，$f(x)$对于$x$的积分“。$a$、$b$分别称为积分，$f(x)$为<strong>被积函数</strong>，$x$是<strong>积分变量</strong>。</p>
<p>函数在任何特定区间上的定积分值依赖于函数而不依赖于表示其自变量的字母。对于同一函数$f$，不论积分变量是$x$还是$t$，其结果都是同一个数。故积分变量称为<strong>哑元</strong>。</p>
<h3 id="定积分与曲面梯形之面积"><a href="#定积分与曲面梯形之面积" class="headerlink" title="定积分与曲面梯形之面积"></a>定积分与曲面梯形之面积</h3><p>现在再考虑之前以有限和估计面积，会发现小矩形面积之和正是<strong>黎曼和</strong>。那么对于在$[a, b]$上可积的非负函数来说，该区间对应的<strong>曲线下的面积定义为定积分的值</strong>。</p>
<p>有了这一定义，我们可以从面积计算积分，反之亦然。</p>
<h3 id="函数平均值"><a href="#函数平均值" class="headerlink" title="函数平均值"></a>函数平均值</h3><p>类似地，可以定义<strong>函数的平均（中）值</strong>：</p>
<p>若$f$在$[a, b]$上可积，则它在$[a, b]$上的平均值是</p>
<p>$$av(f) &#x3D; \frac{1}{b-a} \int_{a}^{b} f(x)dx$$</p>
<h3 id="定积分的性质"><a href="#定积分的性质" class="headerlink" title="定积分的性质"></a>定积分的性质</h3><p>在定积分的定义中，由于它定义在闭区间上，那么自然地上限大于下限。但我们可以将定义扩展到上限小于或等于下限的情形：</p>
<ul>
<li>$\int_{a}^{b}f(x)dx &#x3D; -\int_{b}^{a}f(x)dx$</li>
<li>$\int_{a}^{a}f(x)dx &#x3D; 0$</li>
</ul>
<p>以面积来思考，可以从直观上得到其它几条性质</p>
<ul>
<li>可加性：$\int_{a}^{b}f(x)dx + \int_{b}^{c}f(x)dx &#x3D; \int_{a}^{c}f(x)dx$</li>
<li>最大-最小表达式</li>
<li>控制：$f(x) \geq g(x) \Rightarrow \int_{a}^{b}f(x)dx \geq \int_{a}^{b}g(x)dx$</li>
</ul>
<h2 id="中值定理与基本定理（The-mean-value-and-fundamental-theorems）"><a href="#中值定理与基本定理（The-mean-value-and-fundamental-theorems）" class="headerlink" title="中值定理与基本定理（The mean value and fundamental theorems）"></a>中值定理与基本定理（The mean value and fundamental theorems）</h2><p>本节介绍<strong>积分学的两个最重要的定理</strong>，即定积分的中值定理和基本定理。基本定理至今仍被看作<strong>历史上最重要的计算方面的发现</strong>。</p>
<h3 id="中值定理"><a href="#中值定理" class="headerlink" title="中值定理"></a>中值定理</h3><p>定理：如果$f$在$[a, b]$上连续，则在$[a, b]$中的某点$c$有</p>
<p>$$f(c) &#x3D; \frac{1}{b-a} \int_{a}^{b}f(x)dx$$</p>
<p>证：由积分的最大-最小法则有$\min f \leq \frac{1}{b-a} \int_{a}^{b}f(x)dx \leq \max f$</p>
<p>因为$f$是连续的，根据<strong>连续函数的中值定理</strong>可知，必定存在$[a, b]$中的某点$c$可以取到所要求的函数平均值。</p>
<p>该定理的<strong>连续性</strong>是关键。</p>
<h3 id="微积分基本定理的第一部分"><a href="#微积分基本定理的第一部分" class="headerlink" title="微积分基本定理的第一部分"></a>微积分基本定理的第一部分</h3><p>如果$f$是一个可积函数，那么从固定数$a$到另一数$x$的积分定义一个函数$F$，它的值是</p>
<p>$$F(x) &#x3D; \int_{a}^{x}f(t)dt$$</p>
<p>$F$由定积分表达式表示，但这确实是一个有效的函数定义。对于每一个$x$，均有唯一确定的值与之对应，此函数值即相应的定积分——一个数字。这个函数的定义与迄今所见的通常的函数定义相比，有点奇怪，但它是极为重要的，因为它建立起了积分和导数之间的联系，这就是<strong>基本定理的第一部分</strong>：</p>
<p>如果如果$f$在$[a, b]$上连续，则函数</p>
<p>$$F(x) &#x3D; \int_{a}^{x}f(t)dt$$</p>
<p>在$[a, b]$的每个点$x$都可导，且</p>
<p>$$\frac{dF}{dx} &#x3D; \frac{d}{dx} \int_{a}^{x}f(t)dt &#x3D; f(x)$$</p>
<p>也就是说$F(x)$的导数为$f(x)$。这一结论无疑是优美、深刻且令人惊异的，而该等式也成为数学中最重要的等式之一。它告诉我们每个连续函数必然是另一个函数的导数，它说明了积分和微分的过程是可逆的。</p>
<p>注意：这里等式$a$没有出现，这意味着无论积分下限取什么值，等式都成立。</p>
<p>例：$\frac{d}{dx} \int_{-p}^{x} costdt &#x3D; \cos x$</p>
<p>$\int_{a}^{x}f(t)dt$是关于$x$的函数，尽管形式上与之前所见不太寻常，但我们大可以将其看作某个函数$F(x)$，它本质上就是一个寻常的函数。</p>
<p>例：求$y &#x3D; \int_{1}^{x^2} \cos t dt$的导数。</p>
<p>解：此函数可以看作$F(x) &#x3D; \int_{1}^{x} \cos t dt$与$u &#x3D; x^2$的复合函数，应用链式法则得到：</p>
<p>$$\frac{dy}{dx} &#x3D; \frac{dy}{du} \cdot \frac{du}{dx} &#x3D; \cos u \cdot \frac{du}{dx}$$</p>
<p>$$ &#x3D; cos(x^2) \cdot 2x &#x3D; 2x \cos x^2$$</p>
<p>基本定理的第一部分证明这里从略，只提一下可以用定积分的中值定理证明。</p>
<h3 id="微积分基本定理的第二部分"><a href="#微积分基本定理的第二部分" class="headerlink" title="微积分基本定理的第二部分"></a>微积分基本定理的第二部分</h3><p>应用导数的中值定理推论2，可以证明<strong>微积分基本定理的第二部分</strong>：如果$f$在$[a, b]$的每个点连续，而$F$是$f$在$[a, b]$的任何一个反导数，则有</p>
<p>$$\int_{a}^{b} f(x)dx &#x3D; F(b) - F(a) &#x3D; \left.F(x)\right|_a^b$$</p>
<p>这一等式的形式很简单，但它的威力却是极强的。本来定积分的定义来自于黎曼和的极限，而要求这个极限是颇为繁琐的，涉及划分、函数值的选取和极限的求值，变化颇多，但这一等式却把整个过程简化为反导数的求解这一问题。无怪乎这个等式成为”基本定理“的一部分了。</p>
<h3 id="面积计算"><a href="#面积计算" class="headerlink" title="面积计算"></a>面积计算</h3><p>有了基本定理，面积的求解就成为了一个”计算“问题，只是要注意定积分不会区分”正面积“与”负面积“，一般我们所说的”面积“是两种面积绝对值之和，因此需要先确定负面积之区间。</p>
<h2 id="定积分的变量替换（Substitution-in-Definite-Integrals）"><a href="#定积分的变量替换（Substitution-in-Definite-Integrals）" class="headerlink" title="定积分的变量替换（Substitution in Definite Integrals）"></a>定积分的变量替换（Substitution in Definite Integrals）</h2><p>根据基本定理第二部分，求解定积分时，可以先求不定积分，这样不定积分的各种方法就用得上了，比如”替换积分法“。</p>
<p>另一方面，对定积分而言，它还可以直接应用变量替换。即：</p>
<p>$$\int_{a}^{b} f(g(x)) \cdot g’(x) dx &#x3D; \int_{g(a)}^{g(b)} f(u) du$$</p>
<p>也就是说，变量替换之后，我们只要求新的（期望是简化了的）函数的积分，其积分上下限需要做相应的修改。</p>
<p>例：求$\int_{-1}^{1} 3x^2 \sqrt{x^3+1}dx$</p>
<p>解：令$u &#x3D; x^3 + 1$，则原积分等于$\int_{0}^{2}\sqrt{u}du &#x3D; \frac{4\sqrt{2}}{3}$。</p>
<p>作为一种选择，可以先求反导数再行计算。虽然在本例中，定积分的变量替换更简单，但并不总是如此，因此这两种方法都需要了解。</p>
<h3 id="曲线之间的面积"><a href="#曲线之间的面积" class="headerlink" title="曲线之间的面积"></a>曲线之间的面积</h3><p>若$f$和$g$连续且在$[a, b]$上有$f(x) \geq g(x)$，则在从$a$到$b$的两条曲线之间区域的面积是：</p>
<p>$$A &#x3D; \int_{a}^{b}(f(x) - g(x))dx$$</p>
<h2 id="数值积分"><a href="#数值积分" class="headerlink" title="数值积分"></a>数值积分</h2><p>根据基本定理，对定积分求值时，最理想的方式是先求反导数再代入计算，但某些函数的反导数难以计算，甚至像$\frac{\sin x}{x}$和$\sqrt{1+x^4}$的反导数没有初等表达式。</p>
<p>当我们不能直接用反导数求出定积分的值时，我们转向梯形法和Simpson法这样的<strong>数值方法</strong>。</p>
<h3 id="梯形法"><a href="#梯形法" class="headerlink" title="梯形法"></a>梯形法</h3><p>在考虑有关定积分的问题时，用面积问题来获取直观理解是很有帮助的。求定积分即求曲边梯形的面积，如果我们把区间划分为多个小区间，那么在每个小区间上可以用简单曲线来近似原曲线。那么最简单的曲线就是直线了，采用直线近似时，在每个小区间上，用梯形面积近似原来的小曲边梯形的面积。当划分足够细，我们期望其误差足够小。</p>
<p>此方法除了可以直接应用于面积计算，也可以用于由离散值计算面积的近似值，因为若干连续分布的函数值，恰好是帮我们作好了一个划分：）比如有温度统计来计算一段时间的平均温度。</p>
<p>梯形法的误差分析从略。</p>
<h3 id="抛物线逼近（Simpson法）"><a href="#抛物线逼近（Simpson法）" class="headerlink" title="抛物线逼近（Simpson法）"></a>抛物线逼近（Simpson法）</h3><p>在上述面积近似问题中，如果我们用比直线复杂的抛物线来求近似值，我们期望误差会更小，这就是<strong>抛物线逼近法</strong>。</p>
<h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><h3 id="莱布尼兹法则"><a href="#莱布尼兹法则" class="headerlink" title="莱布尼兹法则"></a>莱布尼兹法则</h3><p>$$\frac{d}{dx} \int_{u(x)}^{v(x)} f(t)dt &#x3D; f(v(x)) \frac{dv}{dx} - f(u(x)) \frac{du}{dx}$$</p>
<p>证：设$F$是$f$的一个反导数，那么$\int_{u(x)}^{v(x)} f(t)dt &#x3D; F(v(x)) - F(u(x))$，对等式右边求导，应用链式法则即得到所需结论。</p>
<h1 id="积分的应用"><a href="#积分的应用" class="headerlink" title="积分的应用"></a>积分的应用</h1><p>从上章可见，积分用于函数”累积之效“类型的问题颇具威力，无论是面积、体积，还是位移等等。其基本之法，在于<strong>以黎曼和之形式表示欲求解之问题</strong>，从而转化为定积分问题。本章将在此思路上引介几种新类型的问题，亦可见积分应用之广泛。</p>
<h2 id="切片法求体积和绕轴旋转"><a href="#切片法求体积和绕轴旋转" class="headerlink" title="切片法求体积和绕轴旋转"></a>切片法求体积和绕轴旋转</h2><p>恰如矩形之于曲线面积，若以柱体近似体积，则有立体体积之定义：</p>
<p>已知从$x &#x3D; a$到$x &#x3D; b$横截面积$A(x)$的立体，如果$A(x)$可积，那么立体的体积是$V &#x3D; \int_{a}^{b} A(x)dx$。</p>
<p>在由小柱体近似立体体积时，就像将原立体切分为若干小的切片儿，此为<strong>切片法</strong>一名之由来。另外，由此定义可以立即得出中学几何中的<strong>卡瓦列里原理（祖暅原理）</strong>。</p>
<h3 id="旋转体之体积"><a href="#旋转体之体积" class="headerlink" title="旋转体之体积"></a>旋转体之体积</h3><p>若一立体由一图像旋转所得，如球体，圆锥体之类，则容易将此类立体的体积求解转化为上面的切片法基本定义。因为旋转体的横截面积容易求得。</p>
<p>略复杂一点的情形是，曲线可以沿$x$轴之外的点直线旋转，如$y$轴或平行于$y$轴的直线等，其思路是一样的。</p>
<p>再复杂一点的是<strong>垫圈形</strong>横截面。此时横截面是一个圆环，还是可以求出来。</p>
<h2 id="以圆柱薄壳模式计算体积"><a href="#以圆柱薄壳模式计算体积" class="headerlink" title="以圆柱薄壳模式计算体积"></a>以圆柱薄壳模式计算体积</h2><p>如果对$y$的积分不易计算，可转而考虑圆柱薄壳方法，这个方法比较巧妙，但仍是<strong>黎曼和</strong>的思路。</p>
<h2 id="平面曲线的长度"><a href="#平面曲线的长度" class="headerlink" title="平面曲线的长度"></a>平面曲线的长度</h2><p>你有没有想过，一个正弦波有多长？波长的通常意义是波的基本周期，对于$y &#x3D; \sin x$来说是$2 \pi$。那么现在再次祭出我们的<strong>黎曼和</strong>来，看看能否解决之。</p>
<p>先作区间的一个划分，每个小区间上，曲线的长度如何近似？首先可以考虑的就是两个端点见的割线长度，割线的长度是$\sqrt{\Delta x_k^2 + \Delta y_k^2}$。这一形式还不是我们熟悉的黎曼和，我们需要将其表示为$f(c_k)\Delta x_k$的形式，通过变形有如下等式：</p>
<p>$$\sqrt{\Delta x_k^2 + \Delta y_k^2} &#x3D; \sqrt{1 + (\frac{\Delta y_k}{\Delta x_k})^2} \Delta x_k$$</p>
<p>而根据可微函数的中值定理，小区间上存在点$c_k$，使得$\frac{\Delta y_k}{\Delta x_k} &#x3D; sin’c_k$，这样就得到了黎曼和。最终我们要求的波长为定积分：</p>
<p>$$\int_{0}^{2\pi} \sqrt{1+(sin’x)^2}dx \approx 7.64$$</p>
<p>注：在对一般函数应用上述计算过程时，函数需满足两个条件。首先函数是<strong>可微的</strong>，此外欲求积分，还要求函数的<strong>导函数是连续的</strong>。总之，此法求解曲线长度的要求是<strong>函数有连续的一阶导数</strong>。这一要求称为<strong>光滑</strong>，中学时所接触的函数都是光滑的，所以那时候老师总是说，要以光滑的曲线连接起几个点了，这就是其依据了。</p>
<p>其它长度形式暂从略。</p>
<h2 id="弹簧、泵吸和提升；流体力；矩和质心"><a href="#弹簧、泵吸和提升；流体力；矩和质心" class="headerlink" title="弹簧、泵吸和提升；流体力；矩和质心"></a>弹簧、泵吸和提升；流体力；矩和质心</h2><p>此三节内容不甚熟悉，暂亦不需要，从略。</p>
<h1 id="超越函数（Transcendental-Functions）和微分方程（Differential-Equations）"><a href="#超越函数（Transcendental-Functions）和微分方程（Differential-Equations）" class="headerlink" title="超越函数（Transcendental Functions）和微分方程（Differential Equations）"></a>超越函数（Transcendental Functions）和微分方程（Differential Equations）</h1><p>至此我们对有理函数、三角函数的导数和积分有了一定了解，接下来就是极重要的对数函数和指数函数。函数$y &#x3D; \ln x$在中学里只是一种特殊的对数函数，但学习了积分后，我们可以以另一种方式定义它，其中隐含的数学概念间的关联是让人颇感新奇的。</p>
<h2 id="对数"><a href="#对数" class="headerlink" title="对数"></a>对数</h2><p><strong>定义</strong>：正数$x$的自然对数，记作$\ln x$，是一个积分值：</p>
<p>$$\ln x &#x3D; \int_{1}^{x} \frac{1}{t}dt, x &gt; 0$$</p>
<p>注意到被积函数总是取正值的。若$x &gt; 1$，$\ln x$是曲线下区域的面积；若$0 &lt; x &lt; 1$，$\ln x$给出曲线下面积之负值；若$x \leq 0$，则函数无定义。还有，$\ln 1 &#x3D; 0$</p>
<h3 id="对数函数的导数"><a href="#对数函数的导数" class="headerlink" title="对数函数的导数"></a>对数函数的导数</h3><p>根据基本定理，易得自然对数函数的导数，即：</p>
<p>$$\frac{d}{dx} \ln x &#x3D; \frac{1}{x}$$</p>
<p>所以导数总为正，函数在定义域内是递增的，二阶导数则恒为负，$\ln x$的图像是凹向下的。</p>
<p>进一步，由链式法则可知，复合函数$\frac{d}{dx}\ln u &#x3D; \frac{1}{u} \frac{du}{dx}$。</p>
<p>下面是对数的三个法则：</p>
<ul>
<li>$\ln ax &#x3D; \ln a + \ln x$</li>
<li>$\ln \frac{a}{x} &#x3D; \ln a - \ln x$</li>
<li>$\ln x^n &#x3D; n \ln x$</li>
</ul>
<h3 id="int-1-u-du-的积分"><a href="#int-1-u-du-的积分" class="headerlink" title="$\int (1&#x2F;u)du$的积分"></a>$\int (1&#x2F;u)du$的积分</h3><p>看起来有点无赖，但我们将积分定义为对数函数后，这一类函数的积分就有了显式的表达式了，是故：</p>
<p>$$\frac{1}{u} &#x3D; \ln |u| + C$$</p>
<p>到这里，所有形如$u^ndu$的积分都可以求解了，其中包括了$\tan x$和$\cot x$：</p>
<ul>
<li>$\int \tan x dx &#x3D; \ln |\sec x| + C$</li>
<li>$\int \tan x dx &#x3D; -\ln |\csc x| + C$</li>
</ul>
<h3 id="对数微分法"><a href="#对数微分法" class="headerlink" title="对数微分法"></a>对数微分法</h3><p>在表达式涉及指数式，对数可将其大幅度简化为几个对数的四则运算，辅之以链式法则，这就是<strong>对数微分法</strong>。</p>
<p>例：求$y &#x3D; \frac{(x^2+1)(x+3)^{1&#x2F;2}}{x-1}$的导数。</p>
<p>解：$\ln y &#x3D; \ln (x^2+1) + \frac{1}{2}\ln (x+3) - \ln (x-1)$，余略。</p>
<h3 id="log-a-u-的导数"><a href="#log-a-u-的导数" class="headerlink" title="$\log_a u$的导数"></a>$\log_a u$的导数</h3><p>先采用换底公式将其转换为自然对数，它只比自然对数多了一个常系数。</p>
<h2 id="指数函数"><a href="#指数函数" class="headerlink" title="指数函数"></a>指数函数</h2><p>中学数学中，对数函数定义为指数函数的反函数。现在对数函数借由积分定义了出来，指数函数定义为对数函数的反函数。在导数已经提及，一个函数与其反函数存在着一定的关系，即：</p>
<p>$$(f^{-1})’ &#x3D; \frac{1}{f’}$$</p>
<p>需要注意的是，$f$上的点$(a, f(a))$对应于$f^{-1}$上的$(f(a), a)$。</p>
<p>函数$\ln x$定义域为全体正实数，且是增函数，那么它有自己的反函数。我们把$\ln^{-1} 1$用$e$表示。</p>
<p>$e$是一个无理数，且是超越数。</p>
<h3 id="自然指数函数"><a href="#自然指数函数" class="headerlink" title="自然指数函数"></a>自然指数函数</h3><p>$e$是一个正实数，那么我们可以定义以它为底的指数函数$y &#x3D; e^x$。对其求对数，有：</p>
<p>$$\ln e^x &#x3D; x \ln e &#x3D; x$$</p>
<p>所以$y &#x3D; e^x$实际上就是$y &#x3D; \ln x$的反函数。</p>
<h3 id="e-x-的导数与积分"><a href="#e-x-的导数与积分" class="headerlink" title="$e^x$的导数与积分"></a>$e^x$的导数与积分</h3><p>使用对数积分法，可以得到一个结论：</p>
<p>$$\frac{d}{dx} e^x &#x3D; e^x$$</p>
<p>注：<a href="https://zh.wikipedia.org/zh-cn/%E8%B6%85%E8%B6%8A%E6%95%B8">超越数</a></p>
<h3 id="a-x-的导数与积分"><a href="#a-x-的导数与积分" class="headerlink" title="$a^x$的导数与积分"></a>$a^x$的导数与积分</h3><p>根据对数函数的性质，$a^x &#x3D; e^{x \ln a}$，所以一般指数函数的导数可以转化为自然指数的导数：</p>
<p>$$\frac{d}{dx}a^x &#x3D; \ln a a^x$$</p>
<p>由此可知，若$a &gt; 1$，那么导数为正，函数递增，否则导数为负，函数递减。而二阶导数恒为正，所以指数函数总是凹向上的。</p>
<p>由上述导数可求得指数函数的积分：</p>
<p>$$\int a^xdx &#x3D; \frac{1}{\ln a}a^x + C$$</p>
<p>例：求$\int \frac{dx}{1+e^x}$</p>
<p>解：令$u &#x3D; 1 + e^x$，则有$dx &#x3D; \frac{du}{u-1}$，同时利用等式$\frac{1}{u} \cdot \frac{1}{u-1} &#x3D; \frac{1}{u-1} - \frac{1}{u}$可解。</p>
<h2 id="反三角函数的导数与积分"><a href="#反三角函数的导数与积分" class="headerlink" title="反三角函数的导数与积分"></a>反三角函数的导数与积分</h2><p>反三角函数在数学、物理与工程上应用颇为广泛，本节讨论其导数与积分。上节提到对数微分法，反三角函数的导数求解起来也有类似思路。</p>
<h3 id="反三角函数的导数"><a href="#反三角函数的导数" class="headerlink" title="反三角函数的导数"></a>反三角函数的导数</h3><p>$y &#x3D; \sin^{-1} x$，故$\sin y &#x3D; x$，两边求导有：</p>
<p>$$\frac{dy}{dx} &#x3D; \frac{1}{\cos y} &#x3D; \frac{1}{\sqrt{1-x^2}}$$</p>
<p>类似地，$\frac{d}{dx}(\tan^{-1} x) &#x3D; \frac{1}{1+x^2}$，$\frac{d}{dx}(\sec^{-1} x) &#x3D; \frac{1}{|x|\sqrt{x^2-1}}$</p>
<p>对另外三个反三角函数（余..），利用它们与上面三个（正..）函数的关系可知，它们的导数是相对应函数导数的负值。</p>
<h3 id="反三角函数的相关积分"><a href="#反三角函数的相关积分" class="headerlink" title="反三角函数的相关积分"></a>反三角函数的相关积分</h3><p>从导数反推过来，得到：</p>
<ul>
<li>$\int \frac{du}{\sqrt{a^2 - u^2}} &#x3D; \sin^{-1}(\frac{u}{a}) + C$</li>
<li>$\int \frac{du}{a^2 + u^2} &#x3D; \frac{1}{a} \tan^{-1}(\frac{u}{a}) + C$</li>
<li>$\int \frac{du}{u\sqrt{u^2 - a^2}} &#x3D; \frac{1}{a} \sec^{-1}|\frac{u}{a}| + C$</li>
</ul>
<h2 id="一阶可分离变量微分方程"><a href="#一阶可分离变量微分方程" class="headerlink" title="一阶可分离变量微分方程"></a>一阶可分离变量微分方程</h2><p>（Linear First Order Differential Equations）</p>
<p>在初次接触隐函数求导法时会发现，导数$\frac{dy}{dx}$的表达式中经常同时包含变量$x$和$y$，本节讨论的初值问题中就包含此类形式的导数。</p>
<p><strong>一阶微分方程</strong>是关系</p>
<p>$$\frac{dy}{dx} &#x3D; f(x, y)$$</p>
<p>方程右边是一个二元函数。此方程的一个<strong>解</strong>是定义在关于$x$值的一个区间上的可微函数$y(x)$，使得在此区间上</p>
<p>$$\frac{dy}{dx} &#x3D; f(x, y(x))$$</p>
<p>例：函数$y &#x3D; \frac{1}{x} + \frac{x}{2}$是方程$\frac{dy}{dx} &#x3D; 1 - \frac{y}{x}$的一个解。</p>
<h3 id="可分离变量方程"><a href="#可分离变量方程" class="headerlink" title="可分离变量方程"></a>可分离变量方程</h3><p>方程$y’ &#x3D; f(x, y)$是<strong>可分离变量</strong>的，如果$f$可表示为一个$x$的函数与一个$y$的函数的乘积。此时方程有形式</p>
<p>$$\frac{dy}{dx} &#x3D; g(x)h(y)$$</p>
<p>若$h(y) \neq 0$，那么</p>
<p>$$\frac{1}{h(y)}\frac{dy}{dx} &#x3D; g(x)，两边取积分$$</p>
<p>$$\int \frac{1}{h(y)}\frac{dy}{dx} dx &#x3D; \int g(x)dx，即$$</p>
<p>$$\int \frac{1}{h(y)}dy &#x3D; \int g(x)dx$$</p>
<p>此时$x$和$y$已经分离，接下来积分两端，把$y$表示为$x$的显函数或隐函数。</p>
<h2 id="线性一阶微分方程"><a href="#线性一阶微分方程" class="headerlink" title="线性一阶微分方程"></a>线性一阶微分方程</h2><p>如果一阶微分方程可以写成形式</p>
<p>$$\frac{dy}{dx} + P(x)y &#x3D; Q(x)$$</p>
<p>则它是<strong>线性</strong>一阶微分方程，此形式是它的<strong>标准形式</strong>。</p>
<p>例：把下面方程表示成标准形式：$x \frac{dy}{dx} &#x3D; x^2 + 3y, x &gt; 0$</p>
<p>解：方程可以变形为：$\frac{dy}{dx} - \frac{3}{x}y &#x3D; x$，是为标准形式。</p>
<h3 id="标准形式的解"><a href="#标准形式的解" class="headerlink" title="标准形式的解"></a>标准形式的解</h3><p>线性方程</p>
<p>$$\frac{dy}{dx} + P(x)y &#x3D; Q(x)$$</p>
<p>的解是</p>
<p>$$y &#x3D; \frac{1}{v(x)} \int v(x)Q(x)dx$$</p>
<p>其中</p>
<p>$$v(x) &#x3D; e^{\int P(x)dx}$$</p>
<p>在$v$的公式中，我们不需要$P(x)$的最一般形式的反导数，任一反导数都适用。</p>
<p>具体求解可参考书本。大体先使用<strong>分部积分</strong>的思路，使用一个未知的$v$辅助，而$v$本身的求解是一个较简单的可分离变量微分方程。</p>
<h2 id="Euler法"><a href="#Euler法" class="headerlink" title="Euler法"></a>Euler法</h2><p>如果我们不需要或者不能够理解求得初值问题$y’ &#x3D; f(x, y), y(x_0) &#x3D; y_0$的<em>精确解</em>，那么或许可以使用计算机产生一个表，列出在一个适当区间内的$x$值和对应的$y$的近似值，这样的一个表称为问题的<strong>数值解</strong>，而生成此表的方法称为<strong>数值方法</strong>。数值方法一般是快速和准确的。本节涉及的是<strong>Euler法</strong>。</p>
<h3 id="Euler法（Euler’s-Method）"><a href="#Euler法（Euler’s-Method）" class="headerlink" title="Euler法（Euler’s Method）"></a>Euler法（Euler’s Method）</h3><p>给定微分方程$y’ &#x3D; f(x, y)$和初条件$y(x_0) &#x3D; y_0$，我们可以用它的<strong>线性化</strong></p>
<p>$$L(x) &#x3D; y(x_0) + y’(x_0)(x - x_0)$$</p>
<p>来逼近解。函数$L$给出解在$x_0$附近的一个小区间上的好的逼近，Euler法的原理是把一系列线性化拼接起来以便在一个较长的区间上逼近曲线。这是一个迭代的过程，其结果是一条折线来近似原来解的曲线。</p>
<h2 id="双曲函数（Hyperbolic-Functions）"><a href="#双曲函数（Hyperbolic-Functions）" class="headerlink" title="双曲函数（Hyperbolic Functions）"></a>双曲函数（Hyperbolic Functions）</h2><p>注：<a href="https://zh.wikipedia.org/wiki/%E5%8F%8C%E6%9B%B2%E5%87%BD%E6%95%B0">双曲函数</a></p>
<p>每个定义在以原点为中心的区间上的函数都能以唯一的方式写成一个偶函数和一个奇函数的和：</p>
<p>$$f(x) &#x3D; \frac{f(x) + f(-x)}{2} + \frac{f(x) - f(-x)}{2}$$</p>
<p>在等式右边，第一部分是偶部分，第二部分是奇部分。如果以这种方式分写$e^x$，它的偶部分和奇部分分别称为<strong>双曲余弦</strong>和<strong>双曲正弦</strong>。它们都是有用的函数，可用以描述弹性固体中波的运动，悬挂的电能线的形状等。</p>
<h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>$$\cosh x &#x3D; \frac{e^x + e^{-x}}{2}$$<br>$$\sinh x &#x3D; \frac{e^x - e^{-x}}{2}$$</p>
<p>按一般三角函数的方式可以定义出另外四个双曲三角函数，更奇妙的是它们之间满足一些恒等式，看起来颇近于一般的三角恒等式。甚至连导数和积分也是如此。</p>
<p>然后也可以定义<strong>反双曲函数</strong>，它们的主要应用体现在积分中。比如我们有导数</p>
<p>$$\frac{d(\tanh^{-1} x)}{dx} &#x3D; \frac{1}{1-x^2}$$</p>
<p>那么右侧看起来很简单的函数的积分就可由反双曲函数来表示了。</p>
<h1 id="积分技术、洛必达法则和反常积分"><a href="#积分技术、洛必达法则和反常积分" class="headerlink" title="积分技术、洛必达法则和反常积分"></a>积分技术、洛必达法则和反常积分</h1><p>至此已经对积分及其应用有了一定的了解。具体的积分法，主要是两个：代数处理和变量替换。前者让我们得以处理函数的组合或对函数进行必要的变换，后者则借由链式法则将被积函数简化为更熟悉的函数。本章将介绍更为复杂的方法，即<strong>分部积分</strong>，然后将积分推广到某些<strong>反常</strong>的积分，即积分限是无穷的，或被积函数是无界的。此外，还介绍计算分式极限时非常有效的<strong>洛必达法则</strong>，尽管该法则实际上是约翰·伯努利发现的。</p>
<h2 id="基本积分公式"><a href="#基本积分公式" class="headerlink" title="基本积分公式"></a>基本积分公式</h2><p>此处是下载自Wikipedia的<a href="/files/lists_of_integrals.pdf">积分表</a>，有了这张表，加上代数处理和变量替换，我们已经能够对大量的函数求积。</p>
<h3 id="代数处理"><a href="#代数处理" class="headerlink" title="代数处理"></a>代数处理</h3><p>常见代数处理法有：</p>
<ul>
<li>配平方</li>
<li>三角恒等式</li>
<li>消去平方根：如$\sqrt{1 + \cos 4x} &#x3D; \sqrt{2 \cos^2 2x} &#x3D; \sqrt{2} |\cos 2x|$</li>
<li>化简假分式：使用分式除法（<a href="https://zh.wikipedia.org/wiki/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%95%BF%E9%99%A4%E6%B3%95">多项式长除法</a>）</li>
</ul>
<h2 id="分部积分"><a href="#分部积分" class="headerlink" title="分部积分"></a>分部积分</h2><p>乘积的积分一般不等于各因子积分之乘积。分部积分是简化函数乘积之积分的一种技术。</p>
<p>导数的乘法法则是：</p>
<p>$$(uv)’ &#x3D; u’v + v’u$$</p>
<p>两边关于$x$积分，得到$\int uv’dx &#x3D; \int (uv)’dx - \int vu’dx$，整理后得到如下公式：</p>
<p>$$\int udv &#x3D; uv - \int vdu$$</p>
<p>该公式将一个积分表示为第二个积分，当然我们期望的是第二个更容易求解。这里$u$和$v$的选取很关键，一般来说，首先需要求$dv$的积分，因此这一部分需要容易积分；其次$du$应至少不比原来的更复杂，这样才可能简化。</p>
<p>例：求$\int x \cos x dx$</p>
<p>解：按上面的两点来看，两因子的积分都易求，但如果选择$x$作为$v’$，那么新积分不会变得更容易，而选择$u &#x3D; x, dv &#x3D; \cos xdx$则满足要求。</p>
<p>例：求$\int \ln xdx$</p>
<p>解：令$u &#x3D; \ln x, v’ &#x3D; 1$。</p>
<h3 id="重复使用"><a href="#重复使用" class="headerlink" title="重复使用"></a>重复使用</h3><p>有时需要不止一次地使用分部积分，如$\int x^2e^xdx$。</p>
<p>上例重复使用时，所求积分逐渐简化，而有时需要求解两次积分，虽然看起来并没有简化，但已经足够求出，比如$\int e^x \cos xdx$。</p>
<h3 id="列表积分法"><a href="#列表积分法" class="headerlink" title="列表积分法"></a>列表积分法</h3><p>在重复使用分部积分时，其中的一个函数逐渐简化，由于其中的符号不断变化，可以考虑<strong>列表积分法</strong>。</p>
<h2 id="部分分式（Partial-Fractions）"><a href="#部分分式（Partial-Fractions）" class="headerlink" title="部分分式（Partial Fractions）"></a>部分分式（Partial Fractions）</h2><p>本节考虑有理函数的积分。</p>
<p>对于分式$\frac{1}{x(x-1)}$的积分，直接求解也可以，但还有更简单的方法，就是将其展开为两个分式$\frac{1}{x-1} - \frac{1}{x}$，这样一下就简单了很多。这种展开技术称为<strong>部分分式法</strong>，使用部分分式法，任一个有理函数都可以写成称为<strong>部分分式</strong>的基本分式之和，从而可以把有理函数的积分转化为部分分式积分之和。</p>
<p>这么做意味着部分分式的积分是易求的。果真如此吗？下面来仔细分析之。</p>
<h3 id="何为部分分式？"><a href="#何为部分分式？" class="headerlink" title="何为部分分式？"></a>何为部分分式？</h3><p>部分分式满足以下条件：</p>
<ul>
<li>分母须为不可约多项式（Irreducible Polynomial）或其幂</li>
<li>分子次数低于分母</li>
</ul>
<h3 id="分解为何种部分分式？"><a href="#分解为何种部分分式？" class="headerlink" title="分解为何种部分分式？"></a>分解为何种部分分式？</h3><p>对有理函数$\frac{f(x)}{g(x)}$，</p>
<ul>
<li>如果它不是真分式，那么先用$g(x)$除$f(x)$，之后对其余项进行操作。</li>
<li>得到真分式后，找到$g(x)$的因子。理论上，<strong>任何实系数多项式都可以写为实线性因式与实二次因式的乘积</strong>。</li>
<li>当$g(x)$因式已知时，使用待定系数法解之。</li>
</ul>
<h3 id="例"><a href="#例" class="headerlink" title="例"></a>例</h3><p>求积分</p>
<p>$$\int \frac{2x^3 - 4x^2 - x - 3}{x^2 - 2x - 3}dx$$</p>
<p>解：该分式不是真分式，先作除法化简之，得到原式$&#x3D; 2x + \frac{5x-3}{x^2 - 2x - 3}$。</p>
<p>接下来需要找出分子的因式，本例较简单，即$(x+1)(x-3)$。</p>
<p>然后使用待定系数法即$\frac{5x-3}{x^2 - 2x - 3} &#x3D; \frac{A}{x+1} + \frac{B}{x-3}$，消去分母，解联立方程组，得到各待定系数之值，剩下的就是对简单分式进行积分了。</p>
<h3 id="Heaviside-掩盖法"><a href="#Heaviside-掩盖法" class="headerlink" title="Heaviside 掩盖法"></a>Heaviside 掩盖法</h3><p>使用待定系数法时，若分母可分解为<strong>相异线性因式</strong>时，Heaviside法可以更快速地求出各系数之值。</p>
<h3 id="确定系数的其它方法"><a href="#确定系数的其它方法" class="headerlink" title="确定系数的其它方法"></a>确定系数的其它方法</h3><ul>
<li>求导法：求导可以降低多项式的次数</li>
<li>指定特定$x$的值：可以快速求解方程</li>
</ul>
<h2 id="三角替换"><a href="#三角替换" class="headerlink" title="三角替换"></a>三角替换</h2><p>三角替换能让我们用单个平方项代替二项式$a^2+x^2$，$a^2-x^2$和$x^2-a^2$，从而能使得<strong>含平方根的积分</strong>变换为可以直接求出的积分。</p>
<p>最简单的思路是想象有一个直角三角形，以$a$和$x$代替其中的边，比如</p>
<ul>
<li>$a^2+x^2$：$x &#x3D; a \tan \theta$</li>
<li>$a^2-x^2$：$x &#x3D; a \sin \theta$</li>
<li>$x^2-a^2$：$x &#x3D; a \sec \theta$</li>
</ul>
<h2 id="积分表、计算机代数系统与Monte-Carlo积分"><a href="#积分表、计算机代数系统与Monte-Carlo积分" class="headerlink" title="积分表、计算机代数系统与Monte Carlo积分"></a>积分表、计算机代数系统与Monte Carlo积分</h2><p>积分表无须多说。</p>
<p>计算机代数系统（CAS，如Mathematica或Maple）中可以方便的求<strong>符号积分</strong>。</p>
<h3 id="Monte-Carlo积分"><a href="#Monte-Carlo积分" class="headerlink" title="Monte Carlo积分"></a>Monte Carlo积分</h3><p>前面提到过求积分近似值的梯形法和Simpson法，另一种方法是Monte Carlo法。</p>
<p>该方法原来容易理解。通过求解面积来求积分值，然后随机生成大量的点，统计落在指定区域内的点，以此来估计面积值。这个过程需要一个随机数生成器。</p>
<h2 id="洛必达法则（L’Hopital’s-Rule）"><a href="#洛必达法则（L’Hopital’s-Rule）" class="headerlink" title="洛必达法则（L’Hopital’s Rule）"></a>洛必达法则（L’Hopital’s Rule）</h2><p>约翰·伯努利发现了一个求分式极限的法则，该分式的分子和分母都趋于零。如今这个法则被称为<strong>洛必达法则</strong>。至于为什么，请查看相关的数学史。</p>
<p>对于一个分式$f(x)&#x2F;g(x)$，若$f$和$g$都连续，如果两者在$a$处取值都为零，那么分式在$a$处的极限就不能代入求解了，这种分式称为<strong>不定型（Indeterminate Form）</strong>。其实我们在求函数导数时，如果函数在一点可导，那我们处理的就是不定型。$\lim_{x \to 0} \sin x&#x2F;x$也是不定型。可以说，不同不定型极限的求解难度有所不同，对于较难的那些，洛必达法则提供了一个可考虑的方法。</p>
<h3 id="洛必达法则（第一种形式）"><a href="#洛必达法则（第一种形式）" class="headerlink" title="洛必达法则（第一种形式）"></a>洛必达法则（第一种形式）</h3><p>第一种形式是：假定$f(a) &#x3D; g(a) &#x3D; 0$，$f$和$g$在$a$处都可导，且$g’(a) \neq 0$，则有</p>
<p>$$\lim_{x \to a} \frac{f(x)}{g(x)} &#x3D; \frac{f’(a)}{g’(a)}$$</p>
<p>其证明可由导数定义式得出。如果在求导之后还是不定型，那么可考虑如下的加强形式。</p>
<h3 id="洛必达法则（加强形式）"><a href="#洛必达法则（加强形式）" class="headerlink" title="洛必达法则（加强形式）"></a>洛必达法则（加强形式）</h3><p>假定$f(a) &#x3D; g(a) &#x3D; 0$，$f$和$g$在包含$a$的一个开区间$I$上是可微的，且当$x \neq a$时，在$I$上有$g’(x) \neq 0$，则当$\lim_{x \to a} \frac{f’(x)}{g’(x)}$存在时，</p>
<p>$$\lim_{x \to a} \frac{f(x)}{g(x)} &#x3D; \lim_{x \to a} \frac{f’(x)}{g’(x)}$$</p>
<p>加强形式把一个极限转换为了另一个更”低阶“的极限，在经过若干次之后，<strong>可能</strong>会得到最后的极限值。</p>
<h3 id="其它不定型之一"><a href="#其它不定型之一" class="headerlink" title="其它不定型之一"></a>其它不定型之一</h3><p>除了$0&#x2F;0$不定型，还有$\infty&#x2F;\infty$、$\infty \cdot 0$和$\infty - \infty$。同样可以使用洛必达法则（加强形式）。</p>
<p>有时需要转换：$\lim_{x \to \infty} x \sin \frac{1}{x} &#x3D; \lim_{h \to 0^{+}} \frac{\sin h}{h}$，这里令$h &#x3D; 1&#x2F;x$</p>
<h3 id="其它不定型之二"><a href="#其它不定型之二" class="headerlink" title="其它不定型之二"></a>其它不定型之二</h3><p>其它的不定型还有形如$1^{\infty}, 0^0, \infty^{0}$这样的，此时可考虑先用洛必达法则求出其对数的极限，再取指数。其依据是</p>
<p>$$\lim_{x \to a} &#x3D; L \Rightarrow \lim_{x \to a}f(x) &#x3D; \lim_{x \to a} e^{\ln f(x)} &#x3D; e^{\lim_{x \to a} \ln f(x)} &#x3D; e^L$$</p>
<p>例1：求$lim_{x \to \infty} (1+\frac{1}{x})^x$ ($1^{\infty}$，结果为$e$)</p>
<p>例2：求$\lim_{x \to 0^+}x^x$ ($\frac{-\infty}{\infty}$，结果为1）</p>
<p>例3：求$\lim_{x \to \infty} x^{1&#x2F;x}$ (${\infty}^0$，结果为1)</p>
<h2 id="反常积分"><a href="#反常积分" class="headerlink" title="反常积分"></a>反常积分</h2><p>目前为止，我们所求定积分的积分限是有界的，而且被积函数在此区间的值域是有界的。当这两个条件至少有一个不满足时，所求的积分称为<strong>反常积分（Improper Integrals）</strong>。</p>
<h3 id="无穷积分限"><a href="#无穷积分限" class="headerlink" title="无穷积分限"></a>无穷积分限</h3><p>考虑第一象限中位于曲线$y &#x3D; e^{-x&#x2F;2}$之下的无界区域，由于曲线向右侧无限延伸，看上去其面积应该是无穷大的，但后面会看到不是这样的。在计算这种情形的面积之前，先要给出它的定义。</p>
<p>如果不是向右无限延伸，而是考虑在区间$[0, b]$范围内的面积，那么它的值是</p>
<p>$$A(b) &#x3D; \int_{0}^{b}e^{-x&#x2F;2}dx &#x3D; -2e^{-b&#x2F;2} + 2$$</p>
<p>然后再求当$b \to \infty$时$A(b)$的极限，结果是2。我们认为第一象限内无界区域的面积是2。将此思路推广就得到<strong>有无穷积分限的反常积分</strong>：</p>
<p>有无穷积分限的积分是<strong>反常积分</strong>。</p>
<ol>
<li>若$f$在$[a, \infty)$是连续的，则$\int_{a}^{\infty}f(x)dx &#x3D; \lim_{b \to \infty} \int_{a}^{b}f(x)dx$</li>
<li>若$f$在$(-\infty, a]$是连续的，则$\int_{-\infty}^{a}f(x)dx &#x3D; \lim_{b \to -\infty} \int_{b}^{a}f(x)dx$</li>
<li>若$f$在$(-\infty, \infty)$是连续的，则$\int_{-\infty}^{\infty}f(x)dx &#x3D; \int_{-\infty}^{a}f(x)dx + \int_{a}^{\infty}f(x)dx$</li>
</ol>
<p>在部分1和2，若极限是存在的，则称反常积分<strong>收敛</strong>且极限为积分的<strong>值</strong>，否则称积分是<strong>发散</strong>。在部分3，若右边的两个积分都收敛，则左边的积分收敛，否则发散；而且其中$a$的选择可以是任意的。</p>
<p>例1：$\int_{-\infty}^{\infty}\frac{dx}{1+x^2} &#x3D; \pi$</p>
<p>例2：$\int_{1}^{\infty}\frac{dx}{x^p}$。</p>
<p>解：函数$y &#x3D; 1&#x2F;x$是加在形如$y &#x3D; 1&#x2F;x^p$的被积函数的收敛与发散反常积分之间的边界。</p>
<ul>
<li>当$p &gt; 1$，积分收敛于$\frac{1}{p-1}$</li>
<li>当$p &lt;&#x3D; 1$，积分发散</li>
</ul>
<h3 id="无界不连续函数的积分"><a href="#无界不连续函数的积分" class="headerlink" title="无界不连续函数的积分"></a>无界不连续函数的积分</h3><p>反常积分的另一情形是在积分限内函数是无界的。如曲线$y &#x3D; 1&#x2F;\sqrt{x}$之下从$x&#x3D;0$到$x&#x3D;1$之间的无界区域。其思路与无穷积分限一致，将其转化为积分之极限。</p>
<p>有了这两类反常积分的定义，我们可以把积分应用在更多的问题上，如一个无限延伸的曲线下的面积，不连续曲线下的面积等等。</p>
<h3 id="收敛和发散的判别法"><a href="#收敛和发散的判别法" class="headerlink" title="收敛和发散的判别法"></a>收敛和发散的判别法</h3><p>如果不能直接求出积分，那么需要先确定它是收敛还是发散的，如果是收敛的，再以数值方法逼近它的值。有两种方法：</p>
<p><strong>直接比较判别法</strong></p>
<p>设$f$和$g$在$[a, \infty)$上连续且对所有$x \geq a$有$0 \leq f(x) \leq g(x)$，则</p>
<ol>
<li>若$\int_{a}^{\infty}g(x)dx$收敛，则$\int_{a}^{\infty}f(x)dx$收敛</li>
<li>若$\int_{a}^{\infty}f(x)dx$发散，则$\int_{a}^{\infty}g(x)dx$发散。</li>
</ol>
<p><strong>极限比较判别法</strong></p>
<p>设_正函数_$f$和$g$在$[a, \infty)$上连续，并且</p>
<p>$$\lim_{x \to \infty} \frac{f(x)}{g(x)} &#x3D; L, 0 &lt; L &lt; \infty$$</p>
<p>那么$\int_{a}^{\infty}f(x)dx$和$\int_{a}^{\infty}g(x)dx$同时收敛或发散。</p>
<p>注：该判别法只是判断是否收敛，当两者同时收敛时，不一定收敛于同一值。</p>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 重积分</title>
    <url>/2017/10/01/thomas-calculus-multiple-integrals/</url>
    <content><![CDATA[<h1 id="重积分综述"><a href="#重积分综述" class="headerlink" title="重积分综述"></a>重积分综述</h1><p>单变量积分基于<strong>黎曼和</strong>，黎曼和涉及一个分割，以及小分割宽度与某个函数乘积之和。单变量情形下，分割当然是在一个区间上。</p>
<h1 id="二重积分"><a href="#二重积分" class="headerlink" title="二重积分"></a>二重积分</h1><p>在多变量情形下，比如二元函数，我们先考虑最简单的例子。在$xy$平面上，函数$f(x, y)$定义在一个矩形域：</p>
<p>$$R: a \leq b, c \leq d$$</p>
<p>设想，$R$被分别平行于$x$轴和$y$轴的直线网格覆盖，这些网格将定义域分割为若干小块，小块面积记为$\Delta A &#x3D; \Delta x \Delta y$，在每个小块面积上选点$(x, y)$，作和：</p>
<p>$$S_n &#x3D; \sum_{k&#x3D;1}^{n}f(x_k, y_k)\Delta A_k$$</p>
<p>可以看到该和与黎曼和的定义如出一辙。当网格的长与宽皆趋于零时，该和趋近于一极限值，该极限称为$f$在$R$上的<strong>二重积分</strong>，记为</p>
<p>$$\iint f(x, y)dA，或 \iint_R f(x, y) dxdy$$</p>
<h2 id="二重积分的性质"><a href="#二重积分的性质" class="headerlink" title="二重积分的性质"></a>二重积分的性质</h2><p>除了一般的数乘、和差、优势关系，二重积分还满足<strong>区域可加性</strong>，对于两个非交叠矩形域，总的积分等于两个区域上的积分之和。</p>
<h2 id="二重积分与体积"><a href="#二重积分与体积" class="headerlink" title="二重积分与体积"></a>二重积分与体积</h2><p>就像定积分自然地对应于曲边梯形的面积，二重积分对应于棱柱体的体积。</p>
<h2 id="计算二重积分的富比尼定理"><a href="#计算二重积分的富比尼定理" class="headerlink" title="计算二重积分的富比尼定理"></a>计算二重积分的富比尼定理</h2><p>富比尼（Guido Fubini）于1907年发表的一个定理证明了矩形域上任一个<strong>连续函数</strong>的二重积分都可用<strong>累次积分</strong>的任一种次序计算。</p>
<h2 id="有界非矩形域上的二重积分"><a href="#有界非矩形域上的二重积分" class="headerlink" title="有界非矩形域上的二重积分"></a>有界非矩形域上的二重积分</h2><p>此时可应用较强形式的富比尼定理，详见12.1的定理2。</p>
<h1 id="三重积分"><a href="#三重积分" class="headerlink" title="三重积分"></a>三重积分</h1><p>简言之，亦有类似的富比尼定理。</p>
<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><p>本章内容，暂时从略，需要时再补。</p>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 多元函数及其微积分</title>
    <url>/2017/09/18/thomas-calculus-multivariable-functions/</url>
    <content><![CDATA[<h1 id="多元函数及其导数"><a href="#多元函数及其导数" class="headerlink" title="多元函数及其导数"></a>多元函数及其导数</h1><pre><code>- Multivariable Functions and Their Derivatives
</code></pre>
<p>在学习概率论和统计学的时候，我们会发现多元函数乃是更自然的存在，在其它学科如流体动力学和电学等领域亦是如此。本章就是介绍多元函数的，值得庆幸的是，在多元函数的情形，微积分的法则本质上保持原样。我们需要了解同一时间里各个方向上的变化，但我们要做的无非是<strong>同时在各个方向上运用单变量微积分</strong>。</p>
<h1 id="多元函数"><a href="#多元函数" class="headerlink" title="多元函数"></a>多元函数</h1><pre><code>- Functions of Several Variables
</code></pre>
<p>许多函数依赖多于一个的自变量。如$f(x, y) &#x3D; x^2 + y^2$表示抛物面在点$P(x, y)$上方的高度。</p>
<h2 id="二元函数"><a href="#二元函数" class="headerlink" title="二元函数"></a>二元函数</h2><p>定义：<strong>二元函数</strong></p>
<p>假定$D$是有序实数对$(x, y)$的集合，$D$上的<strong>二元实函数$f$<strong>是一个</strong>规则</strong>，它对$D$中的每一个有序对指定唯一的一个实数$w &#x3D; f(x, y)$，$D$为<strong>定义域</strong>，$w$的取值集合为<strong>值域</strong>。</p>
<p>与一元函数相比，除了定义域略有不同，其它完全一致。</p>
<p>例：求函数的定义域和值域。</p>
<ul>
<li>$w &#x3D; \sqrt{y - x^2}$：定义域是$y \geq x^2$，抛物线上方区域；值域是$[0, \infty)$</li>
<li>$w &#x3D; \sin xy$：定义域是全平面；值域是$[-1, 1]$</li>
</ul>
<p>二元函数的定义域可以有<strong>内点</strong>和<strong>边界点</strong>，这跟一元函数区间的情形相似。</p>
<p>定义：<strong>内点、边界点、开集合闭集</strong></p>
<p>$xy$平面上的集合$R$的一个点$(x_0, y_0)$是$R$的<strong>内点</strong>，如果它是一个含于$R$内的圆盘的中心。一个点$(x_0, y_0)$是$R$的<strong>边界点</strong>，如果每个以$(x_0, y_0)$为中心的圆盘有不属于$R$的点，也有不属于$R$的点（边界点本身不要求属于$R$）。</p>
<p>注：理解时，可类比于区间的内点与端点。</p>
<p>一个集合的内点全体构成其<strong>内部</strong>，边界点构成其<strong>边界</strong>。如果一个集合完全有内点构成，则称它为<strong>开集</strong>，如果一个集合包含它的所有边界点，则称之为<strong>闭集</strong>。</p>
<p>注：可类比于开区间、闭区间和半开半闭区间。</p>
<p>定义：有界集与无界集</p>
<p>一个平面集合是<strong>有界的</strong>，如果它包含在一个固定半径的圆盘里，否则是<strong>无界的</strong>。</p>
<h2 id="二元函数的图像和等位线"><a href="#二元函数的图像和等位线" class="headerlink" title="二元函数的图像和等位线"></a>二元函数的图像和等位线</h2><p><strong>有两种标准化方法形象化一个函数$f(x, y)$的值</strong>。一是<strong>在定义域里</strong>标注$f$有同一个值的曲线，即等位线，二是<strong>在空间里</strong>画曲面（与一元函数的曲线相对应）。</p>
<p>此外，<strong>等高线</strong>与等位线类似，很多时候不作区别。典型的等高线应用是地图，它可以看作是定义在经度纬度实数对上的函数。</p>
<h3 id="计算机作图"><a href="#计算机作图" class="headerlink" title="计算机作图"></a>计算机作图</h3><p>在$Mathematica$中，可使用$Plot3D$作图：</p>
<figure class="highlight mathematica"><table><tr><td class="code"><pre><span class="line"><span class="built_in">Plot3D</span><span class="punctuation">[</span><span class="built_in">Sin</span><span class="punctuation">[</span><span class="variable">x</span><span class="punctuation">]</span> <span class="built_in">Sin</span><span class="punctuation">[</span><span class="variable">y</span><span class="punctuation">]</span><span class="operator">^</span><span class="number">2</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">x</span><span class="operator">,</span> <span class="number">0</span><span class="operator">,</span> <span class="built_in">Pi</span><span class="punctuation">&#125;</span><span class="operator">,</span> <span class="punctuation">&#123;</span><span class="variable">y</span><span class="operator">,</span> <span class="number">0</span><span class="operator">,</span> <span class="built_in">Pi</span><span class="punctuation">&#125;</span><span class="punctuation">]</span></span><br></pre></td></tr></table></figure>
<h2 id="三元及多元函数"><a href="#三元及多元函数" class="headerlink" title="三元及多元函数"></a>三元及多元函数</h2><p>二元函数的概念可以自然地推广到三元的情形。我们无法在三维框架内表示四维空间，但可考虑使用<strong>等位面</strong>来观察其行为。</p>
<p>内部、边界、有界性等概念也可以推广到三元函数。</p>
<p>最后，以上诸概念可以推广到$n$元函数$w &#x3D; f(x_1, x_2, \cdots, x_n)$的情形。</p>
<h1 id="高维函数的极限和连续"><a href="#高维函数的极限和连续" class="headerlink" title="高维函数的极限和连续"></a>高维函数的极限和连续</h1><pre><code>- Limits and Continuity in Higher Dimensions
</code></pre>
<p>多元函数极限的定义类似于一元函数，但有一个颇重要的区别。</p>
<h2 id="二元函数的极限"><a href="#二元函数的极限" class="headerlink" title="二元函数的极限"></a>二元函数的极限</h2><p>在一元函数的情形下，我们说$x$趋于某值，其意义是明确的，自变量沿着$x$轴向指定点靠近。二元情形下，“趋于”变得复杂，因为自变量可以从无数种可能的方向上靠近指定点。</p>
<p>定义：<strong>二元函数的极限</strong></p>
<p>当$(x, y)$趋于$(x_0, y_0)$时，函数$f$有极限$L$，如果给定给定任意正数$\epsilon$，存在一个正数$\delta$，使得对所有在$f$定义域中且满足$0 &lt; \sqrt{(x-x_0)^2 + (y - y_0)^2} &lt; \delta$的点$(x, y)$有$|f(x, y) - L| &lt; \epsilon$，写作</p>
<p>$$\lim_{(x, y) \to (x_0, y_0)} f(x, y) &#x3D; L$$</p>
<p>看起来有些复杂，其实是完全等价于一元函数的情形，主要区别是，所考察的定义域范围由”区间“变为”圆盘“。另外，圆盘也可以换作”正方形“，即$0 &lt; |x - x_0| &lt; \delta, 0 &lt; |y - y_0| &lt; \delta$。</p>
<p>求一元函数时，需要考虑左、右两个方向，二元函数则需要多个不同的方向，若干不同方向（或曰路径）有不同的极限，那么函数极限不存在。这一点可作为<strong>判别法</strong>使用。</p>
<p>例：求函数$f(x, y) &#x3D; \frac{2x^2y}{x^4+y^2}$趋于$(0, 0)$时的极限。</p>
<p>解：沿路径$y &#x3D; kx^2, x \neq 0$，函数有常数值$\frac{2k}{1+k^2}$，这说明函数沿不同路径趋于$(0, 0)$有不同极限，故函数极限不存在。</p>
<h3 id="极限性质"><a href="#极限性质" class="headerlink" title="极限性质"></a>极限性质</h3><p>按惯例，常规的和、差、积、商、幂等法则都是适用的。</p>
<h2 id="二元函数连续性"><a href="#二元函数连续性" class="headerlink" title="二元函数连续性"></a>二元函数连续性</h2><p>其定义与一元函数本质上是一样的，即函数在点$(x_0, y_0)$有定义，在该点极限存在，两者相等。</p>
<h2 id="多于二元的函数"><a href="#多于二元的函数" class="headerlink" title="多于二元的函数"></a>多于二元的函数</h2><p>二元函数的极限、连续之定义，以及和、差、积、商、幂法则，以及复合函数的性质都可以推广到多于二元的函数。</p>
<h2 id="有界闭集上连续函数的极值"><a href="#有界闭集上连续函数的极值" class="headerlink" title="有界闭集上连续函数的极值"></a>有界闭集上连续函数的极值</h2><p>一元连续函数在闭区间上的极值性质可以推广到多元连续函数的情形。在多元的情形下，<strong>闭集</strong>有多种不同的可能，在平面上，可以是线段、圆盘和填满的三角形等，在空间内，可以是球体、立方体或球壳等。</p>
<p>具体如何求解极值，在后面介绍了导数后会了解到。</p>
<h1 id="偏导数"><a href="#偏导数" class="headerlink" title="偏导数"></a>偏导数</h1><pre><code>- Partial Derivatives
</code></pre>
<p>对于多元函数，如果我们固定一个自变量之外的自变量，仅对这一自变量求导，就得到<strong>偏（partial）导数</strong>。</p>
<h2 id="二元函数的偏导数"><a href="#二元函数的偏导数" class="headerlink" title="二元函数的偏导数"></a>二元函数的偏导数</h2><p>若$(x_0, y_0)$是函数定义域中一点，竖直平面$y &#x3D; y_0$割曲面$z &#x3D; f(x, y)$得到<strong>曲线</strong>$z &#x3D; f(x, y_0)$。曲线在竖直平面内，成为关于$x$的一元函数，因此可以对其求出一般的导数。</p>
<p>定义：<strong>关于$x$的偏导数</strong></p>
<p>在点$(x_0, y_0)$，$f(x, y)$对$x$的偏导数是</p>
<p>$\frac{\partial f}{\partial x} |_{(x_0, y_0)} &#x3D; \frac{d}{dx}f(x, y_0)$</p>
<p>有时也记为$f_x(x_0, y_0)$。类似地，也可以定义$f(x, y)$对$y$的偏导数$f_y$。</p>
<p>现在来看，在$y &#x3D; y_0$平面内，可由$f_x$找出过点$P(x_0, y_0, f(x_0, y_0))$的切线，在$x &#x3D; x_0$平面内，可作出过$P$的另一切线，这两条切线确定的平面是否是函数曲面的切平面呢？这个问题的解答有赖于更多关于偏导数的知识。</p>
<p>注：函数对$x$和$y$的偏导数，可理解为函数在两个不同方向或路径上的切线斜率，因此两者的值不等就不足为怪了。</p>
<h3 id="隐函数的偏导数"><a href="#隐函数的偏导数" class="headerlink" title="隐函数的偏导数"></a>隐函数的偏导数</h3><p>与一元函数的求解方法相同。</p>
<h2 id="多于二元的函数-1"><a href="#多于二元的函数-1" class="headerlink" title="多于二元的函数"></a>多于二元的函数</h2><p>不管有几个自变量，所谓偏导数总是仅对<strong>一个</strong>自变量而言，因而本质上它可以理解为<strong>一元函数</strong>的导数。</p>
<h2 id="偏导数与连续性"><a href="#偏导数与连续性" class="headerlink" title="偏导数与连续性"></a>偏导数与连续性</h2><p>一个函数可以在一个点有对于$x$和$y$的偏导数，但在该点不连续，这与一元函数的情形不同。这个可以这么理解，偏导数仅说明了在两个方向上函数的变化特征，但连续性却包含了任意可能的方向。</p>
<h2 id="二阶偏导数"><a href="#二阶偏导数" class="headerlink" title="二阶偏导数"></a>二阶偏导数</h2><p>对函数$f(x, y)$求导两次，就得到二阶导数。</p>
<p>$\frac{\partial^2f}{\partial x^2}$对$x$求导两次，$\frac{\partial^2f}{\partial x \partial y}$先对$y$求导，再对$x$求导。</p>
<p>定理：<strong>混合导数定理</strong></p>
<p>若$f(x, y)$以及它的偏导数$f_x, f_y, f_{xy}, f_{yx}$定义在含点$(a, b)$的开集，且都在$(a, b)$连续，则</p>
<p>$$f_{xy}(a, b) &#x3D; f_{yx}(a, b)$$</p>
<p>也就是说，在计算二阶混合导数时，可按任意次序微分，从而可以先选择较易进行的计算。</p>
<h2 id="更高阶的偏导数"><a href="#更高阶的偏导数" class="headerlink" title="更高阶的偏导数"></a>更高阶的偏导数</h2><p>没有什么能够阻挡对更高阶偏导数的计算，而且它们依然遵循混合导数定理。</p>
<h2 id="可微性"><a href="#可微性" class="headerlink" title="可微性"></a>可微性</h2><p>二元函数的可微性出发点不是<strong>差商</strong>，而是<strong>增量</strong>。一元函数中，当$x$从$x_0$改变到$x_0 + \Delta x$时，$f$的改变用等式</p>
<p>$$\Delta y &#x3D; f’(x_0) \Delta x + \epsilon \Delta x$$</p>
<p>给出，其中当$\Delta x \to 0$时，$\epsilon \to 0$。</p>
<p>定理：<strong>二元函数的增量定理</strong></p>
<p>假定$f(x, y)$的一阶偏导数在包含$(x_0, y_0)$的一个开集上有定义，并且$f_x$和$f_y$在$(x_0, y_0)$<strong>连续</strong>，则从$(x_0, y_0)$移动到$(x_0 + \Delta x, y_0 + \Delta y)$时引起的函数改变量$\Delta z$满足</p>
<p>$$\Delta z &#x3D; f_x(x_0, y_0)\Delta x + f_y(x_0, y_0)\Delta y + \epsilon_1\Delta x + \epsilon_2\Delta y$$</p>
<p>其中，当$\Delta x, \Delta y \to 0$时，$\epsilon_1, \epsilon_2 \to 0$</p>
<p>定义：<strong>二元函数的可微性</strong></p>
<p>一个函数$z &#x3D; f(x, y)$在$(x_0, y_0)$是<strong>可微的</strong>，若$f_x(x_0, y_0)$和$f_y(x_0, y_0)$存在，且$\Delta z$满足</p>
<p>$$\Delta z &#x3D; f_x(x_0, y_0)\Delta x + f_y(x_0, y_0)\Delta y + \epsilon_1\Delta x + \epsilon_2\Delta y$$</p>
<p>其中，当$\Delta x, \Delta y \to 0$时，$\epsilon_1, \epsilon_2 \to 0$。如果函数在定义域的每个点都是可微的，那么说函数是<strong>可微的</strong>。</p>
<p>增量定理的推论：<strong>偏导数的连续性蕴含可微性</strong></p>
<p>定理：<strong>可微性蕴含连续性</strong></p>
<h1 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h1><p>我们可以在<strong>适当定义域</strong>内复合多变量函数，这跟建立单变量函数的复合一样。一元函数的链式法则表示为</p>
<p>$$\frac{dw}{dt} &#x3D; \frac{dw}{dx} \frac{dx}{dt}$$</p>
<p>定理：<strong>二元函数的链式法则</strong></p>
<p>若$w &#x3D; f(x, y)$是可微的，而$x$和$y$是$t$的可微函数，则$w$是$t$的可微函数，并且</p>
<p>$$\frac{dw}{dt} &#x3D; \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}$$</p>
<p>TODO：定理5的证明需要再看一遍。</p>
<p>注：该定理的记忆可按照<strong>树形图解</strong>，该方法也适用于更高维的函数。</p>
<p>定理：<strong>三元函数的链式法则</strong></p>
<p>若$w &#x3D; f(x, y, z)$是可微的，而$x$、$y$和$z$是$t$的可微函数，则$w$是$t$的可微函数，并且</p>
<p>$$\frac{dw}{dt} &#x3D; \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt} + \frac{\partial f}{\partial z} \frac{dz}{dt}$$</p>
<p>注意到这两个链式法则最后都是一元的，如果是多于一元的，那么将有关于<strong>偏导数</strong>的链式法则，比如$x, y, z$到$r, s$，然后求$w$关于$r, s$的偏导数。又或者是一对多的情况，从$x$到$r, s$，那么也可以求$w$关于$r, s$的偏导数。</p>
<p>链式法则确然是<strong>多才多艺的</strong>，如此结论还有证据，即它还可以简化隐函数求导过程。</p>
<h2 id="隐函数求导法"><a href="#隐函数求导法" class="headerlink" title="隐函数求导法"></a>隐函数求导法</h2><p>假定$F(x, y)$是可微的，并且方程$F(x, y) &#x3D; 0$定义$y$为$x$的可微函数。则在$F_y \neq 0$的点，</p>
<p>$$\frac{dy}{dx} &#x3D; - \frac{F_x}{F_y}$$</p>
<p>证：令$w &#x3D; F(x, y) &#x3D; 0$，此时可定义$y &#x3D; h(x), x &#x3D; x$，这样可应用链式法则，从而</p>
<p>$$\frac{dw}{dx} &#x3D; F_x\frac{dx}{dx} + F_y\frac{dy}{dx} &#x3D; 0$$</p>
<p>这样证明了<strong>隐函数微分公式</strong>。</p>
<h2 id="链式法则小结"><a href="#链式法则小结" class="headerlink" title="链式法则小结"></a>链式法则小结</h2><p>上面可以看到链式法则的不同应用场景，但它们都遵循同一个公式或思路。想象有一个树形结构，从因变量到中间变量再到自变量，为求得选定自变量的导数，从因变量开始，<strong>往下读树的每条路径到自变量</strong>，各条路径导数之和即为所求。</p>
<h1 id="方向导数、梯度向量和切平面"><a href="#方向导数、梯度向量和切平面" class="headerlink" title="方向导数、梯度向量和切平面"></a>方向导数、梯度向量和切平面</h1><pre><code>- Directional Derivatives, Gradient Vectors, and Tangent Planes
</code></pre>
<p>如果我们看一下等高线地图，会发现河流都是垂直于等高线流动，即沿着最陡峭的路径流动。本节将分析为何大自然如此安排河流的走向。</p>
<h2 id="平面内的方向导数"><a href="#平面内的方向导数" class="headerlink" title="平面内的方向导数"></a>平面内的方向导数</h2><p>假定函数$f(x, y)$定义在$xy$平面的区域$R$内，$P_0(x_0, y_0)$是$R$中的一个点，而$u &#x3D; u_1i + u_2j$是一个单位向量，则方程</p>
<p>$$x &#x3D; x_0 + su_1, y &#x3D; y_0 + su_2$$</p>
<p>是<strong>过$P_0$且平行于$u$的直线的参数方程</strong>。我们通过计算在$P_0$的$df&#x2F;ds$来求$f$在$P_0$沿方向$u$的变化率。</p>
<p>定义：<strong>方向导数</strong></p>
<p>$f$在$P_0(x_0, y_0)$沿单位向量$u &#x3D; u_1i + u_2j$的方向的导数是<strong>数</strong></p>
<p>$$(\frac{df}{ds})<em>{u, P_0} &#x3D; \lim</em>{s \to 0} \frac{f(x_0 + su_1, y_0 + su_2) - f(x_0, y_0)}{s}$$</p>
<p>如果极限存在的话。方向导数又可以表示为$(D_uf)_{P_0}$</p>
<p>初次看到方向导数的定义会感觉比较抽象，因为里面涉及到一个<strong>单位向量</strong>，这似乎和目前为止所遇到的各种导数都不同。但其实本质并无不同。想一想偏导数的定义，当我们求$f_x$时，是固定$y$的值，求$f$关于$x$的导数，此时自变量沿着直线$y &#x3D; y_0$变化，于是也可以说$f$沿着单位向量$u &#x3D; i$的方向变化。这样偏导数就是一种特殊的方向导数了。另一方面，既然$f$可以沿着$y &#x3D; y_0$变化，就也可以沿着其它方向变化，将方向以单位向量变化，就得到方向导数的定义了。可以说，方向导数推广了两个偏导数。</p>
<p>几何上，相当于以垂直于$xy$平面的一个平面切割曲面，求所得曲线在某点的导数。</p>
<h3 id="方向导数的计算"><a href="#方向导数的计算" class="headerlink" title="方向导数的计算"></a>方向导数的计算</h3><p>对方向导数的定义应用链式法则，可以简化其计算</p>
<p>$$(\frac{df}{ds})<em>{u, P_0} &#x3D; [(\frac{\partial f}{\partial x})</em>{P_0} i + (\frac{\partial f}{\partial y})_{P_0}j] \cdot [u_1 i + u_2 j]$$</p>
<p>这样就引出了梯度向量的概念。</p>
<h2 id="梯度向量"><a href="#梯度向量" class="headerlink" title="梯度向量"></a>梯度向量</h2><p>定义：<strong>梯度向量或梯度</strong></p>
<p>$f(x, y)$在点$P_0(x_0, y_0)$的梯度向量是由$f$在$P_0$的偏导数得到的向量</p>
<p>$\nabla f &#x3D; \frac{\partial f}{\partial x} i + \frac{\partial f}{\partial y}j$</p>
<p>注意到，函数在一点的偏导数是固定值，故方向梯度是由函数与点本身确定的，与方向导数无关。</p>
<p>综上，得出如下结论：</p>
<p>定理：<strong>方向导数是点积</strong></p>
<p>若$f(x, y)$在$P_0(x_0, y_0)$可微，则</p>
<p>$$(\frac{df}{ds})<em>{u, P_0} &#x3D; (\nabla f)</em>{P_0} \cdot u$$</p>
<p>只要计算梯度向量与方向向量的点积即可。</p>
<h2 id="方向导数的性质"><a href="#方向导数的性质" class="headerlink" title="方向导数的性质"></a>方向导数的性质</h2><p>$(D_uf)<em>{P_0} &#x3D; (\nabla f)</em>{P_0} \cdot u &#x3D; |\nabla f||u|\cos \theta &#x3D; |\nabla f| \cos \theta$</p>
<p>其中$\theta$是向量与梯度向量的夹角，此公式揭示出以下性质：</p>
<ul>
<li>函数$f$当$\cos \theta &#x3D; 1$时，或当$u$是梯度的方向时增加最快</li>
<li>函数$f$当$\cos \theta &#x3D; -1$时，或当$u$是梯度的反方向时减少最快</li>
<li>正交于梯度的方向$u$是$f$变化率为零的方向，此时$\theta &#x3D; \pi&#x2F;2$，方向导数为0。</li>
</ul>
<h2 id="梯度和等高线的切线"><a href="#梯度和等高线的切线" class="headerlink" title="梯度和等高线的切线"></a>梯度和等高线的切线</h2><p>若一个可微函数$f(x, y)$沿一条光滑曲线$r &#x3D; g(t) i + h(t) j$取常数值$c$（从而该曲线成为函数的一条等高线（level curve）），有$f(g(t), h(t)) &#x3D; c$，对$t$求导此等式两端并应用链式法则，得到</p>
<p>$$(\frac{\partial f}{\partial x} i + \frac{\partial f}{\partial y}j) \cdot (\frac{dg}{dt}i + \frac{dh}{dt}j) &#x3D; 0$$</p>
<p>即<strong>梯度向量正交于切向量$\frac{dr}{dt}$</strong>，于是它正交于切线。所以，我们的结论是$f$的梯度正交于过一点的等高线。</p>
<p>河流必须是以最快的方式往下流动的，而<strong>最快</strong>即沿着负梯度向量的方向，从而必然垂直于等高线。</p>
<p>既然如此，便可由梯度求得等高线的切线方程。过$P_0(x_0, y_0)$垂直于向量$Ai + Bj$的直线方程是</p>
<p>$$A(x - x_0) + B(y - y_0) &#x3D; 0$$</p>
<p>故切线方程为</p>
<p>$$f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0) &#x3D; 0$$</p>
<h2 id="梯度的代数法则"><a href="#梯度的代数法则" class="headerlink" title="梯度的代数法则"></a>梯度的代数法则</h2><p>梯度计算满足若干代数法则，如和、差、积和商的梯度，对于积和商有：</p>
<ul>
<li>$\nabla (fg) &#x3D; f \nabla g + g \nabla f$</li>
<li>$\nabla (f&#x2F;g) &#x3D; \frac{g \nabla f - f \nabla g}{g^2}$</li>
</ul>
<h2 id="增量和距离"><a href="#增量和距离" class="headerlink" title="增量和距离"></a>增量和距离</h2><p>若要估计从点$P_0$到邻近的另外一点移动一个小的距离，函数变化有多少，通常会用到<strong>方向导数</strong>。在一元函数中，这种估计即是<strong>微分</strong>$df &#x3D; f’(P_0)ds$，二元函数与此类似：</p>
<p>$$df &#x3D; (\nabla f|_{P_0} \cdot u)ds$$</p>
<p>即方向导数乘以该方向上移动的距离。以平面之切片来看，完全是一元函数的样子。</p>
<h2 id="三元函数"><a href="#三元函数" class="headerlink" title="三元函数"></a>三元函数</h2><p>在三元函数例，梯度向量和方向导数有着完全一致的定义和性质。比如沿梯度增加最快，正交于梯度则方向导数为0。</p>
<h3 id="切平面和法线"><a href="#切平面和法线" class="headerlink" title="切平面和法线"></a>切平面和法线</h3><p>等位面$f(x, y, z) &#x3D; c$在点$P_0(x_0, y_0, z_0)$的<strong>切平面</strong>是过点$P_0$正交于$\nabla|<em>{P_0}$的平面，曲面在$P_0$的<strong>法线</strong>是过$P_0$平行于$\nabla|</em>{P_0}$的直线。</p>
<p>这里的切平面对应于二元函数下的<strong>切线</strong>。切平面和法线的方程分别是：</p>
<p>$$f_x(P_0)(x - x_0) + f_y(P_0)(y - y_0) + f_z(P_0)(z - z_0) &#x3D; 0$$</p>
<p>$$x &#x3D; x_0 + f_x(P_0)t, y &#x3D; y_0 + f_y(P_0)t, z &#x3D; z_0 + f_z(P_0)t$$</p>
<h1 id="线性化和微分"><a href="#线性化和微分" class="headerlink" title="线性化和微分"></a>线性化和微分</h1><pre><code>- Linearization and Differentials
</code></pre>
<p>一元函数的线性化和微分可以推广到多元函数。</p>
<h2 id="二元函数的线性化"><a href="#二元函数的线性化" class="headerlink" title="二元函数的线性化"></a>二元函数的线性化</h2><p>如果$z &#x3D; f(x, y)$在$(x_0, y_0)$是可微的，那么由增量定理可知</p>
<p>$$\Delta z &#x3D; f_x(x_0, y_0)\Delta x + f_y(x_0, y_0)\Delta y + \epsilon_1\Delta x + \epsilon_2\Delta y$$</p>
<p>当$\Delta x$和$\Delta y$足够小的时候，后两项可以忽略，这样就得到了<strong>线性化</strong>。</p>
<p>定义：<strong>线性化、标准线性逼近</strong></p>
<p>当函数$f$可微时，$f(x, y)$在点$(x_0, y_0)$的<strong>线性化</strong>是函数</p>
<p>$$L(x, y) &#x3D; f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)$$</p>
<p>逼近$f(x, y) &#x3D; L(x, y)$是函数的<strong>标准线性逼近</strong>。</p>
<p>可以看到，$L(x, y)$也是函数在该点的切平面，正如微分是一元函数的切线。</p>
<h3 id="标准线性逼近的精确度"><a href="#标准线性逼近的精确度" class="headerlink" title="标准线性逼近的精确度"></a>标准线性逼近的精确度</h3><p>假定$L(x, y)$是可微函数$f$的线性化，那么此逼近的精确度是多少？它依赖于三个因素：</p>
<ul>
<li>$\Delta x$</li>
<li>$\Delta y$</li>
<li>$f$在点附近用<strong>二阶导数</strong>的大小衡量的”弯曲程度“</li>
</ul>
<p>由此得到如下结论：<strong>标准线性逼近的误差</strong></p>
<p>若$f$在包含以$(x_0, y_0)$为中心的矩形$R$的开集上有连续的一阶和二阶导数，而$M$是$|f_{xx}|, |f_{xy}, |f_{yy}|$的值在$R$上的一个上界，则标准线性逼近带来的误差$E(x, y)$满足：</p>
<p>$$|E(x, y)| \leq \frac{1}{2}M(|x - x_0| + |y - y_0|)^2$$</p>
<h2 id="全微分"><a href="#全微分" class="headerlink" title="全微分"></a>全微分</h2><p>以$L$线性化时，$\Delta L &#x3D; f_x(x_0, y_0)\Delta x + f_y(x_0, y_0)\Delta y$，由此可得全微分之定义。</p>
<p>定义：<strong>全微分</strong></p>
<p>如果我们从$(x_0, y_0)$移动到附近的点$(x_0 + \Delta x, y_0 + \Delta y)$，由此引起的<strong>线性化的变化</strong></p>
<p>$$df &#x3D; f_x(x_0, y_0)dx + f_y(x_0, y_0)dy$$</p>
<p>称为$f$的全微分。</p>
<p>全微分可用于了解函数对于自变量变化的敏感性。</p>
<h2 id="对于两元的函数"><a href="#对于两元的函数" class="headerlink" title="对于两元的函数"></a>对于两元的函数</h2><p>二元函数中的线性化、全微分概念可以自然地推广到多于二元的函数。</p>
<h1 id="极值和鞍点"><a href="#极值和鞍点" class="headerlink" title="极值和鞍点"></a>极值和鞍点</h1><pre><code>- Extreme Values and Saddle Points
</code></pre>
<p>求多元函数的极值以及极值点是多元微分学的重要应用之一。在本节我们将讨论如何通过偏导数来解决此类问题。</p>
<h2 id="闭有界区域上的状况"><a href="#闭有界区域上的状况" class="headerlink" title="闭有界区域上的状况"></a>闭有界区域上的状况</h2><p>一元函数情形下，导数用于了解函数的极值点，极值只可能出现在端点和临界点。同时导数为零的点未必取到极值。比如，在<strong>拐点</strong>处没有极值。</p>
<p>二元函数呈现类似的情况。它的极值也是仅出现在区域边界点或两个偏导数为零的内点，或至少有一个偏导数不存在的点。对应于拐点的是<strong>鞍点</strong>。</p>
<h2 id="局部极值的导数判别法"><a href="#局部极值的导数判别法" class="headerlink" title="局部极值的导数判别法"></a>局部极值的导数判别法</h2><p>二元函数有与一元函数类似的局部极大值与极小值概念，不再赘述。</p>
<p>局部极大值对应曲面的山峰，局部极小值则对应曲面的谷底。在这样的点，如果切平面是存在的，那么它必是水平的。局部极值判断的关键是<strong>一阶导数判别法</strong>。</p>
<p>定理：<strong>局部极值一阶导数判别法</strong></p>
<p>若$f(x, y)$在定义域的一个内点$(a, b)$有局部极大值或局部极小值，且一阶偏导数在该点存在，那么有$f_x &#x3D; f_y &#x3D; 0$</p>
<p>若求出该点的切平面，则是$z &#x3D; f(a, b)$，这是曲面的水平切平面。</p>
<p>这样，二元函数$f(x, y)$仅有的极值点位置包括：</p>
<ul>
<li>在使$f_x &#x3D; f_y &#x3D; 0$的内点（即上面定理）</li>
<li>$f_x$和$f_y$的一个或两个不存在的内点</li>
<li>定义域的边界点</li>
</ul>
<p>前两类又称为<strong>临界点</strong>。</p>
<h3 id="鞍点"><a href="#鞍点" class="headerlink" title="鞍点"></a>鞍点</h3><p>一个可微函数$f(x, y)$在一个临界点$(a, b)$取鞍点，如果在以$(a, b)$为中心的<strong>每个开圆盘</strong>内既存在点满足$f(x, y) &gt; f(a, b)$，又存在点满足$f(x, y) &lt; f(a, b)$。</p>
<p>例：函数$z &#x3D; y^2 - x^2$在$(0, 0)$取到鞍点。</p>
<p>定理：<strong>局部极值的二阶导数判别法</strong></p>
<p>假定$f$和它的一阶及二阶导数在以$(a, b)$为中心的一个圆盘内连续，且$f_x(a, b) &#x3D; f_y(a, b) &#x3D; 0$。</p>
<ol>
<li>如果在$(a, b), f_{xx} &lt; 0且f_{xx}f_{yy} - f_{xy}^2 &gt; 0$，则$f$在该点取得局部极大值</li>
<li>如果在$(a, b), f_{xx} &gt; 0且f_{xx}f_{yy} - f_{xy}^2 &gt; 0$，则$f$在该点取得局部极小值</li>
<li>如果在$(a, b), f_{xx}f_{yy} - f_{xy}^2 &lt; 0$，则$f$在该点取得鞍点</li>
<li>如果在$(a, b), f_{xx}f_{yy} - f_{xy}^2 &#x3D; 0$，则判别法无法得出结论，需借助它法。</li>
</ol>
<p>$f_{xx}f_{yy} - f_{xy}^2$称为函数的<strong>判别式</strong>，或$Hess$，有时以行列式的形式记忆之。</p>
<h2 id="闭有界区域上的绝对最大值和最小值"><a href="#闭有界区域上的绝对最大值和最小值" class="headerlink" title="闭有界区域上的绝对最大值和最小值"></a>闭有界区域上的绝对最大值和最小值</h2><p>与一元函数类似，分为三步：</p>
<ul>
<li>检查$R$的内点中的临界点</li>
<li>检查边界点</li>
<li>查看列表</li>
</ul>
<h1 id="拉格朗日乘子"><a href="#拉格朗日乘子" class="headerlink" title="拉格朗日乘子"></a>拉格朗日乘子</h1><pre><code>- Lagrange Multipliers
</code></pre>
<p>有的极值问题，定义域约束在平面的某个特殊子集，比如一个圆盘或闭三角形区域，当然也可以有其它类型的约束。拉格朗日乘子是求函数约束极值的强有力的方法。</p>
<p>对于11.8例1中那样的问题，使用替换法可以解决，但并非最有效的方法。</p>
<h2 id="拉格朗日乘子法"><a href="#拉格朗日乘子法" class="headerlink" title="拉格朗日乘子法"></a>拉格朗日乘子法</h2><p>定理：<strong>正交梯度定理</strong></p>
<p>假定$f(x, y, z)$在一个其内部含有以下曲线的区域内可微：</p>
<p>$$C: r(t) &#x3D; g(t)i + h(t)j + k(t)k$$</p>
<p>若$P_0$是$C$上的点，在该点$f$取相对于$C$上其它值的局部最大值或最小值，则$\nabla f$在$P_0$正交于$C$。</p>
<p>推论：取消正交梯度定理中含$z$的项，则可得到关于二元函数的结果。</p>
<p>此定理是拉格朗日乘子法的关键。</p>
<p><strong>拉格朗日乘子法</strong>：假定$f(x, y, z)$和$g(x, y, z)$是可微的，为求$f$在约束$g(x, y, z) &#x3D; 0$下的局部最大值和最小值，就求$x, y, z, \lambda$，使它们同时满足</p>
<p>$$\nabla f &#x3D; \lambda \nabla g, g(x, y, z) &#x3D; 0$$</p>
<p>对于二元的情形，则去掉$z$即可。</p>
<p>几何解释：例3和例4中，通过等高线的运动来理解正交梯度定理和拉格朗日乘子法。</p>
<h2 id="带两个约束条件的乘子法"><a href="#带两个约束条件的乘子法" class="headerlink" title="带两个约束条件的乘子法"></a>带两个约束条件的乘子法</h2><p>此类问题可看作一个约束条件的推广。在一个约束的情形，两个梯度平行，两个约束的情形下，原函数之梯度在两个约束函数之梯度所决定的平面上，故而可表示为后两者的线性组合。</p>
<p>此时有非常美妙的几何解释，详见11.8图11.64。</p>
<h1 id="带约束变量的偏导数"><a href="#带约束变量的偏导数" class="headerlink" title="带约束变量的偏导数"></a>带约束变量的偏导数</h1><pre><code>- Partial Derivatives with Constrained Variables
</code></pre>
<p>暂从略。</p>
<h1 id="两个变量的泰勒公式"><a href="#两个变量的泰勒公式" class="headerlink" title="两个变量的泰勒公式"></a>两个变量的泰勒公式</h1><pre><code>- Taylor&#39;s Formula for Two Variables
</code></pre>
<p>暂从略。</p>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>Thomas&#39; Calculus - 平面与空间中的向量</title>
    <url>/2017/09/13/thomas-calculus-vectors-in-the-plane-and-space/</url>
    <content><![CDATA[<h1 id="平面向量和极坐标函数"><a href="#平面向量和极坐标函数" class="headerlink" title="平面向量和极坐标函数"></a>平面向量和极坐标函数</h1><pre><code>- Vectors in the Plane and Polar Functions
</code></pre>
<p>当一个物体在$xy$平面上漫游时，<strong>参数方程</strong>$y &#x3D; f(t)$和$y &#x3D; g(t)$可用来作为物体的运动和路径模型。这一章将了解<strong>参数方程的向量方式</strong>，用它来描述运动物体的轨迹，并计算其速度和加速度。</p>
<p>向量函数的一个主要作用是分析空间运动，行星运动最好用<strong>极坐标</strong>描述（由雅各布·伯努利首先发表），因为我们也将了解如何在这一新坐标系下分析曲线、导数和积分。</p>
<h2 id="平面向量"><a href="#平面向量" class="headerlink" title="平面向量"></a>平面向量</h2><pre><code>- Vectors in the Plane
</code></pre>
<p>我们测量时用到的量，分为两类，一是<strong>标量</strong>（Scalar），或称纯量，表示单纯的数值，如长度、质量与速率等；二是<strong>向量</strong>（Vector），或称矢量（因带有箭头而颇为形象），兼有大小与方向，如位移、速度与力等。</p>
<h3 id="分量形式"><a href="#分量形式" class="headerlink" title="分量形式"></a>分量形式</h3><p>向量用<strong>有向线段</strong>表示，箭头所向表示方向，长度指定大小。有向线段用$\overrightarrow{AB}$这样的形式表示，A、B分别为起点和终点；其长度用$|\overrightarrow{AB}|$表示。</p>
<p>如果两条有向线段长度相等且方向相同，则它们是<strong>相等</strong>的。更进一步，我们认为它们表示<strong>同一向量</strong>。（类似于，两个标量相等，则它们表示同一个量）</p>
<p>在笛卡尔坐标系中，两点确定出一条有向线段，从而它的长度与方向（即斜率）可以计算，因此可以确定两个向量是否相等。</p>
<p>与向量$v$相等的有向线段中，起点位于原点的那个是唯一的，称为$v$的<strong>标准位置</strong>。</p>
<p>定义：<strong>向量的分量形式</strong></p>
<p>如果平面上的向量$v$的标准位置终点在$(v_1, v_2)$，那么$v$的分量形式是：</p>
<p>$$v &#x3D; &lt;v_1, v_2&gt;$$</p>
<p>如此，平面上的向量与实数的<strong>有序对</strong>是一一对应的。这里$v_1$和$v_2$称为$v$的<strong>分量</strong>。向量$&lt;v_1, v_2&gt;$称为点$(v_1, v_2)$的<strong>位置向量</strong>。</p>
<p>若向量$v &#x3D; &lt;v_1, v_2&gt;$用有向线段$\overrightarrow{PQ}$，P、Q坐标分别是$(x_1, y_1)$、$(x_2, y_2)$，则$v$的分量是：</p>
<p>$$v &#x3D; &lt;x_2 - x_1, y_2 - y_1&gt;$$</p>
<p>向量$\overrightarrow{PQ}$的长度或大小为：</p>
<p>$$|v| &#x3D; \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$$</p>
<p>以上，都是中学数学解析几何的内容。</p>
<h3 id="零向量与单位向量"><a href="#零向量与单位向量" class="headerlink" title="零向量与单位向量"></a>零向量与单位向量</h3><p><strong>零向量</strong>是$0 &#x3D; &lt;0, 0&gt;$，长度为零，方向则不确定。</p>
<p>任何长度为1的向量$v$是<strong>单位向量</strong>。若$v$与正$x$轴夹角为$\theta$，则$v$的分量可表示为：</p>
<p>$$v &#x3D; &lt;\cos \theta, \sin \theta&gt;$$</p>
<p>$\theta$从$0$变化到$2\pi$时，单位向量取遍所有可能的方向。</p>
<h3 id="向量的代数运算"><a href="#向量的代数运算" class="headerlink" title="向量的代数运算"></a>向量的代数运算</h3><p>向量的两个主要运算是加法与数乘。</p>
<p>定义：<strong>向量加法与数乘</strong></p>
<p>设$u &#x3D; &lt;u_1, u_2&gt;, v &#x3D; &lt;v_1, v_2&gt;$，$k$是实数</p>
<ul>
<li>加法：$u + v &#x3D; &lt;u_1 + v_1, u_2 + v_2&gt;$</li>
<li>数乘：$ku &#x3D; &lt;ku_1, ku_2&gt;$</li>
</ul>
<p>向量加法在几何上可使用<strong>三角形法则</strong>或<strong>平行四边形法则</strong>，一种非常直观的理解是物理中的<strong>位移</strong>概念。</p>
<p>至于数乘，若$k$为正，则$ku$的方向与$u$同；若$k$为负，则$ku$的方向与$u$反。另一方面，$|ku| &#x3D; |k| \cdot |u|$。特别地，$(-1)u &#x3D; -u$。</p>
<p>定义：<strong>向量的差</strong></p>
<p>$$u - v &#x3D; u + (-u) &#x3D; &lt;u_1 - v_1, u_1 - u_2&gt;$$</p>
<p>注意到$(u - v) + v &#x3D; u$，故向量加法与减法类似于数的加减法，减法可看作加法的逆运算。</p>
<h3 id="标准单位向量"><a href="#标准单位向量" class="headerlink" title="标准单位向量"></a>标准单位向量</h3><p>任何平面向量$v &#x3D; &lt;a, b&gt;$都可以写成<strong>标准单位向量</strong></p>
<p>$$i &#x3D; &lt;1, 0&gt;, j &#x3D; &lt;0, 1&gt;$$</p>
<p>的<strong>线性组合</strong>：$v &#x3D; a&lt;1, 0&gt; + b&lt;0, 1&gt; &#x3D; ai + bj$。$a$和$b$分别称为<strong>水平分量&#x2F;i分量</strong>和<strong>垂直分量&#x2F;j分量</strong>。</p>
<p>例：一个向量可以表示为与其同方向单位向量的数乘，求$v &#x3D; 3i - 4j$的此种表示。</p>
<p>解：$|v| &#x3D; 5$，那么$\frac{v}{|v|}$即为与其同方向的单位向量，令其乘以$|v|$即可得到原向量。结果是$v &#x3D; 5(\frac{3}{5}i - \frac{4}{5}j)$。</p>
<p>$\frac{v}{|v|}$是与$v$同方向的单位向量，也称为$v$的<strong>方向</strong>。</p>
<h3 id="切线和法线"><a href="#切线和法线" class="headerlink" title="切线和法线"></a>切线和法线</h3><p>一个向量是一条曲线在一个点$P$的<strong>切向量</strong>或<strong>法向量</strong>，如果它分别平行或垂直于曲线在该点的切线。切线斜率可由导数计算，而法线斜率则是导数的负倒数。</p>
<p>例：在曲线路径上，速度是切向量，如果物体受到法向量方向上的力，速度会发生变化。</p>
<h2 id="点积"><a href="#点积" class="headerlink" title="点积"></a>点积</h2><pre><code>- Dot Products
</code></pre>
<p>本节将了解如何通过向量分量计算两个向量的夹角，其关键是称为<strong>点积</strong>的表达式，点积亦称为<strong>数量积</strong>。之后还会介绍如何求解一个向量在另一个向量上的<strong>投影</strong>。</p>
<p>中学物理中，力的分解将一个向量分解为两个方向上的分量。特别地，如果要求力$F$在$v$的方向上的大小，改大小可以表示为$|F|\cos \theta$，这里的$\theta$是两向量的夹角。</p>
<h3 id="向量夹角"><a href="#向量夹角" class="headerlink" title="向量夹角"></a>向量夹角</h3><p>如果两向量$u, v$起点重合，它们形成大小为$\theta$的角，这个角称为两者的<strong>夹角</strong>。</p>
<p>定理：<strong>两向量的夹角</strong></p>
<p>两个<strong>非零向量</strong>$u &#x3D; &lt;u_1, u_2&gt;$和$v &#x3D; &lt;v_1, v_2&gt;$的夹角由如下公式给出：</p>
<p>$$\theta &#x3D; cos^{-1} \frac{u_1 v_1 + u_2 v_2}{|u| |v|}$$</p>
<p>式中的分子部分称为向量的<strong>点积</strong>或<strong>内积</strong>，即各分量乘积之和，记为$u \cdot v$。故上述公式又可表示为：</p>
<p>$$\theta &#x3D; cos^{-1} \frac{u \cdot v}{|u| |v|}$$</p>
<p>此定理可由三角形的<strong>余弦定理</strong>证明。该等式又可变形为：</p>
<p>$$u \cdot v &#x3D; |u| |v| \cos \theta$$</p>
<h3 id="点积法则"><a href="#点积法则" class="headerlink" title="点积法则"></a>点积法则</h3><p>依实数性质，点积遵循若干运算法则，如交换律、分配律等，特别地有：$u \cdot u &#x3D; |u|^2$</p>
<h3 id="垂直（正交）向量"><a href="#垂直（正交）向量" class="headerlink" title="垂直（正交）向量"></a>垂直（正交）向量</h3><p>若两个非零向量$u, v$夹角为$\pi&#x2F;2$，那么它们是<strong>垂直的</strong>或<strong>正交的</strong>。此时由夹角定理可知，$u \cdot v &#x3D; 0$，反之亦成立。</p>
<p>由于零向量可以是任意方向的，故零向量垂直于任意向量。这样的规定也符合上段的结论。</p>
<h3 id="向量投影"><a href="#向量投影" class="headerlink" title="向量投影"></a>向量投影</h3><p>向量$u, v$起点重合，从$u$终点引垂线，由起点与垂足确定的向量称为$u$在$v$上的<strong>投影</strong>，记为$proj_vu$。其计算公式为：</p>
<p>$$proj_vu &#x3D; (|u|\cos \theta ) \frac{v}{|v|} &#x3D; (\frac{u \cdot v}{|v|^2}) v$$</p>
<p>其中$|u|\cos \theta$称为**$u$在$v$方向上的数值分量**。</p>
<h3 id="把一个向量写成正交向量之和"><a href="#把一个向量写成正交向量之和" class="headerlink" title="把一个向量写成正交向量之和"></a>把一个向量写成正交向量之和</h3><p>由向量投影的定义，$v$与$u - proj_vu$是正交的，而且它们的和等于$u$，这样就得到了将$u$分解的方法：</p>
<p>$$u &#x3D; proj_vu + (u - proj_vu)$$</p>
<h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>柯西-施瓦茨不等式：$|u \cdot v| \leq |u| |v|$，当两向量平行时等号成立。</p>
<p>垂直于向量的直线：向量$v &#x3D; ai + bj$垂直于直线$ax + by &#x3D; c$。</p>
<p>平行于向量的直线：向量$v &#x3D; ai + bj$平行于直线$bx - ay &#x3D; c$。</p>
<h2 id="向量值函数"><a href="#向量值函数" class="headerlink" title="向量值函数"></a>向量值函数</h2><pre><code>- Vector-Valued Functions
</code></pre>
<p>本节将以向量来研究平面上运动物体的路径、速度与加速度，其中有许多微分和积分概念从数值函数推广到了向量值函数。</p>
<h3 id="平面曲线"><a href="#平面曲线" class="headerlink" title="平面曲线"></a>平面曲线</h3><p>当一个质点历经<strong>时间区间</strong>$I$在平面运动时，质点的坐标可看作定义在区间上的函数</p>
<p>$$x &#x3D; f(t), y &#x3D; g(t), t \in I$$</p>
<p>注：这又回到开始时接触到的<strong>参数方程</strong>。之所以选用参数方程而不是一般的$(x, y)$方程，是因为在诸如运动这类问题中，时间是更自然的自变量，而选择了时间作自变量，那么$(x, y)$也就自然地分开表示了。如果不用时间，那么何者为$x$，何者为$y$？它们的关系如何表示？</p>
<p>点$(x, y) &#x3D; (f(t), g(t))$形成平面上的曲线，称为质点的<strong>路径</strong>。在时刻$t$的<strong>位置</strong>$P(f(t), g(t))$的向量</p>
<p>$$r(t) &#x3D; \overrightarrow{OP} &#x3D; &lt;f(t), g(t)&gt; &#x3D; f(t) \text{i} + g(t)\text{j}$$</p>
<p>称为质点的<strong>位置向量</strong>。因此$f, g$称为位置向量的<strong>分量函数</strong>。于是质点的路径是经由时间区间$I$由$r$描绘的曲线。</p>
<p>$r(t)$定义在实变量上，函数值为向量，这就是所谓的<strong>向量值函数</strong>。相对地，一般实数值函数称为<strong>标量函数</strong>。</p>
<p>例：$r(t) &#x3D; (t\cos t)i + (t\sin t)j, t \geq 0$表示一条螺线。</p>
<h3 id="极限与连续"><a href="#极限与连续" class="headerlink" title="极限与连续"></a>极限与连续</h3><p>定义：<strong>向量值函数极限</strong></p>
<p>若$r$的两分量函数在某点皆有极限，那么$r$也有极限：</p>
<p>$$\lim_{t \to c} r(t) &#x3D; \lim_{t \to c} f(t)i + \lim_{t \to c} g(t)j$$</p>
<p>定义：<strong>连续性</strong></p>
<p>若$\lim_{t \to c} r(t) &#x3D; r(c)$，则$r$在$c$连续。</p>
<p>由极限定义可知，$r$在$c$连续，当且仅当$f$和$g$在$c$连续。</p>
<h3 id="导数"><a href="#导数" class="headerlink" title="导数"></a>导数</h3><p>定义：<strong>向量值函数在一点的导数</strong></p>
<p>向量函数$r &#x3D; fi + gj$在$t$有导数，若$f$和$g$在$t$有导数。导数是：</p>
<p>$$r’(t) &#x3D; \frac{dr}{dt} &#x3D; \frac{df}{dt}i + \frac{dg}{dt}j$$</p>
<p>注：目前可见，上述定义都是标量函数相应概念的自然推广。</p>
<p>若$r$在定义域内每个点都是可微的，那么说$r$是可微的。若$dr&#x2F;dt$是连续的且从不为0（注意这里是零向量），那么说$r$描绘的曲线是光滑的（这意味着$f$和$g$有连续一阶导数且不同时为零）。</p>
<p>向量$dr&#x2F;dt$存在且不为零时，$dr&#x2F;dt$是曲线在该点的<strong>切向量</strong>，以此可求出曲线的<strong>切线</strong>。</p>
<p>向量值函数的导数是按分量计算的，而分量函数皆是一般的标量函数，因此向量值函数的导数继承了很多标量函数的性质，比较特别的是如下两个：</p>
<ul>
<li>点积法则：$\frac{d}{dt}[u(t) \cdot v(t)] &#x3D; u’(t) \cdot v(t) + v’(t) \cdot u(t)$</li>
<li>链式法则：$\frac{d}{dt}[u(f(t)] &#x3D; f’(t) u’(f(t))$</li>
<li>标量乘积法则：$\frac{d}{dt}[f(t)u(t)] &#x3D; f’(t)u(t) + f(t)u’(t)$</li>
</ul>
<p>注意其中标量函数与向量值函数交错的地方。</p>
<h3 id="向量函数在运动中的应用"><a href="#向量函数在运动中的应用" class="headerlink" title="向量函数在运动中的应用"></a>向量函数在运动中的应用</h3><p>在将质点的运动路径以向量表示后，速度、加速度等也随之确定下来了。</p>
<p>定义：<strong>速度、速率、加速度、运动的方向</strong></p>
<p>若$r$是沿光滑平面曲线运动的质点的位置向量，则在时刻$t$，</p>
<ol>
<li>$v(t) &#x3D; \frac{dr}{dt}$是质点的<strong>速度向量</strong>，与曲线相切</li>
<li>$|v(t)|$是速度的大小，即速率</li>
<li>$a(t) &#x3D; \frac{dv}{dt}$，速度的导数，或位置向量的二阶导数，称为<strong>加速度向量</strong></li>
<li>$\frac{v}{|v|}$，一个单位向量，是<strong>运动的方向</strong>。</li>
</ol>
<p>速度可以写成$|v|(\frac{v}{|v|})$，此即速率与方向之乘积。</p>
<p>至此可以看到，表示运动的函数向量化以后，相应的各个量都能容易地转为向量。</p>
<h3 id="积分"><a href="#积分" class="headerlink" title="积分"></a>积分</h3><p>定义：<strong>不定积分</strong></p>
<p>$r$对$t$的不定积分是$r$的所有反导数的几何，用$\int r(t)dt$表示，若$R$是任一反导数，则有</p>
<p>$$\int r(t)dt &#x3D; R(t) + C$$</p>
<p>定义：<strong>定积分</strong></p>
<p>$$\int_{a}^{b} r(t)dt &#x3D; (\int_{a}^{b} f(t)dt)i + (\int_{a}^{b} g(t)dt)j$$</p>
<p>可以说：积分之分量等于分量之积分。</p>
<p>注：微积分基本定理也适用于向量值函数（见习题9.3 43）：</p>
<ul>
<li>$$\frac{d}{dt}\int_{a}^{t}r(q)dq &#x3D; r(t)$$</li>
<li>$$\int_{a}^{b}r(t)dt &#x3D; R(b) - R(a)$$</li>
</ul>
<h2 id="对抛射体运动建模"><a href="#对抛射体运动建模" class="headerlink" title="对抛射体运动建模"></a>对抛射体运动建模</h2><pre><code>- Modeling Projectile Motion
</code></pre>
<p>暂从略。</p>
<h2 id="极坐标和图形"><a href="#极坐标和图形" class="headerlink" title="极坐标和图形"></a>极坐标和图形</h2><pre><code>- Polar Coordinates and Graphs
</code></pre>
<h3 id="极坐标系"><a href="#极坐标系" class="headerlink" title="极坐标系"></a>极坐标系</h3><p>中学解析几何已经学习过极坐标系，它包含一个<strong>极点</strong>和一条<strong>极轴</strong>，这样平面上任一点都可以指定一个极坐标$(r, \theta)$。</p>
<p>$\theta$与三角学中的情形一样，有正负之分。同时一个给定点的角不是唯一的，因为不同的角可以重合；而且$r$也有正负之分，如果$r$为负，表示其方向与一般定义的方向相反。故$(2, 7\pi&#x2F;6)$与$(-2, \pi&#x2F;6)$表示同一个点。</p>
<h3 id="极图形"><a href="#极图形" class="headerlink" title="极图形"></a>极图形</h3><ul>
<li>$r &#x3D; a$，表示圆心在极点，半径为$|a|$的圆；</li>
<li>$\theta &#x3D; \alpha$，表示过极点的一条直线。</li>
</ul>
<h3 id="其他内容"><a href="#其他内容" class="headerlink" title="其他内容"></a>其他内容</h3><p>暂从略。</p>
<h1 id="空间中的向量和运动"><a href="#空间中的向量和运动" class="headerlink" title="空间中的向量和运动"></a>空间中的向量和运动</h1><pre><code>- Vectors and Motion in Space
</code></pre>
]]></content>
      <tags>
        <tag>Maths</tag>
      </tags>
  </entry>
  <entry>
    <title>what-is-populism</title>
    <url>/2020/10/31/what-is-populism/</url>
    <content><![CDATA[<h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><blockquote>
<p>政治是由各种团体进行集体决策的一个过程，也是各种团体或个人为了各自的领域所结成的特定关系，尤指对于社会群体的统治，例如统治一个国家，亦指对于一国内外事务之监督与管制。狭义来说，这个词多用来指政府、政党等治理国家的行为。</p>
</blockquote>
<blockquote>
<p>从人类社会学来讲，政治是人类社会中存在的一种非常重要的社会现象，它影响到人类生活的各个方面。<br>政治学是专门以政治为研究对象的一门社会科学，研究政治行为的理论和考察权力的获得与行使。</p>
</blockquote>
<p>”政治是由各种团体进行集体决策的一个过程“，团体有不同的构成，决策有不同的方式。但不管怎样，在现代社会，每个人都无法逃脱政治，即使你不关心它，它仍然以某种方式影响到你。</p>
<p>”团体“的划分，有时我们会自己归类，比如无产、中产，但社会的看不见的手则将每个人都归类了，比如”精英“和”大众“。</p>
<h2 id="精英主义与民粹主义"><a href="#精英主义与民粹主义" class="headerlink" title="精英主义与民粹主义"></a>精英主义与民粹主义</h2><p>精英主义（Elitism）是从现实主义出发来理解和阐释政治与社会的结构及其发展的一种理论，认为应该由少数具备知识、财富与地位的社会精英，来进行政治决策，主导社会走向。精英主义的反义词为民粹主义（大众主义）。 </p>
<blockquote>
<p>以大众主义者的角度而言，常认为精英主义者是蔑视大众的。精英主义甚至被认为是一种对普通大众的蔑视、嘲笑，甚至仇视；而精英主义者认为大众是一个无知、盲动而又自命不凡的群体，“奴隶”、“野蛮人”、“乌合之众”、“群畜”等名词是精英主义下的产物。 </p>
</blockquote>
<p>精英主义者的拥护者认为不是所有人都有能力参与政治决策，由精英治理国家是最佳选择，否则将陷入”暴民政治“。现实中其结果常常是精英群体作为既得利益者，只想维护自身的地位。精英主义的存在给民粹主义带来了产生的土壤。</p>
<p>PS：对于现代社会中的公民来说，将决策完全交给”精英“是省心的，精英类似于家长，代为决策。</p>
<h2 id="建制派"><a href="#建制派" class="headerlink" title="建制派"></a>建制派</h2><blockquote>
<p>建制派（The Establishment）是指支持主流与传统、主张维护现有体制的政治势力。这一术语用于描述控制政体或组织的统治集团或精英，可能存在于一个封闭的社会团体（该团体选择自己的成员），或在特定机构中根深蒂固的精英阶层。可以行使控制权的任何相对较小的阶级或人群都可以被称作“建制派”。</p>
</blockquote>
<h2 id="代议制"><a href="#代议制" class="headerlink" title="代议制"></a>代议制</h2><p>代议民主制（Representative Democracy），又称间接民主制（Indirect Democracy），与直接民主制相对立，是由公民以选举形式选出立法机关的成员（议员），并代表其在议会中行使权力（称为代议）、制定法律和管理公共事务的一类民主制度。简言之，就是人民通过其代表来进行统治，而不是直接进行统治。在此种政制之下，“主人”与“主事”相互分离，用约翰·密尔的话说：“人民应该是主人，但他们必须聘用比他们更能干的仆人。”</p>
<p>直接民主制是一种自古存在的民主体制，在这种体制中，每一个公民直接参与所有政策的制订，而方法是全体投票来决定，例如公民投票便是其中一种实践直接民主的方式（全民公投）。</p>
<h2 id="民粹主义"><a href="#民粹主义" class="headerlink" title="民粹主义"></a>民粹主义</h2><blockquote>
<p>民粹主义（Populism），又译为平民主义、大众主义、人民主义、公民主义，意指平民论者所拥护的政治与经济理念，是社会科学语汇中最没有精确定义的名词之一，也可以被当成是一种政治哲学或是政治语言。学术界有关民粹主义的讨论甚多，但是把它当成一个独立学术概念来处理的却很少，主要原因是民粹主义呈现的样貌过于丰富、难以捉摸。（Wikipedia）</p>
</blockquote>
<p>一方面没有精确定义，另一方面则是不断滥用，引用频率是在太高。因此需要一本书来厘清其中的细节。</p>
<h1 id="中文版序言"><a href="#中文版序言" class="headerlink" title="中文版序言"></a>中文版序言</h1><p>近年来民粹主义成为热词，用于描述一种令人注目的新兴政治势力：英国独立党法拉奇、美国特朗普、法国勒庞、匈牙利欧尔班、土耳其埃尔多安等。他们呈现出某些相似的特点：强硬而富有煽动力，鼓吹极端的理念与政策，宣称代表底层民众，发誓彻底改变腐败和无能的建制派精英造就的黑暗现状，向民众许诺一个光明的未来。</p>
<p>作者认为，民粹主义的”界定性特征“不是反对精英，而是对”人民”代表性的垄断。民粹主义者宣称，他们且只有他们才代表“真正的人民”及其意志与利益。</p>
<p>民粹主义是代议制民主无法摆脱的“永恒的影子”，一种“源于民主世界内部”的危险。</p>
<ul>
<li>对“人民”代表性的垄断</li>
<li>反多元</li>
<li></li>
</ul>
<p>在一个复杂多元的现代社会里，不存在单一的政治意志，更不用说单一的政治观点。</p>
<p>民粹主义者制造一个神话：世上存在一个真正的“人民”群体，一个同质性的、永远正直的人民，全体人民可以通过一个声音表达心声，而民粹主义者自己就是这个声音，是人民独一无二的代表。</p>
<p>民粹主义对民主政治的危害：</p>
<ul>
<li>将政治对手非法化：实际上可能只是政策分歧，而分歧并非问题，也不是“善恶”问题</li>
<li>否定了多元化</li>
</ul>
<p>流行的误解：</p>
<ul>
<li>民粹主义比代议制民主更具“直接民主”的倾向：他们制造民意的方式是在民主程序之外来定义人民，他们并不是真地反对代议制民主、精英主义，不真地关心人民，不促进开放和广泛的辩论，他们要的是“民意”</li>
<li>右翼民粹主义的支持者与其社会经济状况强相关：美国的情况并非如此。特朗普的成功之处是，他让许多白人相信自己的地位已经衰落</li>
<li>民粹主义政客上台之后会自我瓦解，因为他们没有真正可行的政策：即使他们面临失败与挑战，他们仍然可以找到许多替罪羊，他们也偏爱阴谋论</li>
</ul>
<p>民粹主义通过控制非政府力量，打击异议组织，造就了他们期望的同质化人民，从而成为某种“自我实现的预言”。这样，他们也就犯下了自身曾经提出的指控：排斥公民和篡夺国家，成为新的建制派。</p>
<p>如何应对民粹主义，作者提出：</p>
<ul>
<li>防止对民粹主义的滥用</li>
<li>认清民粹主义对民主的威胁，而不是夸大他们对精英权力的矫正作用</li>
<li>将政客与其支持者区分开来：有的政治问题并非完全虚构</li>
<li>直面我们时代特有的真实冲突</li>
</ul>
<p>保罗·瓦莱里：我从“人民”这个词中看到的唯一语意是“混合”。</p>
<p>PS：“人民的”从来都意味着“多元化的”。</p>
<p>贝尔托·布希莱特：一切权力都来自人民，但人民去了哪里？</p>
<p>PS：代议制之下，人民的消失。</p>
<h1 id="导论：人人都是民粹主义者吗？"><a href="#导论：人人都是民粹主义者吗？" class="headerlink" title="导论：人人都是民粹主义者吗？"></a>导论：人人都是民粹主义者吗？</h1><p>汉娜·阿伦特：政治判断力就是进行合理区分的能力。</p>
<p><strong>本书试图帮助我们认识和对待民粹主义。</strong></p>
<ul>
<li>说明什么样的人物算是民粹主义。<strong>批评精英</strong>只是必要条件；通常反对多元主义（道德上的排他性），从而对民主构成威胁。</li>
</ul>
]]></content>
      <categories>
        <category>政治学</category>
      </categories>
      <tags>
        <tag>政治学</tag>
      </tags>
  </entry>
  <entry>
    <title>关于书评写作</title>
    <url>/2021/07/27/%E4%B9%A6%E8%AF%84%E5%86%99%E4%BD%9C/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>本文主要整理了关于书评写作的几篇文章的内容，这些文章是：</p>
<ul>
<li><a href="https://book.douban.com/review/8374678/">如何写出高质量的书评</a></li>
<li><a href="https://www.zhihu.com/question/20750866/answer/32340974">如何写出好的书评</a></li>
<li><a href="https://www.jianshu.com/p/a973416be1a7">给刚开始写书评的人的一些写书评的套路</a></li>
<li><a href="https://www.essaymon.com/how-to-write-a-book-review-guide.html">如何写书评</a></li>
</ul>
<p>而上述文章又来自于<a href="https://book.douban.com/subject/26952635/">完全写作指南</a>。</p>
<h1 id="通用写作-checklist"><a href="#通用写作-checklist" class="headerlink" title="通用写作 checklist"></a>通用写作 checklist</h1><p>整理自夏丏尊的《文章作法》，所谓 6W：</p>
<ul>
<li>Why：写作目的是？（叙述、趣味、评论等）</li>
<li>What：要写什么？（旅行经历、一个命题等）</li>
<li>Who：写给谁看？（以理解作者与读者的关系，且行文应因人而异）</li>
<li>Where：写作的情境、场合（在乡村、程序员、学术圈等）</li>
<li>When：文章主题所属的时代、季节等</li>
<li>How：如何写？（体裁、简述&#x2F;详述、直白&#x2F;委婉、布局等）</li>
</ul>
<h1 id="写作步骤（文1）"><a href="#写作步骤（文1）" class="headerlink" title="写作步骤（文1）"></a>写作步骤（文1）</h1><h2 id="1、明确目标"><a href="#1、明确目标" class="headerlink" title="1、明确目标"></a>1、明确目标</h2><p>写任何文章之前都需要明确目标是什么，书评也不例外。书评通常是对某本书发表自己的见解，其中可能包含了（或明或暗地）是否建议读者去阅读。</p>
<h2 id="2、站在读者角度"><a href="#2、站在读者角度" class="headerlink" title="2、站在读者角度"></a>2、站在读者角度</h2><p>先考虑读者可能是谁，然后考虑两个关键词：信息与态度（想读与不想读）。</p>
<h2 id="3、头脑风暴，确定要表达的内容"><a href="#3、头脑风暴，确定要表达的内容" class="headerlink" title="3、头脑风暴，确定要表达的内容"></a>3、头脑风暴，确定要表达的内容</h2><p>边阅读边写笔记，将书中有价值的内容罗列出来，从而在写作书评有迹可循。</p>
<h2 id="4、文章组织"><a href="#4、文章组织" class="headerlink" title="4、文章组织"></a>4、文章组织</h2><p>组织方式取决于文章类型与目标，《完全写作指南》给出的基本范例是：</p>
<ul>
<li>开头：介绍书的基本信息，如作者、标题、图书类别等</li>
<li>中间：讲述书中最精彩的部分，逐步对内容进行深入说明</li>
<li>结尾：总结自己的观点，告知值不值得读，表明自己的看法</li>
</ul>
<p>此范例中规中矩，似乎有些乏味，但对于初学者来说颇值得参考。</p>
<h2 id="5、初稿"><a href="#5、初稿" class="headerlink" title="5、初稿"></a>5、初稿</h2><p>将想到过的内容先写出来，这个过程可能还会产生新的想法。</p>
<h2 id="6、修改"><a href="#6、修改" class="headerlink" title="6、修改"></a>6、修改</h2><p>修改是必须的，最好在初稿之后稍微隔一小段时间进行。</p>
<h1 id="注意事项（文1）"><a href="#注意事项（文1）" class="headerlink" title="注意事项（文1）"></a>注意事项（文1）</h1><h2 id="对内容进行取舍"><a href="#对内容进行取舍" class="headerlink" title="对内容进行取舍"></a>对内容进行取舍</h2><p>毕竟篇幅有限，而且需要突出书的特色，不可能事无巨细完全涵盖到。</p>
<h2 id="书评主要是表达自己观点，不是大段摘抄"><a href="#书评主要是表达自己观点，不是大段摘抄" class="headerlink" title="书评主要是表达自己观点，不是大段摘抄"></a>书评主要是表达自己<strong>观点</strong>，不是大段<strong>摘抄</strong></h2><p>基于书的内容，和自己的经验、知识等结合起来，以自己的方式表达出来，其实这不止是写给读者，也是自己学习的好机会。</p>
<h2 id="不要使用书籍名称作为书评名"><a href="#不要使用书籍名称作为书评名" class="headerlink" title="不要使用书籍名称作为书评名"></a>不要使用书籍名称作为书评名</h2><p>使用能反映书的内容的名字。</p>
<blockquote>
<p>所谓习惯写作，就是持续不断地写，永远不要放弃，它终究会教你如何写作。</p>
</blockquote>
<h1 id="按读者类型划分（文2）"><a href="#按读者类型划分（文2）" class="headerlink" title="按读者类型划分（文2）"></a>按读者类型划分（文2）</h1><h2 id="给自己"><a href="#给自己" class="headerlink" title="给自己"></a>给自己</h2><h3 id="情绪"><a href="#情绪" class="headerlink" title="情绪"></a>情绪</h3><p>暂不理会“傲慢与偏见”，纯粹自我感受之发挥，减少自我审查。</p>
<h3 id="写作技巧"><a href="#写作技巧" class="headerlink" title="写作技巧"></a>写作技巧</h3><p>仍然作为写作练习来看待，视为片段写作，尽列书中有感触者，加上自己的点评。这些内容也可以作为未来灵感之来源。</p>
<p>倾向于“读书笔记”。</p>
<h2 id="给他人（朋友、豆瓣等）"><a href="#给他人（朋友、豆瓣等）" class="headerlink" title="给他人（朋友、豆瓣等）"></a>给他人（朋友、豆瓣等）</h2><blockquote>
<p>这种写法建立在写给自己看的基础之上，相同点在于要选择书中一点或几点打动你的地方来进行评论，尤其是初学写作的，忌贪多求全，能把一个观点讲深、讲透就很好。</p>
</blockquote>
<h3 id="情绪-1"><a href="#情绪-1" class="headerlink" title="情绪"></a>情绪</h3><p>必须有个人观点，避免情绪化偏见。或者说是“有依据的观点”。</p>
<h3 id="写作技巧-1"><a href="#写作技巧-1" class="headerlink" title="写作技巧"></a>写作技巧</h3><ul>
<li>趣味性：即能让人看下去</li>
<li>书评不限于书本身：讲述这本书与你的思想、生活的联系</li>
<li>切入点可考虑从普通人的日常生活中选取</li>
</ul>
<p>对于公之于网络的书评，可以当作是给一个朋友写的书评，那么你会怎么写？（是否恰好符合上述三方面）。</p>
<p>给朋友的书评，首先会包含关于书本身的评论，同时也会有一定的倾向，如对于某些人可以不读；对于另一些人强烈推荐等等。</p>
<h2 id="给媒体"><a href="#给媒体" class="headerlink" title="给媒体"></a>给媒体</h2><p>此种先行略过。</p>
<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>作为第一步，先考虑这些：</p>
<ul>
<li>考虑 general checklist</li>
<li>参考上面的写作步骤</li>
<li>考虑：现在要写给一个朋友看，该如何做？</li>
</ul>
]]></content>
      <categories>
        <category>写作</category>
      </categories>
      <tags>
        <tag>写作</tag>
      </tags>
  </entry>
  <entry>
    <title>儿时伙伴</title>
    <url>/2019/11/08/%E5%84%BF%E6%97%B6%E4%BC%99%E4%BC%B4/</url>
    <content><![CDATA[<p>前几天生日时，和我娘聊起来一个人，他的有点儿戏剧性的故事，让我想起来他也算是儿时伙伴之一了。</p>
<p>在村子里，不止是与村外联系少，村内也是如此，当时一起耍的，也只限于邻近家同龄的孩子。其中有一个打我一岁的，小名俩字和我的是反过来的，姑且称他为 H。</p>
<p>H 属于对学习毫无兴趣的那种，但算是比较灵头（灵活的头脑之意）的，形貌也高于均值。很早就到市里厮混，相形之下颇有些见识，我初中时的一盘流行歌曲正版磁带，就是从他那里拿到的。多年之后回忆起来，里面还有一首《黑梦》。印象中的样子是，他见到你，露出笑容，跟你开几句玩笑，满嘴”油腔滑调“。</p>
<p>小学时，为解决灌溉问题，村里集资在小河流经处挖了一个大坑，人称”大湾“，号称有十米之深。这里成为当时孩子们渴望去探索的地方，虽然基本上都不会真正地游泳。听闻有一次，他带着一群孩子去游泳，一个孩子游到中间开始往下沉，呼喊救命，他赶紧跳下去，把那个孩子救了上来。后来孩子的父母送去一筐水果作为答谢。</p>
<p>曾跟随他偷过葡萄、海棠果、苹果之类，至于为何没偷其它水果，只是因为附近没有种的。但他还偷钱，这似乎是性质严重得多的事情。</p>
<p>上了高中之后，我再也没有偷过东西，和他也很少会见面。听说，有个女孩子喜欢她，趄（ju）着他不走，他不太喜欢她，不过后来他们还是结婚了。</p>
<p>如果他此后变得安分，也有点浪子回头的意味了，但是没有。听说，他伙同姨妈的表兄弟及邻村的一人，去绑架了当地某厂长的母亲。不知细节如何，但结果是正好一辆车过来，轧死了老太太，他不得不承担这一切。</p>
<p>他被带走的那个夜晚，他的儿子也出生了，我想当时应该是大雨如注吧。</p>
]]></content>
      <categories>
        <category>故事</category>
      </categories>
      <tags>
        <tag>故事</tag>
      </tags>
  </entry>
  <entry>
    <title>历史的技艺</title>
    <url>/2021/05/01/%E5%8E%86%E5%8F%B2%E7%9A%84%E6%8A%80%E8%89%BA/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>总的来说，比较“硬”的、有诸多事实和主题，或是讲亲身经历的文章和报道至今耐读，而当时用作批评和鼓吹，或基于一时的政治风潮而写的“观点型”文章，则光辉不再。</p>
<p>这两篇文章未能收录于此供读者评判，但它们佐证了筛选文集的难度：我对其中一篇所描述的事件颇有共鸣，对另一篇则没有，但这两篇文章都失之淡然。</p>
<p>这一点，连同我为《太平洋事务》写的第一篇稿子所得的40美元稿费（我用来买了一台留声机和《蝴蝶夫人》选段《晴朗的一天》的唱片），让我觉得，我的职业生涯已经开始。</p>
<p>我一直认为，让一个人背负深刻烙印的是他步入成熟的那些年，而不是他出生的那一年。所以，我认为我自己是19世纪30年代的孩子。我有信仰，我猜二十几岁的人都会有（在我那代人中确实是这样）。我信仰正义和理性最终会获得胜利。</p>
<p>对于这些选文凑在一起是否提供了某种历史哲学的问题，我回答起来一直都甚为小心，因为我害怕各种哲学。它们隐藏着历史学家试图操控事实以充实自己理论体系的危险，导致历史强于意识形态，弱于“事实是如何发生的”。我不敢保证，一个长期写作历史的人不会遵行某种原理和准则。我想，后面的这些文章展现的是历史的一种偶然和循环，一种人类行为，就像平静的河水在无穷无尽的各种田野中流过，时代和人的好与坏交织共存，横流和逆流交替来回，任何一种简单的归纳都无法涵盖。至于应该怎样，我相信，事实应该早于论点；相信编年叙述（chronological narrative）是骨架和血液，它让历史更接近于“事实是如何发生的”，更易于恰当地理解原因和作用；我还相信，历史应该以当时的所知所识来叙述，而不是带着事后诸葛亮的视角，否则结论不足为信。虽然我没有做原创性声明，但这些原则都是我自己在多年的技艺习练和职业实践中发现的。</p>
<h1 id="上篇-历史技艺"><a href="#上篇-历史技艺" class="headerlink" title="上篇 历史技艺"></a>上篇 历史技艺</h1><h2 id="寻找历史"><a href="#寻找历史" class="headerlink" title="寻找历史"></a>寻找历史</h2><p>后来我的兴趣越来越倾向于历史文学方向，而不是纯历史。</p>
<p>（在大学），有意思的是，对我帮助最大的三门课中，有两门都是文学，不是历史。</p>
<p>（关于论文），我希望你是真正强烈地关心其中的“潜在意象”，而不是因为你所在的院系认为这是一个原创度很高的题目。</p>
<p>（在哈佛的怀德纳图书馆）我在丰富的书架间随兴徜徉，随心所欲地翻阅。这种经历妙不可言。在大约15年后正式开始历史写作前，我学术生活中最快乐的时光就是在怀德纳的书架中度过的。</p>
<p>我对我的论文有同样的感觉：立意多好啊，写得多差啊。所以，光有热情是不够的，还需要知道如何运用语言。我发现，写作是在练习中学会的。我在杂志历练了7年发现，有没有好的文字，关键在于写作者有没有一双好耳朵。写作者需要倾听自己文章的声音。</p>
<p>我在首次失败后定下了这样的目标：<strong>写吸引读者的历史，让他们和我一样对写作主题欲罢不能。前提是，这段故事必须要先吸引我自己，以至于有一种分享的使命感</strong>。和谁分享呢？当然是读者，我一直将之装在心里的人。</p>
<p>如果历史作者希望读者读下去，他就肩负着对他们的很多责任。第一步是去粗存精。他必须做一些准备工作，搜集资料，组织逻辑，挑选精华，丢掉无关内容，然后把剩下的综合到一起，使之形成一种发展式的引人入胜的叙述。<strong>叙述，被称为历史的命脉</strong>。扔给读者一大堆未经消化的内容、未敢确认的人名和未可定位的地名对他们来说毫无用处，这是作者的懒惰，或是炫耀所学庞杂的虚荣。丢掉无关内容需要勇气，还需要一些额外的工夫。历史学家总是被历史的旁门和枝节所吸引，但写作的艺术——对艺术家的试炼——就在于，是否能够忍痛割爱，直奔主题。</p>
<p>我认为自己是个讲故事的人，一个讲述者，只不过我讲的确有其事，并非虚构。二者的区别不在于谁比谁更有价值，只是历史比小说更吸引我而已。</p>
<p>兰克也为历史学家设定了任务：找到“wie es eigentlich gewesen ist”——发生了什么，或者就字面来说——真相是什么。我们写过去的事，但我们不是过去的人。我们永远也不能保证，我们重写的故事是否就是真相，<strong>我们唯一能做的只是保证用证据说话</strong>。</p>
<p><strong>材料的选择决定了最终作品的质量，这是我只用原始文献的原因</strong>。我对二手文献的态度是，它们有用，但也有害。我在写作计划之初会看它们，它们引导我了解故事梗概，但我从不引用它们，因为我不想再重写一遍别人的书。<strong>二手文献中的事实是已经被筛选过的，使用它们就表明你放弃了自己筛选的机会。</strong></p>
<p>原始文献中的偏见是可以预见的，你应该允许它存在，并通过阅读其他版本来修正它。</p>
<p>**我有一个做研究的小技巧，就是在4×6的索引卡片上记笔记。**每隔一个小时，我就要温习从一本研究手册上看来的规矩：“千万不要在任何东西的背面记笔记。”既然复印是件烦人的工作，那么请使用卡片，越小越好，有助于你提取相关度最高的信息，从一开始就去粗存精，记下你在脑子里研磨过的材料。最后，当围绕某个主题、某个人或依据年代顺序把卡片聚集在一起时，我的故事就能开讲了。</p>
<p>**关于做研究，最重要的事是要知道何时停止。**怎么才能知道是何时呢？在我18岁左右，我妈妈告诉我，在跟年轻小伙子出去时，要在你冒出回家念头的半个小时前回家。虽然我不知道这怎么可能实现，但我认为这是个好建议，同样可以运用于做研究。你必须在你完成之前停下来，否则你永远也停不下来，也永远完不成。</p>
<p>历史写作的一个难点是，如何在人人都知道结果的情况下让故事保持悬念。我一开始十分担心这一点，但当我进入实际写作，并且反复验证之后，就有了办法。我发现，如果你装作并未时过境迁，避免受惠于事后诸葛亮的聪明，忍住不要提到之后发生的事件，那么，悬念自然而然就会自己产生。</p>
<p>这将把我引向一个至今悬而未决的问题——<strong>历史的本质</strong>。如今，这场争论如你所知还在扩散。一边是宏观思想家（big thinkers），或者说汤因比们，或者系统论者；另一边是人性论者（humanists）——我这样叫他们，取其关乎“人性”的意思，而跟“人道”无关。<strong>汤因比型的人着迷于寻找历史的解释。他们制作了种种系统和周期要把历史挤压进去，这样历史就会有一个标准的形状，有了模式，有了意义</strong>。</p>
<p>他说：“<strong>理论先行的历史学家很难避免偏爱最适合他系统的事实。</strong>”他还说：“历史读者的心里都应该有此判断。”这简直就是我的口号。</p>
<p>在一开始，找出发生了什么就够了，不必急于确定“为什么”。我相信，在你搜集了足够的事实，并将它们依时间顺序排列之后——具体地说，是把它们落笔写为句子、段落和章节之后，再问“为什么”，才更为安全。</p>
<p>如果历史学家屈服于自己的材料，而不是把自己强加于材料，那么，那些材料最终会对他说出历史谜团的答案。</p>
<p>在经历了1914年头30天的战争之后，人们已经预感到，前路上已经没有任何荣誉可言了。</p>
<p>我写作的目的不是指导什么，只是讲故事而已。<strong>启示是聪明的读者自己从书中获得的</strong>。我想，这是因为（也应该如此），<strong>最好的书得益于作者和读者的通力合作</strong>。</p>
<h2 id="历史何时开始"><a href="#历史何时开始" class="headerlink" title="历史何时开始"></a>历史何时开始</h2><p>近来，这种滚烫鲜活的历史大受出版商的青睐，这提出了一个问题：历史应该，或者说是否可以，在它还冒着热气的时候就被写成？</p>
<p>他（爱德华·H·卡尔）说：“认为历史事实独立于历史学家的阐释而存在，是个荒谬的错误，一个难以根除的错误。”</p>
<p>我由此宣布了我对“荒谬错误”的坚定信仰：历史事实独立于历史学家存在。我想，就算《末日审判书》和那个时代的其他记录都被烧掉，撒克逊人把土地所有权转交给诺曼人的事实也仍然存在于英国历史中。</p>
<p>情况稍有不同的是那种现场的见证者，通常是记者。他们的叙述中往往藏有金矿，而金矿通常掩埋于对日常新闻的报道中，那些每日见闻随时间流逝最终都变成了琐屑。一些《八月炮火》中最为生动的细节就是出自当时的媒体报道。</p>
<h3 id="后世与当世史家"><a href="#后世与当世史家" class="headerlink" title="后世与当世史家"></a>后世与当世史家</h3><p>后世史家最大的优势在于时间提供给他们的距离。远观那些历史事件，他的描述视觉会更为宽阔，他能更多地看见那时发生了什么，区分什么是要紧的，什么又无关大局。</p>
<p>历史同代人，他得之与历史的亲密——这一点我们望尘莫及，却失之超然的视角。</p>
<p><strong>距离也不总是带来客观性</strong>。你很难说吉本的罗马帝国和卡莱尔的法国大革命写得多么客观。客观性是个程度问题。后世史家做到相对客观是可能的，但这和中立、不站队又是不同。<strong>根本就没有中立和纯粹客观的历史学家</strong>。没有了观点，历史学家就变成了一台时钟，也写不出好东西。</p>
<p>我并<strong>不是在说情感在历史写作中没有一席之地</strong>。相反，我认为那是历史的一种核心因素，就像它在诗歌中的作用那样——华兹华斯把诗的起源称为“重归平静的情感”。人们会说，历史是情感和事实的重新整理，或者——对后世历史学家来说——是详查记录之后于平静中的思考。历史学家的首要任务是忠于证据。</p>
<p>诗人所做的是传递他在历史时段或瞬间的感受。历史学家的任务是在事实的规范下讲述到底发生了什么。想象力之于诗人，就像事实之于历史学家。他的取舍中有他的判断，材料安排中有他的艺术。他的工具是叙述。他的对象是人类的过去。他的作用是让事实被人们看到。</p>
<h2 id="计以盎司的历史"><a href="#计以盎司的历史" class="headerlink" title="计以盎司的历史"></a>计以盎司的历史</h2><p>她的叙述之所以出色、生动，令人过目不忘，正是在于她运用了“确凿的细节”。</p>
<p>在汤因比的高度，空气的味道令人兴奋，视野也足够广阔，但人和房屋在脚下都小得看不见了。历史学家不管多么相信他发明的理论，如果它们不能被确凿细节所支持和佐证，那么他们所写历史的价值也就和普巴对行刑的想象一般无二。</p>
<p>所有情况下，卓有成效的办法是首先积累材料，然后把它们整理为叙述的形式，在此过程中看着理论或历史规律自然而然地浮现出来。写历史对我来说是个极为刺激的内心寻宝游戏。这种时刻不是每日必来，有时写一章也等不来一次，但当它到来，它留给我的是愉快的成就感。</p>
<p>我信奉以盎司来计算历史，我不相信用1加仑（约3.7升）水壶端上的历史，其呈现者更急于建立某种历史的意义和目的，而不是事实。那么历史为什么不能如它自己本身——人类活动的记录——那样去学、去写、去读呢？<strong>那已经是最为精彩动人的主题了</strong>。坚持寻找目的把历史学家变成了先知——那又是另一个领域的事了。</p>
<p>确凿的细节不能每次都得出什么结论，但能时时揭示出历史的真实，让你脚踏实地，不违背现实。</p>
<p>普巴说，没有事实的叙述就是“贫乏而难以服人”，此时我也想如此评论。</p>
<p>当我遇见一个没有例子佐证的普遍性结论和结论性的叙述时，我就会突然警觉，并想：“给我证据。” 再比如，他写道，“全体人都有一种好战情绪”，或者，“那是一段非常紧张的时间”，那么，如果他之后没有补充什么证据的话，我就会认为他在毫无节制地做一些无凭无据的叙述。</p>
<p>它们（词语）的自主力非常强大，完全可以在读者脑中造成作者始料未及的印象。显然它们的这一特性对所有题材的写作都适用，但对于敏感的历史写作则尤具杀伤，因为历史需要准确，用词不慎会出现作者本无此意，而读者深会其意的差错。</p>
<p>对我来说这个问题出在我对写作的艺术和历史的艺术同样感兴趣（我希望这么说不会太过激：我认为历史是艺术，不是科学）。在写作中，我一直被文字的音律所诱惑，为文字的发音和意义的互动而着迷。</p>
<p>我该因为它是个好句子而留下它吗？或者因为它不是好的历史而去掉它？历史胜出了，这个比喻将失传了（虽然你看，我正在这里拯救它）。文字是极具诱惑的危险东西，要谨慎使用。我首先是个作家呢，还是历史学家呢？长久以来的争论占据了我。但是并不必要非黑即白。这两种功能没有必要，也不应该有冲突。二者的融合就是目标。<strong>长期来看，最好的作家才是最好的历史学家。</strong></p>
<p>仅仅奉上观点是无血又无肉的。学院派历史就常常满篇都是观点而不见行动，只说他们是怎么写的，不说他们是怎么做的。</p>
<p>如何确定小说中什么样的材料可以被使用，其标准和非小说是一样的：如果这个片段为你提供了时代、地域、环境和人的了解，则可用，反之则否。<strong>如果我是老师，我不会允许学生满足于引用二手文献。要顺着二手文献上溯其源头，发现鲜活的原始材料，在它们中间取舍，而不是满足于重复使用别人的选择</strong>。</p>
<p>执着寻找重要的细节，不带先入之见地看待它们，让它们自己说话，是历史学家工具的一半。另一半——观念、观点、写作理由、“为什么”要写作历史——则未能在本篇中讨论，虽然我眼中并非没有它们，它们一直都在幕后起着作用。第三个一半则是写作艺术。如果这听起来不合算法，那是因为，历史是人的活动，不是算术。</p>
<p>工作的三方面：</p>
<ul>
<li>细节、事实</li>
<li>观念、观点</li>
<li>写作艺术</li>
</ul>
<h3 id="作为艺术家的历史作家"><a href="#作为艺术家的历史作家" class="headerlink" title="作为艺术家的历史作家"></a>作为艺术家的历史作家</h3><p>那么我想谈谈一类特殊的写作者——历史作家。不是作为历史学家的历史作家，而是作为艺术家的历史作家，即一种创造性的写作者，和诗人、小说家同一层次的那种。</p>
<p>理想的历史写作，应该是勉为其难地用文学艺术的手法，把过去的事实中最有情感价值和智识价值的部分呈现给<strong>普通大众</strong>。</p>
<p>我想不通，为什么“艺术”这个词总是局限于虚构作家和诗人，而我们其余的只能面目不清地被叫作“非虚构类（Nonfiction）”——听起来就像剩下的什么东西。</p>
<p>好的虚构作品（与垃圾作品相对）即使和事实不沾边，也常常建立在现实之上，并且能从中感知到真相——往往比一些历史作家更为真实。正是感知真相——把真相从不相干的环境中抽取出，然后传递给书的读者或画作的观者——造就了艺术家。**艺术家具有独到的眼光（extravision）和内省的眼光（innervision），以及表达出它们的能力。**他们提供一种没有他们创造性眼光的帮助，读者就无法得到的观点或理解。</p>
<p>特里维廉写道，<strong>最好的历史作家是能够把事实证据同“最大规模的智力活动、最温暖的人类同理心以及最高级的想象力”相结合的人</strong>。后两个品质同一个伟大小说家需要的别无二致。它们也是历史作家的必备，因为它们能帮助写作者理解他搜集到的证据。想象力用来延伸有效事实。</p>
<p>但是，他又写道：“当此仇恨满胸，良知不存的时候，我把这几页的内容，连同最深的情感，献给从前的那个我。”</p>
<p>在我看来，创造的过程有三步：第一，艺术家以独到的眼光感知真相，传递真相；第二，表达的媒介——作家用语言，画家用画笔，雕塑家用黏土和石料，作曲家用音符；第三，设计和结构。</p>
<p><strong>锤炼语言的目标就是晓畅、有趣，还有审美的享受</strong>。关于第一点，我想引用伟大的历史学家和作家麦考利写给朋友的话：“重要的艺术门类是如何把意思传达透彻的，现在研究得太少了！大众作家中除了我很少有人注意到这个。”</p>
<p>叙述历史不是看上去那么简单和直接。它需要编排、组合和计划，就像作画——拿伦勃朗的《夜巡》为例，他安排进的所有人物，有的位于光照下的前景，有的隐于背景，没有试画、失误和数不清的前期打稿，是不可能完成的。写历史也是一样。虽然成稿看上去一气呵成，毫无滞碍，就像作者照时间顺序写就一样，但其实，并没有那么简单。</p>
<p>排布结构最主要的问题就是取舍，这个是烦人的事，因为材料总是比你需要放进叙述里的更多。问题就是，从发生的事情中，如何选择和选择哪些，又不会因为你的取舍而过于强调、过于轻视一些事实，从而与真实不符。你又不能一口气放进所有材料：结果就是一团糨糊。<strong>你需要沿着叙述的主线，既不从关键事件上游弋得过远，又不遗漏它们，还不能行自己的方便而扭曲材料。这三种情况非常有诱惑性</strong>，但如果你这么对待历史，你一定会被后来的事实绊倒。</p>
<h2 id="历史学家的机遇"><a href="#历史学家的机遇" class="headerlink" title="历史学家的机遇"></a>历史学家的机遇</h2><p>自第二次世界大战爆发，从图书销售数据就能知道，大众越来越偏好传记、自传、科学、社会学、历史——特别是当代史的图书。</p>
<p>人们开始青睐对人和社会有更真实刻画的书，而不再是当代小说。找到小说不再提供真相的原因是历史学家的部分工作。我认为，小说家的失败是20世纪人类的经历造成的——从第一次世界大战开始，人类建立起的幻梦就开始逐渐崩溃。认为历史不断进步的观念是战争的最大牺牲者，它之后变成了犬儒主义，又被第二轮世界大战和纳粹毒气室一次次加固夯实。</p>
<p>他说得有道理。阅读，或说写作，是一个人赋予自己最大的馈赠，这意味着，我们可以借着它的力量在无限的天地中翱翔。我们要虚掷时间去捡拾人性中的垃圾吗？当然，肮脏和没用，卑劣和堕落，都是人性的一部分，如同葡萄酒中的沉淀也是酒的一部分，但酒之琼浆才是有价值的。</p>
<p>历史学家和小说家相比一开始就有个优势，他们的主角作为公共人物，被赋予了操控命运的能力。他们是船长和国王，是圣人和狂徒，是叛国者，是流氓和恶棍，是开创者和探险家，是思想者和创造者，有时甚至是英雄。他们不必可敬，但绝对重要。</p>
<p>现在，当人类的地位更胜以往地臣服于未知，当“疏远（alienation）”成为流行词，公众便想获知一些命运的指导，一些在这个飞速旋转的世界上生存的模式和意义。</p>
<p>历史学家就提供了这样一面单向玻璃，通过它，人们看到各个时代的人类做着那些今天他们同样会做的恶劣、下流和愚蠢的事。</p>
<p>亨利·亚当斯（Henry Adams）的加速法则已被可怕地证明是正确的。无论如何，亚当斯法则是历史学家提供的众多指导中的一种。过去的故事和研究，不论远近，都无法揭示未来，只是在路上洒下些许光亮，不让人过于绝望罢了。</p>
<p>我无意加深专业历史学者和所谓业余历史写手的裂痕，我只想澄清二者的概念。“专业学者”的概念非常清楚：为取得学位而进行研究生训练、在大学中写作历史的人；然而“业余写手（amateur）”指的是在大学之外的、没有研究生学位的人，这就有些用词不当。研究生训练当然会造成某些不同，我无此训练，但深知这点——对此时而遗憾，时而欣喜。但是，<strong>我更愿意把区别设置在学院作者和自由作者之间，或者学者和作家之间，而不是专业作家和业余写手之间，因为问题的关键不是谁更专业（degree of professionalism），而是职业（profession）不同</strong>。大学老师是专业的历史学家，大学门外的我们是专业作家。现在他们借用了我们写作的功能（function），我们借用了他们研究的对象（subject），双方都有很多东西要向对方学习。</p>
<p>然而对于沟通的第一要素，韦布却给出了非常完美的三个标准：作者对“有话要讲”“话值得讲”“自己比别人更会讲”这三点有坚定的信心。</p>
<p>待到开始写作内容，灵感明显是个关键，韦布称为归纳瞬间（moment of synthesis）——归纳综合的念头闪过脑际的那一刻。如果读者能够从摆在他面前的事实中自己发现“一般”，那么这个过程和最后得出的整体观点就是最有说服力的。</p>
<p>尽管有人会反对，但直觉也会有帮助。直觉型的历史学家对长逝已久的历史环境做出超凡的感知，就像亚里士多德的前辈德谟克利特想象出原子一样。他反复研究观察到的现象，最终发展出了物质由数不清的运动分子构成的理论。思维过程是理性的，但其推动力却是直觉的。</p>
<p>历史学家的工具之中，<strong>最让人心驰神往的就是他对主题宏大意义的信念</strong>。</p>
<p>如果真的有“纯粹客观”的历史学家存在，那他的作品一定像锯末一样让人不忍卒读。偏向只有在有所隐瞒的情况下才是误导人的。显而易见可比遮遮掩掩要好得多。</p>
<p>历史学家尽量保持客观，那是因为他希望了解到更多情况，尽量能够以同理心带入和思考各方的动机和处境，这样才能使这场戏的写作更加紧张，也更加可信。但我们千万别假装自己是毫无偏向的，这样一来历史学家就变成了一台录音机，放弃了评判。偏向表示偏好，是评判的结果，是洞察力的源泉。诚然，这其中有感情成分，但这更宣布了你信奉什么。最伟大的历史学家常常激情澎湃地忠于某一事业或他的某个主人公，像蒙森对尤里乌斯·恺撒的赞扬，像米什莱对人民权力的热忱。</p>
<p>作者选择了一个生动的片段来展示更为宏大的整体。这个细节是从时代和文化中的提炼。</p>
<p>我无论如何也不会是第一个这么说的人：提炼就是筛选、再筛选，是写作历史的关键。这是一个重要的编排过程，一个困难的、微妙的、充满了失误和艺术的过程。鉴别什么重要、什么次要是必要的能力。</p>
<p>最为文采飞扬的麦考利写道，写历史就像画画，把所有的素材都放进去只会得到一点点真相（truthful result）。他说，<strong>最佳的画作和最佳的历史是“展示真相的裙角，却能窥见真相的全貌”</strong>。这条法则是这么显而易见，我大惑不解，为什么今天那么多的历史学家都要反其道而行之，去追求无所不包呢？答案可能是胆怯：害怕被批评挂一漏万，或者害怕因为选择不当，而未能抓住要害。这就是独立作家长于专业史家的地方了：他们不怕伸长脖子被人逮个正着。</p>
<p>最后，历史学家不能没有想象力。想象力更应该用到推测人类的行为和环境所造成的动机上面。这就要求<strong>作家有意地作“移情通感（empathy）”之想</strong>，特别是在想要理解、解释历史人物的行为的时候。遇到反感的人物，这就更为必要。</p>
<p>新技术只是研究的方法，而不是表达的方法。</p>
<p>历史写作需要作家，尤需伟大的作家，像特里维廉那样从士兵的信件中发现“诗意”并用之恰当的作家，像帕克曼那样观察和感受，并能用莎士比亚般的文字表达的作家。</p>
<h2 id="写作史迪威将军传记遇到的问题"><a href="#写作史迪威将军传记遇到的问题" class="headerlink" title="写作史迪威将军传记遇到的问题"></a>写作史迪威将军传记遇到的问题</h2><p>这是做军事史研究的常见问题：战役的结果无人不知，然而难点在于重现战斗的过程。</p>
<p>至于为什么没给我的采访录音，我只能说，录音机让我胆怯。或许和我身为女性有关。女人熟稔于以私人的角度切入话题，即使是和陌生人——可能陌生人尤甚。</p>
<p>说了这么多做研究的事，该说说写作了，不仅因为写作更吸引我，还因为普通的外行人往往低估写作，高估研究。人们常对我惊叹：“你一定做了不少了不得的研究工作！”他们假定研究是最难的部分。其实不是。作为创作过程的写作更难，所花时间是研究的两倍。</p>
<p>我用的是叙述的写法，我觉得这样最自然。他第一是历史学家，第二才是作家，而我首先是个作家，写作对象是历史，目的是顺畅表达。我非常在意把读者当成倾听者，他们的注意力必须留在这里，而不是神游天外。我脑中的情景是一个吉卜林笔下的流动说书人。</p>
<p>作为一种文体，用叙述来写历史天生有效，因为它天然就能解释原因。事件不是以类型为界发生的——经济的、思想的、军事的——而是以时间为序发生的。</p>
<p>自古登堡印刷术发明以来，资料来源就开始井喷。19世纪真是个好时代，各种信息应有尽有，也不为今天的信息过剩而发愁。</p>
<p>作过度记录的后果，我要长时间地在写作“尺寸（scale）”上进行挣扎。我就像是个制图人，要根据1英里∶1英寸比例尺的材料，作出100英里∶1英寸的地图。</p>
<p>写出“大尺寸”的历史不能靠轻松地略过史实和大段的时间来达成，而是需要我所知最困难的精炼提纯，还有最为微妙的筛选。筛选是写作的全部，是对历史作家的考验。</p>
<p>我想用一句描述20年代中国军阀的话来总结：“在中国打仗，司令官从不穷着下台。”这在某种程度上或许是对的，但这会留给美国读者一个印象：所有的中国将军都贪污——这只有以美国的标准衡量才是对的。我不是中国通，但我已经足够认识到，以西方的价值框架来写中国是不对的。</p>
<p>再说到我的另一个工作原则：不要当着读者的面和文献材料理论。在叙述文体中，不要呈现作者的想法。你应该在幕后解决自己的疑惑，细究有争议的证据，判断人物的动机，在附录的参考文献中去争论，而不是在正文中。这样才能让作者隐于行文，读者越感觉不到作者存在，越与故事联系得紧密。</p>
<p>为了和时代保持一致，事后聪明也是决计要避免的。</p>
<h2 id="做研究的殿堂"><a href="#做研究的殿堂" class="headerlink" title="做研究的殿堂"></a>做研究的殿堂</h2><p>图书馆是历史学家的食粮，是避风港，甚至是灵感源泉。有两类图书馆：以书、册、期刊等已出版资料为馆藏的，以及搜罗书信、文件等未出版材料的。</p>
<p>徜徉于书架之间，是最开心的研究方式——如果不是最必需的方式的话，也是最能有所发现的方式。</p>
<p>对于所有美国政府地下室的咖啡厅，你唯一有礼貌的评价就是保持沉默。可能图书馆和美食无法兼得，除了在巴黎——这似乎是理所应当。</p>
<p>我经常在写书时刻画一些人物，不仅是因为我想写这个人，更因为它往往呈现了一个时代的特征。我从不当自己是传记作者，我只是一次两次地利用传记去写历史。</p>
<p>每个有创造力的艺术家——我把普鲁塔克算作其中一员，并且大言不惭地把自己也算上——都有两个目标：表达自己的观点，并将之传达给读者、评论者、听众和消费者。（我必须说明，对于写作历史和传记，“创造性”不是如某些人所想的生造，而是对事实做艺术的编排。）</p>
<p>读者与作者之间有着不可分割的联系。如果做爱、打仗和打网球都需要两方的话，写作也需要两方的力量去完善每一个铅字的功能。我从不认为我写的东西在被人读到之前是独立的存在。</p>
<p>我怀疑我们时代的编剧更喜欢去发现小人物的悲剧，劳拉的玻璃动物园，推销员之死，或是在孤独中哭喊小希巴的归来。这个时代的某种东西在拒绝宏大，尽管悲悯和受挫无疑和《特洛伊妇女》的主题一样都是人性中的真实存在。</p>
<p>这只能证明所有作家都知道的一点：一些读者总能在书里找到作者没说的，他自己强加其上的东西。</p>
<p>但从斯特雷奇开始，当然也是从弗洛伊德开始，隐藏的秘密，尤其是黑暗的秘密，就变成了传记作家的标靶、读者的所好。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>塔奇曼的作品以历史为主题，所获的不是普利策历史奖，而是普利策非虚构文学奖。她对自己的定位也是“历史作家”而不是“历史学家”。这这本书的第一篇里，塔奇曼从不同角度讲述了一个好的历史作家所需的“技艺”。</p>
]]></content>
  </entry>
  <entry>
    <title>小狗钱钱</title>
    <url>/2021/03/01/%E5%B0%8F%E7%8B%97%E9%92%B1%E9%92%B1/</url>
    <content><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><blockquote>
<p>富裕是每个人与生俱来的权利，它让我们更有尊严，也能更好地为自己和他人服务。</p>
</blockquote>
<p>PS：富裕也给人以更多<strong>自由</strong>。</p>
<p>个人的经历是无法效仿的，但最基本的真理却完全可以。</p>
<p>那些复杂的投资模型经常将人引入歧途。现代社会里，追求高深莫测的东西似乎才是正道，而那些简单和基本的真理越来越被人淡忘。人们常常认为：“这不可能如此简单”。实际上，这就是“如此简单”。</p>
<p>基本的原理颇为简单，它们自古有之，它们在各种（人类所处的）时空都是有效的。</p>
<h2 id="有益和必要的知识"><a href="#有益和必要的知识" class="headerlink" title="有益和必要的知识"></a>有益和必要的知识</h2><p>阅读金融百科全书，或了解货币史，不能给我们带来富裕和幸福。</p>
<p>描述基本的事实时，有一种危险：人们会过快地做出结论，我已经知道了。这会让人停止学习。</p>
<h2 id="财富法则"><a href="#财富法则" class="headerlink" title="财富法则"></a>财富法则</h2><ol>
<li>一开始，我们必须明确金钱对自己的<strong>意义</strong>。</li>
<li>确立最重要的目标。（长长的 wishlist 中的某几个）</li>
<li>为什么梦想储蓄罐和梦想相册很重要：潜意识的作用，前提条件，专注投入</li>
<li>仅有较高的收入不能解决我们的财务难题</li>
<li>如何使我们不放弃已经作下的决定——想象的艺术</li>
<li>这不总是容易的</li>
<li>成功日记的作用：自信的重要性</li>
<li>如何将自己最大的爱好作为职业，并以此大幅度提高收入</li>
<li>了解重要性和紧迫性的区别：不偏离既定的目标</li>
<li>付诸实施的关键：72小时法则</li>
<li>如何（轻松地）挣到许多钱</li>
<li>减少债务的四个最重要原则</li>
<li>下金蛋的鹅：量入为出</li>
<li>如何正确使用银行</li>
<li>幸福的本质以及我们如何才能获得更多的幸福</li>
<li>爱钱可以吗：保险箱里的现金</li>
<li>钱与幸福的关系</li>
<li>归还我们的一部分所得是重要的</li>
<li>对待恐惧的最佳方式：成功日记</li>
<li>投资俱乐部：确保成功的五条规定</li>
<li>白手起家的魔法</li>
<li><strong>适用于所有投资的三条最重要规定</strong></li>
<li>股票及其收益</li>
<li>走出舒适区，从事我们畏惧的事情</li>
<li>如何获得每年的高利息：最佳投资战略</li>
<li>基金及其利润</li>
<li>复利的力量</li>
<li>波动率：平衡风险与盈利</li>
<li>心算利息与复利</li>
<li>当汇率下跌时如何做？</li>
<li>以基金获利的前提</li>
<li>通货膨胀与选择投资对象</li>
<li>金钱对生活中其它领域的影响</li>
</ol>
<h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><blockquote>
<p>金钱有一些秘密和规律，要想了解这些秘密和规律，前提条件是，你自己必须真地有这个愿望。</p>
</blockquote>
<p>认真看待金钱（注意是手段而非目的），去了解它。拥有金钱是每个人的权利，渴望“有钱”从来不是问题。</p>
<h1 id="第二章-梦想储蓄罐和梦想相册"><a href="#第二章-梦想储蓄罐和梦想相册" class="headerlink" title="第二章 梦想储蓄罐和梦想相册"></a>第二章 梦想储蓄罐和梦想相册</h1><blockquote>
<p>大部分人不清楚自己想要的是什么，他们只知道，自己想要得到更多的东西。<br>太多人做事犹豫不决，因为他们觉得尚未完全弄懂一样东西。而真正付诸实践要比纯粹的思考要聪明多了。<br>钱的数目并不是决定性因素，更重要的是我们如何使用它。我们首先要学会量入为出，如此才有能力获得更多钱。</p>
</blockquote>
<ul>
<li>愿望清单：列出最重要的三个愿望，弄清楚自己最想要的是什么</li>
<li>梦想相册：想象成功后的情景，即视觉化，将愿望变为具体的渴望，然后去寻找实现的机会。而空想只是占据大脑，消耗注意力而已。另外有了渴望，也不会轻易放弃。</li>
</ul>
<h2 id="语录"><a href="#语录" class="headerlink" title="语录"></a>语录</h2><p>如果只是抱着试试看的心态，那么你最后只会以失败告终，也就一事无成。尝试只是一种借口，还没有做，已经在想退路了。</p>
<h1 id="第三章-成功日记"><a href="#第三章-成功日记" class="headerlink" title="第三章 成功日记"></a>第三章 成功日记</h1><p>能否赚到钱，最关键的因素是<strong>自信程度</strong>。如果不自信，就什么都不会有。</p>
<p>成功日记：每天记下五条”成果“，每天不需要10分钟，但时间长了，会有大效果。</p>
<p>两个建议：</p>
<ul>
<li>尝试为别人解决一个难题</li>
<li>把精力集中在你知道的、你会的和你拥有的东西上（而不是只关注自己做不到什么）</li>
</ul>
<h1 id="第四章-做喜欢的事情来赚钱"><a href="#第四章-做喜欢的事情来赚钱" class="headerlink" title="第四章 做喜欢的事情来赚钱"></a>第四章 做喜欢的事情来赚钱</h1><blockquote>
<p>有没有用过一整个下午来考虑如何挣到钱的问题呢？</p>
</blockquote>
<blockquote>
<p>你最好想清楚，你喜欢做什么，然后再考虑怎么用它来赚钱</p>
</blockquote>
<h1 id="第五章-72小时规定"><a href="#第五章-72小时规定" class="headerlink" title="第五章 72小时规定"></a>第五章 72小时规定</h1><blockquote>
<p>许多人爱犯的错误：他们又那么多紧急的事情要做，以至于没有时间去关注重要的事情。</p>
</blockquote>
<blockquote>
<p>当你决定做一件事情时，必须在72小时内完成它，否则可能就再也不会去做它了。</p>
</blockquote>
<h1 id="第六章-解决负债问题"><a href="#第六章-解决负债问题" class="headerlink" title="第六章 解决负债问题"></a>第六章 解决负债问题</h1><p>多数人觉得，工作一定是一件艰苦而令人不快的事情，其实只有做自己喜欢的事情的人，才能真正获得成功。</p>
<p>解决负债问题的四个建议：</p>
<ul>
<li>欠债的人应当毁掉所有的信用卡：使用信用卡花的钱比现金更多</li>
<li>使用分期付款时，每一期还得要尽可能少：如果需要偿付的过多，就不得不进行更多贷款</li>
<li>消费贷款：50&#x2F;50原则，扣除生活费之后富余的钱的一半存起来，另一半还贷。在不必新贷款的情况下，满足生活之需要。另外，所有的消费贷款都是不明智的。</li>
<li>新的借债前问一句：这真地有必要吗？</li>
</ul>
<h1 id="第七章-养一只鹅"><a href="#第七章-养一只鹅" class="headerlink" title="第七章 养一只鹅"></a>第七章 养一只鹅</h1><blockquote>
<p>你为什么不能因为做了一件自己喜欢的事情而挣到钱呢？</p>
</blockquote>
<blockquote>
<p>如果你想变得富有，你还要存钱，这笔钱是绝不会再花的。目标是你能依靠它来生活。</p>
</blockquote>
<blockquote>
<p>鹅代表你的钱，如果你存钱，就会得到利息，利息就是金蛋。</p>
</blockquote>
<blockquote>
<p>养鹅：把收入的10%甚至是50%变成鹅。</p>
</blockquote>
<p>语录：当你定下了大目标时，就意味着你必须付出比别人多得多的努力。</p>
<h1 id="第八章"><a href="#第八章" class="headerlink" title="第八章"></a>第八章</h1><h1 id="第九章"><a href="#第九章" class="headerlink" title="第九章"></a>第九章</h1><p>语录：没有鹅的时候，为赚钱而工作；有鹅的时候，钱为我而工作。</p>
<h1 id="第十章"><a href="#第十章" class="headerlink" title="第十章"></a>第十章</h1><h1 id="第十一章"><a href="#第十一章" class="headerlink" title="第十一章"></a>第十一章</h1><p>一个原则：你干的活最多只占报酬的一半，另一半是因为你的想法和实施这个想法的勇气。</p>
<h1 id="第十二章"><a href="#第十二章" class="headerlink" title="第十二章"></a>第十二章</h1><p>金钱本身既不会诗人幸福也不会带来不幸。金钱像一个放大镜，帮你更充分地展现你本来的样子（所谓自由）。</p>
<h1 id="第十三章"><a href="#第十三章" class="headerlink" title="第十三章"></a>第十三章</h1><ul>
<li>不要停止成功日记</li>
<li>不能再困难面前逃跑。对困难、犯错误和丢面子的恐惧已经破坏了无数人的生活</li>
<li>对失败的可能性想得越多，就越会害怕</li>
</ul>
<h1 id="第十四章-如何投资"><a href="#第十四章-如何投资" class="headerlink" title="第十四章 如何投资"></a>第十四章 如何投资</h1><p>金钱咒语：</p>
<ul>
<li>确定自己喜欢获得财务上的成功</li>
<li>自信、有想法、做自己喜欢的事情</li>
<li>把钱分为日常开销、梦想目标和金鹅账户三部分</li>
<li>进行明智的投资</li>
<li>享受生活</li>
</ul>
<p>投资建议</p>
<ul>
<li>投资在安全的地方</li>
<li>钱应该下很多金蛋</li>
<li>投资应该简单明白</li>
</ul>
<p>如何估值</p>
<blockquote>
<p>决定一件东西价值多少的唯一因素是你愿意为它支付多少钱</p>
</blockquote>
<h1 id="第十五章"><a href="#第十五章" class="headerlink" title="第十五章"></a>第十五章</h1><p>顶住压力，做了一件事情后，会知道：原来自己能做到什么。一个人最引以为豪的事情，往往是那些做起来最艰难的事情。</p>
<h1 id="第十六章"><a href="#第十六章" class="headerlink" title="第十六章"></a>第十六章</h1><h2 id="挑选基金"><a href="#挑选基金" class="headerlink" title="挑选基金"></a>挑选基金</h2><ul>
<li>应有十年以上历史</li>
<li>选择大型跨国股票基金</li>
<li>对基金的走势图进行比较</li>
</ul>
<p>多买几种基金，分散风险。</p>
<h2 id="72-定理"><a href="#72-定理" class="headerlink" title="72 定理"></a>72 定理</h2><p>根据年利率估算翻倍时间。</p>
<h1 id="第十七章"><a href="#第十七章" class="headerlink" title="第十七章"></a>第十七章</h1><blockquote>
<p>把钱投在一个基金上，5到10年不去看它。</p>
</blockquote>
<h1 id="第十八章"><a href="#第十八章" class="headerlink" title="第十八章"></a>第十八章</h1><blockquote>
<p>在他眼里，钱是一种再自然、再普通不过的东西了。</p>
</blockquote>
<blockquote>
<p>不要为失去的东西而忧伤，而要对拥有它的时光心存感激。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>控制力幻象</title>
    <url>/2017/10/04/%E6%8E%A7%E5%88%B6%E5%8A%9B%E5%B9%BB%E8%B1%A1/</url>
    <content><![CDATA[<p>初听，“普通话”令人震惊。</p>
<h1 id="1、导语：跟你的焦虑和解"><a href="#1、导语：跟你的焦虑和解" class="headerlink" title="1、导语：跟你的焦虑和解"></a>1、导语：跟你的焦虑和解</h1><p>焦虑，带着我们过去生活的匮乏，也带着对未来的担心和希望。焦虑的本质就是一种失控感。担心某些东西不在掌控范围内。担心上帝或命运不会善待我们，以至于忘了我们本能够掌控一些东西。</p>
<p>即使在二战集中营这样的环境，我们依然能作出选择。那么理论上，我们的生活中也可以做出不同的选择。</p>
<p>焦虑源于失控感，而失控感源于我们总是试图去控制那些我们控制不了的东西，却不愿对可控者承担起自己的责任。</p>
<p>控制力幻象：我们可以控制很多东西。认清现实后，又不甘心只能控制这么一点，看不到这一点的丰富。</p>
<p>不同的心理咨询的流派都在帮助我们重新建立控制感。</p>
<p>生活是一个修行的道场。</p>
<h1 id="2、乐观的人反而会更焦虑？寻求控制感"><a href="#2、乐观的人反而会更焦虑？寻求控制感" class="headerlink" title="2、乐观的人反而会更焦虑？寻求控制感"></a>2、乐观的人反而会更焦虑？寻求控制感</h1><p>我们有烦恼，是因为我们总妄想去控制那些我们控制不了的东西，却不愿对我们能够控制的东西担负起责任。</p>
<p>控制是人的基本需要。从婴儿时期，人就想控制这个世界了。</p>
<p>控制感是<strong>安全感</strong>的来源。从某种程度上说，人的心智成熟，就是从认为很多事我能控制到发现很多事我不能控制。</p>
<p>精神分析-全能自恋：婴儿觉得自己是无所不能的。喂奶；哭，安抚。逐渐发现，这世界不是围绕着我转的。</p>
<p>夸大我们控制世界的能力。控制别人的评价；如果我当时做对了，某事就如何如何。</p>
<p>天生的乐观派：我做得好，应当得到好评；每个人都应当有美满的原生家庭；愧疚于拖延，则认为本能够长时间保持投入与专注。真相是，这个世界本来就是不完美的。</p>
<p>当现实与想象不符时，我们就会焦虑、沮丧或愤怒。从乐观到悲观。从而不愿去控制那些我们能控制的东西，因为它看起来太微不足道。</p>
<p>逃避责任：比如请出拖延症这个”对象“，你看，因为拖延症我才这样的。事实上，可控者远比我们想象地多，把握和享受这些使我们安全感的来源。它需要换一个看待问题的角度。</p>
<p>当我们说，道理我都懂的时候，就是还没懂的时候。将其置于一个遥远的与己无关的位置，而不愿去践行这个道理。但这是我们可以控制的。</p>
<p>问自己两个问题：</p>
<p>这是我能控制的吗？如果不是，那我能控制什么？</p>
<p>行为模式四个层次：生理、感受、思维和行动。生理反应和情绪感受很难直接控制。思维方式和行动较易进行。</p>
<p>焦虑时很难直接停下，但可以有行动：公园散步，见朋友。如此以思维和行动反过来影响了生理与感受。</p>
<p>上帝，请赐予我勇气，让我改变能够改变的事情；请赐予我胸怀，让我接受不能改变的事情；请赐予我智慧，让我分辨这两者。</p>
<p>尽人事，听天命。</p>
<p>以为可控者之背后，有我们不可控的东西，承认之让人痛苦，但也让我们解脱；以为不可控者之背后，也有我们可控者。这种智慧是帮我们走出焦虑的良方。这种智慧是什么？</p>
<h1 id="3、如何拒绝别人不合理的请求？课题分离法"><a href="#3、如何拒绝别人不合理的请求？课题分离法" class="headerlink" title="3、如何拒绝别人不合理的请求？课题分离法"></a>3、如何拒绝别人不合理的请求？课题分离法</h1><p>关系是影响个体幸福感的最重要因素。</p>
<p>个体心理学家阿德勒：人际关系的烦恼是一切烦恼的根源。人际关系中，什么是可控的，什么是不可控的？</p>
<p>老好人：担心别人恶评；担心他人找不到其它帮忙者。事实上，他人评价不可控，不可剥夺，而且自己行事准则亦不能因他人而定。另一方面，夸大了自己的作用。最极端者，你也不能拯救一个人。</p>
<p>拒绝为何很难？混淆了可控与不可控两者。控制他人之评价；施加自己之影响。（看起来，不是他人需要自己，倒像是自己需要帮助别人，你知道，这会很感人）</p>
<p>各人皆有界，只须做力所能及欲及之事。如果多次欲拒绝而不得，盖其为超出自己界限之信号。</p>
<p>阿德勒：课题分离。区分什么是你的事情，什么是我的事情。我负责把我的事情做好，你也需要如此。</p>
<p>这是谁的事情？判断标准是，谁为结果负责。例：母催女结婚。则女儿反感，又担心不结婚导致母亲不高兴。分离之，则女儿只婚事有其自己承担，母亲不能插手；母亲之高兴由其自己负责，与女儿是否结婚无关，女儿亦无需负责。</p>
<p>拒绝困难：把别人的问题当成了自己的问题。</p>
<p>另一问题，是否显得冷漠？如父亲对儿子之关心。则问题是，如果</p>
<p>爱是，你可以对一个人好或不好时，选择了好，心甘情愿的。课题分离的目的不是分离，而是从人际关系的困扰中解脱出来，回归我们的本心。所谓本心，即自愿地做事。去助人，不是担心评价，或希望感激，而是同情与爱耳。</p>
<p>担心被拒绝：不仅是此行为，亦有背后关系之含义。他是否认为不重要，不在意我？表达需求很难，也是因为背后被评价的恐惧。我们不能控制别人满足自己要求，但我们能控制自己表达需要之需要。</p>
<p>彼得·德鲁克：不为任何人做事，为上帝做事。</p>
<h1 id="4、亲密关系中为什么总想控制对方？排序思维"><a href="#4、亲密关系中为什么总想控制对方？排序思维" class="headerlink" title="4、亲密关系中为什么总想控制对方？排序思维"></a>4、亲密关系中为什么总想控制对方？排序思维</h1><p>亲密关系中，何者不可控，何者可控？</p>
<p>亲密关系的基本动力有两种：权力和爱，相对于思维模式：排序思维和联结思维。</p>
<p>排序思维：把人排出高低贵贱。</p>
<p>控制的企图会极大地伤害两人的关系。愈亲密，愈期待，愈想控制。控制引发斗争，使身处关系中的人痛苦不堪。吃饭、看电影之类的小事儿，所争论者，谁听谁的。这次听了他的，是不是他不尊重我？我是否输了？输赢即典型的排序思维。此种思维者，担心关系中的不平等，害怕被拒绝。<strong>控制代替了亲密，权力代替了爱</strong>。我们以为，控制了别人，爱就会回来。我们可以要求别人做很多事情，却不能控制别人爱。</p>
<p>都是对方的错。尝试改变对方。自己可以做什么改善关系？争论对错，也是排序思维。控制别人，就是控制不可控之事。对方先改，仍然在争高下。放到自己身上，这是自己唯一能控制的事。</p>
<p>放弃控制，才能给对方自主的选择，才能给爱留下空间。</p>
<p>退一步，放弃对对方的控制。把自己的需要和对方的需要分开。</p>
<h1 id="5、自己制定的计划，为什么总是拖延？张力和控制感"><a href="#5、自己制定的计划，为什么总是拖延？张力和控制感" class="headerlink" title="5、自己制定的计划，为什么总是拖延？张力和控制感"></a>5、自己制定的计划，为什么总是拖延？张力和控制感</h1><p>想好好利用时间，制定了<strong>很多目标</strong>。锻炼身体；学英语；读不同领域的书。刷手机、打游戏。何如？</p>
<p>为什么定很多目标？不能定少数几个？</p>
<p>这几个都很重要？看到焦灼的目光，急切地想要改变什么。此时就想要制定各种目标和计划，但这样的计划不是用来实现的，而是用来<strong>缓解焦虑</strong>的，它通过幻想提供一种<strong>虚假的希望</strong>。这样的计划愈是宏大，就愈有“功效”，万一实现了呢？成功学的秘密大概也在于此，他们先是提供焦虑，再献上良方。</p>
<p>那么，这些焦虑的来源是什么？它们是否是恰当的？（焦虑也有恰当一说？）幻想本身无可厚非，但幻想却能减弱行动的力量。制定了很多计划，买了很多书，行动力可能会降下来，因为焦虑已经通过上述行为释放掉了（我毕竟已经做了很多努力了），且有了我已经进步了的<strong>错觉</strong>。</p>
<h2 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h2><p>目标与计划本质不同。目标的本质是张力，如同一张弓。此张力是一种心理上的未完成状态，而且达到目标之前，不会随着行动而消失。</p>
<p>格式塔疗法：未完成事件一直在我们的世界里隐隐作痛，希望去完成它。坏的目标，张力不可持续，做一点，张力少一点。</p>
<p>例：写一本对自己很有意义的书，假设有10章，那么写完第9章，也不会失去动力。如果是坚持写作，那么完成一点，目标的动力就消失一点。</p>
<p>制定一个创造型的目标，如写一本书、完成一幅画、作一首曲子，会比坚持型的目标，如坚持读书、健身更容易。因为创造型的目标，我们心里有一个未完成状态，会保持张力。所以，尝试去<strong>制定一个创造型的目标</strong>。</p>
<p>那么，好的目标是否一定能够完成？不一定，因为是否完成取决于很多因素，如所处时代（互联网的兴起对传统行业的冲击）、运气等等。故有时且需要根据形势调整目标。如果目标是否实现不是我能控制的，那我还能做什么？这就是目标之外的<strong>计划</strong>。</p>
<h2 id="计划"><a href="#计划" class="headerlink" title="计划"></a>计划</h2><p>目标的本质是制造张力，计划的本质是<strong>控制</strong>。做事时的<strong>不可控和不确定的感觉</strong>很折磨人，它容易使人焦虑和拖延。这时需要计划。仔细想想，每个不可控的事情背后，也有其可控的部分。即使努力准备考试，也不确定是否能通过，但去努力却能提高通过的几率。不知道何时有研究灵感，但多读文献，多讨论就更可能产生灵感。</p>
<p>所以，找出可控的部分，做成计划，这就是我们该做的事儿。计划的本质是控制，不是提供虚幻的希望，把注意力放在能做的事情上，让你谦虚、节制、理性。</p>
<p>如果一个计划让你好高骛远，当下却不知道该做什么，只想着做不到的事情，那就不是一个好的计划。好的计划让你沉下心来，脚踏实地。结果不是我们能控制的，却可以说，我已经尽力了。</p>
<h1 id="6、为什么你的人生规划会给你这么大的压力？创造福流"><a href="#6、为什么你的人生规划会给你这么大的压力？创造福流" class="headerlink" title="6、为什么你的人生规划会给你这么大的压力？创造福流"></a>6、为什么你的人生规划会给你这么大的压力？创造福流</h1><p>多隆——阿里的神人 </p>
<p>“就是解决问题嘛”。</p>
<p>状态：不去想我不能控制的事情，只关注我能控制的事情。</p>
<p>基本信条：远大的理想，不能泯与众人。</p>
<p>如果做不好眼前的事情，远大的理想就会成为沉重的负担。</p>
<p>高远的理想下，生活成为一架运行的机器。</p>
<p>只有大纲，没有内容——很乏味。</p>
<p>不希望过程，只希望结果——快快来到。但结果很难控制，恰恰过程才是能控制的，放弃了过程，也就放弃了结果。</p>
<p>没有人能保证生活会如何如何。所以，去做自己能做的事情吧。将自己交付给命运。不是说，只要我努力，上天就一定会给我回报，而是，即使上天不给我回报，我也要去努力投入。</p>
<p>投入不能保证成功，却能带来幸福。漂移不定，比专注投入时更不幸福。Flow，忘我，忘时，沉浸于某事——幸福感的真正来源。条件：需要放下事情以外的<strong>目标的执念</strong>，做好能做的事情，忘我。忘我——到达自我。不要以成功为目标，成功是自己全心投入，置之度外时意外获得的副产品。</p>
<p>投入眼前的事情，把它当做人生规划的手段。</p>
<p>更大的世界：福流可能是向内求得的。</p>
<h1 id="7、目的论和因果论"><a href="#7、目的论和因果论" class="headerlink" title="7、目的论和因果论"></a>7、目的论和因果论</h1><p>找出能够控制的事情，不仅需要常识，还需要换一个角度来看待行为。</p>
<p>焦虑可以“有用”：实现了某种目的。不想面对找工作的挑战，“选择”了焦虑，焦虑给了他一个好的理由为自己开脱，在这种意义上是“有用”的。</p>
<p>虽然有用，缓解了心中的痛苦，但我们也交出了手中的控制权，因为现在找不找工作是由焦虑来控制的了。如果我们说自己“选择”了焦虑，那么是说自己“不想找工作”，焦虑是主动选择的结果，是否出门找工作是由自己来决定的。如此一来，就夺回了控制权，代价是我们得为自己负责了。</p>
<p>因果论：所有发生的事情都有背后的事情，如原生家庭。因果论往往导向过去决定论，而过去是我们没法控制的。</p>
<p>阿德勒的说法目的论：强调行为背后的目的。为了种种目的，我们才有了特定的行为。回避挑战-&gt;制造焦虑。心理问题不是问题-&gt;而是为了满足某个目的而想出来的一种解决方案。</p>
<p>抑郁通过缩小活动空间保护自己；焦虑通过情绪唤醒提醒你有危险接近；自卑通过一系列的退缩行为避免在激烈的竞争中受伤，自卑的痛苦主要来自己不如人，避免了竞争，就避免了不如人情境的发生，同时亦可获得关注与安慰。</p>
<p>初级和次级收益：社会认可的直接收益；情感上的。</p>
<p>阿德勒论故意捣蛋的儿童：获得称赞的需要（人群中的优越感，优越感带来安全感？）；若无称赞，则要表现得与众不同，包括做坏事，以引起关注；若否，开始权力斗争阶段，开始不服任何人；复仇，故意捣乱和破坏；证明自己的无能，回避自己人生发展的课题；作为受害人，谴责他人。</p>
<p>自省：问题行为获得了哪些好处，这些好处反映了自己内心的哪些需求？如果没有这些问题行为，我们还能用哪些方式来满足这些需求？也许这些行为背后也有自己能控制的东西。</p>
<h1 id="8、怎样跟自己的焦虑感对话？"><a href="#8、怎样跟自己的焦虑感对话？" class="headerlink" title="8、怎样跟自己的焦虑感对话？"></a>8、怎样跟自己的焦虑感对话？</h1><p>情绪低落，不想出去活动；生活毫无意义。</p>
<p>抑郁症：标签；确认了，至少有什么是确定了。贴到身上，当作自己的一部分，没法把问题与自我分离。</p>
<p>欲重获控制感，换个角度。</p>
<p>心理咨询技术，来自<strong>叙事疗法</strong>。</p>
<p>黄金棍的故事：控制不住自己-&gt;是自己的问题；棍-&gt;问题是外部的。</p>
<p>外化，分离自己与问题，增加我们的主动性与控制感。找到一个动物、植物或物品，形容问题，找到合适的比喻，这样同时也界定了自己与问题的关系。不要使用斗争关系，易使人紧张，选择轻松温情的。如“黑狗”、“小孩”。</p>
<p>具象：它如何影响我的生活，如何相处，如何找回控制权。</p>
<p>焦虑：小孩；理智：成年人。你听谁的话呢？听听你的问题，它在跟你说什么，你该怎么做呢？</p>
<p>大部分心理咨询的本质就是找回控制感。外化是方法之一。</p>
<h1 id="9、为什么说犯错反而能缓解焦虑？悖论法"><a href="#9、为什么说犯错反而能缓解焦虑？悖论法" class="headerlink" title="9、为什么说犯错反而能缓解焦虑？悖论法"></a>9、为什么说犯错反而能缓解焦虑？悖论法</h1><p>放弃不可控者：顺其自然；为可控者担责：专注精进。</p>
<p>陷入焦虑和恐惧时，很难什么也不做。</p>
<p>标签收集器：什么症状总能找到适合自己者。</p>
<p>有时候，很想控制和改变自己的状态，但这种控制和改变本身也会成为问题。欲睡而不能；欲摆脱焦虑而更为焦虑。但放弃改变之心很难，身处问题，急于改变。</p>
<p>接纳自己：平静之情绪。接纳本身也会成为悖论：要不要接纳那个不接纳自己的自己呢？接纳自己的本质是舍弃，不是追求和获得。舍弃不可控者；舍弃“完美的自己”；舍弃“完美世界的执念”；接纳自己，不是因为它有什么好处，而是缺陷、不完美就是我们生存的事实，如果希望内心平静满足，通常不能成功。</p>
<p>内心平静满足不是目标，而是接纳自己的副产品。</p>
<p>放弃无效的控制，去接近内心的焦虑，是一个巨大的冒险。故悖论中人难以走出悖论。</p>
<p>但悖论也是悖论，不仅是问题，亦可成为方案。治疗自己。</p>
<p>正是恐惧导致了我们害怕的事物出现；过度渴望使我们希望的事情变得不可能。矛盾意向法：越是害怕，就越是在意向中让它发生。比如害怕演讲。制造特别的情境。无论做什么，都能获得控制感，重点是要去做。</p>
<p>犯错说明你在工作，而且可资学习。犯错计划：每周3次。不去过于担心无需担心之事。</p>
<h1 id="10、带着症状去生活：森田疗法"><a href="#10、带着症状去生活：森田疗法" class="headerlink" title="10、带着症状去生活：森田疗法"></a>10、带着症状去生活：森田疗法</h1><p>森田疗法：带着症状生活，为所当为。</p>
<p>手抖：承载着自己的不安和自我怀疑，有其历史，现在表现为手抖。以为心理问题是能够控制的，出现时本能地希望治愈修正它。生活倒映在水里的影子。</p>
<p>身体生病：能够定位；心理问题不能：不是控制心理问题能解决的；无法通过影子来修正原来的问题。</p>
<p>停下生活去治疗它，但治疗的力量却来自于生活本身。</p>
<p>不是艰难的情况下去控制焦虑，而是在偶尔焦虑的情况下去过艰难的生活，让它运转良好。疾病之外的部分是唯一能控制的事情，这就是为所当为。</p>
<p>一方面夸大之；一方面轻视之。</p>
<p>弃疗，去生活。问题以外的生活。生活滚滚向前，以为很重要的事情，变得不那么重要了。</p>
<p>荣格：人生中所有最严重、最重要的事情，基本上都是无解的。问题无法被解决，只会被更大的问题掩盖掉。视野变得更大更宽了，问题也失去了它的紧迫性。</p>
<h1 id="11、为什么说要专注于当下？正念思维"><a href="#11、为什么说要专注于当下？正念思维" class="headerlink" title="11、为什么说要专注于当下？正念思维"></a>11、为什么说要专注于当下？正念思维</h1><p>妄图控制不可控，却不对可控者行使控制权。这里隐含着两种思维模式：</p>
<ul>
<li>远的思维：没有发生之事、抽象的和远的事情；</li>
<li>近的思维：真实的、正在发生的、近的事情</li>
</ul>
<p>远之三特征：</p>
<ul>
<li>过度概括化：不舒服，可理解；但说我总是不受欢迎，就走得太远了；这<strong>一切</strong>有什么用呢？（一切、总是、根本）。此时，无事可控制。</li>
</ul>
<p>你问的问题是否太过抽象？我有拖延症怎么办？我总是很紧张怎么办？此类提问反映了其思维模式。</p>
<p>-&gt; 遇到哪些人&#x2F;哪些场合紧张？什么时候不紧张？用近的语言，亦即近的思维模式去思考<strong>真实的</strong>问题。说因为内向故而紧张，过于概括，过远，远离了真实问题。</p>
<ul>
<li><p>想象代替看见，脑补代替现实：以为了解了现实，实际上没有。不要去看没有发生的事情。</p>
</li>
<li><p>以有用、无用的判断和评价代替行动：根据可能的结果来判断是否去做，但很多时候做了才知道是否有用。结果不可控，但做不做可以。</p>
</li>
</ul>
<p>我们现在能做什么？你愿不愿意去做？不愿做是现在，为何不愿在远方。</p>
<p>远的思维：让我们远离真实的生活，失去对生活的控制感。</p>
<p>正念：原为佛教术语，现在心理学界亦流行。关注此时此刻，关注当下。是一种近的思维方式。只有近的东西是你能控制和把握的，也只有近的东西才是你存在的现实。</p>
<h1 id="12、怎样跟自己的过去告别？心理重生"><a href="#12、怎样跟自己的过去告别？心理重生" class="headerlink" title="12、怎样跟自己的过去告别？心理重生"></a>12、怎样跟自己的过去告别？心理重生</h1><p>如何面对生活的变动，面对生活中的结束和开始。</p>
<p>上一次重要的生活转变发生在什么时候？</p>
<p>转变：社会意义上，有积极者，也有消极者。所有转变都伴有压力，因内心需要调整。回顾起来，顺理成章，这是记忆之作品耳。手足无措，焦虑。转变的过程，伴有大量的失控（此为很多人不愿改变之原因？）。</p>
<p>何者可控？何者不可控？</p>
<ul>
<li><p>不可控：迷茫与混乱，失恋；</p>
</li>
<li><p>可控：知道自己会经历什么，勇敢走出，迎接新生活。</p>
</li>
</ul>
<p>威廉·布里奇斯《转变》，转变三阶段：结束、迷茫、重生。转变自结束始。</p>
<p>如何开始新生活？试图直接跨过前两阶段。无法转变入下一阶段，可能是因为在结束处卡主了。</p>
<p>案例：失恋三年，依旧关注ex之微博，尽管早已没有自己之痕迹。曰：我难过，故感情仍在。若我好了，那感情就真地结束了。此一执念，或许对当事人仍有意义，但旁观者会发现，感情“事实上”已经结束了，不管你是否接受。（如《海边的曼彻斯特》）。你所需要的是生活在对上一段感情或ex的留恋中？还是希望幸福？那么幸福是来自于留恋还是更真实的感情呢？</p>
<p>停留在过去，有何好处？内心留有一些虚幻的希望，以此对抗孤独。承认结束，就承认永远失去了一个人（但你从不曾拥有一个人，对吗）。结束总是包含了失去。这种失去也包含一部分<strong>旧的自我</strong>。</p>
<p>这就又回到了：妄图控制不可控者。</p>
<p>但结束了，不会立即进入重生，还有第二个阶段：<strong>迷茫</strong>。伴随着抑郁、自我否定，空虚、无聊。为了摆脱空虚和无聊，会急着开始。</p>
<p>迷茫之要义：不是振作和重新开始，而是放弃抵抗，同时保持对未来的好奇，与自己相处。事情为何发生？转变意味着什么？迷茫期：等待新自我的萌芽。</p>
<p>第三阶段：<strong>重生</strong>。已能够把转变整合到自己的人生经历里。从自我中长出了新的东西。</p>
<h1 id="13、你是不是也在摸索生命的意义？接受无常。"><a href="#13、你是不是也在摸索生命的意义？接受无常。" class="headerlink" title="13、你是不是也在摸索生命的意义？接受无常。"></a>13、你是不是也在摸索生命的意义？接受无常。</h1><p>生命及人类之产生纯属偶然，人终将死去，甚至地球也会消失，那么人所做的一切有何意义？</p>
<p>一个东西，无论是花还是人，它的存在本身都是有其意义的，不需要用有用来证明，也不需要用时间上的延续来证明。把任何东西当成达到目的的一种手段，都是对它本身的贬低。</p>
<p><strong>可控&#x2F;不可控</strong>视角，也许能减轻焦虑，或达到幸福，但并不是因为这个而采用，而是因为它本身就是对的。</p>
<p><strong>随缘</strong>：你遇到什么，就享受什么，但不要留恋。</p>
<p>佛祖说：”阿难陀，你看，这灵鹫山多美！“</p>
<p>纵使落日稍纵即逝，也无法消减它那刻的美。</p>
<h1 id="道理，终究是远的，切记。"><a href="#道理，终究是远的，切记。" class="headerlink" title="道理，终究是远的，切记。"></a>道理，终究是远的，切记。</h1>]]></content>
      <tags>
        <tag>心理学</tag>
      </tags>
  </entry>
  <entry>
    <title>大龄男青年相亲故事一则</title>
    <url>/2020/07/04/%E5%A4%A7%E9%BE%84%E7%94%B7%E9%9D%92%E5%B9%B4%E7%9B%B8%E4%BA%B2%E6%95%85%E4%BA%8B%E4%B8%80%E5%88%99/</url>
    <content><![CDATA[<p>村中有一个大龄单身男青年，相亲屡次失败，一家人为此都很是拿急。说起来，失败的原因不是因为太穷，或者太矮、太土，只是因为他的嘴实在有些大。</p>
<p>一天，村里一位大姐来家里耍，聊起了相亲的事儿，便问：“你和那些闺女一般都拉些什么？”他说，就是家常啊，不知道为什么就是不行。一次典型的聊天可能是这样的：</p>
<blockquote>
<p>女：你属什么？<br>男：属马。<br>女：你喜欢吃什么？<br>男：吃瓜（地瓜）。<br>女：那你喜欢看什么？<br>男：看花。</p>
</blockquote>
<p>大姐听了，沉吟了一会儿说：“这样，以后你就这么说：我属虎、喜欢吃红薯、喜欢看竹。”</p>
<p>很快，下一次相亲机会来了，在女方家里。男青年按大姐的指点一一作答，没有什么破绽，大家都挺满意的。女方留男青年在家吃午饭，吃饺子。不巧的是，家里醋没了，吃饺子可不能没有醋啊，男青年主动提出去打醋。</p>
<p>过了一会儿，男青年端着一碗醋回来了，奇怪的是只有小半碗儿。那个闺女问起原因，男青年说：“本来是打了满满的一碗，都洒咯。”</p>
]]></content>
      <categories>
        <category>故事</category>
      </categories>
      <tags>
        <tag>故事</tag>
      </tags>
  </entry>
  <entry>
    <title>女性主义</title>
    <url>/2021/06/06/%E5%A5%B3%E6%80%A7%E4%B8%BB%E4%B9%89/</url>
    <content><![CDATA[<h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><p>一种朴素的对“公平性”的辩护，认为男性、女性不应该被区别对待，这一点与性别无关。</p>
<p>feminism：女权主义与女性主义，“权”颇为敏感，有争权夺利之感，是来自“既得利益者”的视角。权主要表示权利，而非权力。</p>
<p>污名化：为何不愿自称为女权主义者。</p>
<h1 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h1><ul>
<li>同与异</li>
<li>公私两个领域</li>
<li>家庭劳动——非价值化</li>
<li>个人生命体验与普遍境况的差异；个人自由选择；</li>
<li>男女的悲欢不可能相通；</li>
<li>男性凝视</li>
<li>男性油腻</li>
</ul>
<h1 id="女性主义理论"><a href="#女性主义理论" class="headerlink" title="女性主义理论"></a>女性主义理论</h1><h2 id="女性主义理论-1"><a href="#女性主义理论-1" class="headerlink" title="女性主义理论"></a>女性主义理论</h2><p>两类：宏观理论和微观理论。</p>
<p>奠基性作品七部：</p>
<p>女性主义重要观点：<strong>女性的地位是衡量一个民族文明程度的最好尺度</strong>。</p>
<p>为什么要追求平等？</p>
<ul>
<li>抑制人的潜能</li>
<li>不喜欢不平等</li>
</ul>
<p>社会物质条件和生产关系的改变使得新的状态出现：<strong>性别错位</strong>，即文化的滞后性。</p>
<h2 id="男权制的定义"><a href="#男权制的定义" class="headerlink" title="男权制的定义"></a>男权制的定义</h2><p>女性主义的共同观点：男权制既不是自然的，也不是永恒的，有人为构建的成分，而且是可以改变的。</p>
<p><strong>男权制的核心：对男性特权和权力的维护和将其合理化</strong>。</p>
<p>男权制包含内容：</p>
<ul>
<li>男性统治：想知道她是否能够像男性那样做个好总统？（）</li>
<li>男性认同：男性气质与社会核心价值观接近</li>
<li>将女性客体化：凝视，置于次等，贬低</li>
<li>男权制的思维模式：两分思维；线性思维；等级思维</li>
</ul>
<p>性别歧视由来已久，那些大思想家更是重灾区。</p>
<p>存在主义：反对抽象、理性，强调具体的活的经验，包括身体和情感经验。</p>
<p>陷阱：保护家庭、保护女性、赚钱养家</p>
<h2 id="同与异"><a href="#同与异" class="headerlink" title="同与异"></a>同与异</h2><p>女性主义思想史上，<strong>差异是一个最充满争议也是最重要的概念</strong>。争取平等与保持差异。</p>
<ul>
<li>男权制：男尊女卑，将差异本质化 - 本来如此；</li>
<li>男女相同：社会主义女性主义</li>
<li>男女相异：自由主义女性主义</li>
<li>男女相异：女尊男卑，激进女性主义</li>
<li>男女混合：性别界限不清，难分高低，后现代女性主义</li>
</ul>
<p>差异：不要轻易分出高下。</p>
<p>生理决定论和本质主义：一些人就是比另一些人高级，此定义有权力优势一方来下（不只是性别维度）。</p>
<h1 id="女性主义流派"><a href="#女性主义流派" class="headerlink" title="女性主义流派"></a>女性主义流派</h1><p>三大家+后现代</p>
<p>在争取男女平等上有基本共识，但对性别主义的起源解释不同，如何消除的方法也不同；</p>
<h2 id="自由主义"><a href="#自由主义" class="headerlink" title="自由主义"></a>自由主义</h2><p>理性、公正、机会均等和选择自由。总体上较温和。</p>
<p>早期：受教育权、选举权、私有财产权；同工同酬；</p>
<p>波伏娃：要工作；有知识；争取社会变革；</p>
<p>批评：仍旧以男性规范为标准，忽略了女性品质特有之价值，未解答公领域和私领域两分的问题。</p>
<h2 id="激进主义"><a href="#激进主义" class="headerlink" title="激进主义"></a>激进主义</h2><p>个人问题就是政治问题。追问：为什么女性在所有社会都是从属地位？女性作为一个阶级，普遍屈从；关注性和身体的领域；</p>
<p><strong>个人问题就是政治问题（The personal is political）</strong>：女性现在所面临的个人困局，比如性别歧视、母职惩罚、无偿再生产劳动，都有社会和政治原因，需要政治干预才能产生变化。</p>
<ul>
<li>消除孤独感</li>
<li>责任免除</li>
</ul>
<p>米丽特将男权制（父权制）引入女性主义理论。</p>
<h2 id="社会主义"><a href="#社会主义" class="headerlink" title="社会主义"></a>社会主义</h2><p>恩格斯《家庭、私有制和国家的起源》：私有财产制度这一经济秩序导致女性受压迫。</p>
<p>与自由主义不同，社会主义站在“平等”一边，而非“公正”。</p>
<p>四种结构——生产、生殖、性、儿童教化——在家庭中结合在一起，相互依存，是女性受压迫的物质基础。</p>
<p>本斯通： 家务劳动是女性处于从属地位的根源。</p>
<p>公私两领域是不可分割的。</p>
<p>关注问题：女性参加社会劳动的问题；家内劳动不被当作工作的问题；劳动报酬普遍低于男性的问题。</p>
<h2 id="后现代"><a href="#后现代" class="headerlink" title="后现代"></a>后现代</h2><p>极关注后现代思想大家，如<strong>福柯</strong>。</p>
<ul>
<li>挑战关于解放和理性的宏大叙事，局部的小型理论才是有效的</li>
<li>从根本上反对传统知识结构中的两分主义（dualism），提倡多元模式</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>《数学分析八讲》笔记</title>
    <url>/2017/10/05/%E6%95%B0%E5%AD%A6%E5%88%86%E6%9E%90%E5%85%AB%E8%AE%B2/</url>
    <content><![CDATA[<p><a href="https://book.douban.com/subject/4825571/">数学分析八讲 原书链接</a>，作者辛钦。</p>
<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>非数学专业的工程师、经济学家等，一般会先行学习较为简单的微积分，到了某个时候发现需要更为牢固的数学基础。如果找一本《微积分学教程》来看，事实证明效果不佳。学习者要么无法安排足够的时间去学习，要么还没有足够好的数学基础，无法从研究中区分出哪些是原则的内容，哪些是较为微末的细节。</p>
<p>要满足这类学生的需求，所需其实有限。我的秘诀是：从一开始就拒绝充分详细地讲授哪怕只是阐述本课程牟一章的想法，而只限于讲授那些<strong>具有原则性的内容</strong>。我讲的更多地是关于目的和趋势、问题和方法、基本的分析概念之间的以及它们与应用之间的<strong>关系</strong>，而不是个别的定理与证明。但在有着主导作用和原则意义的概念或方法上，我则不吝时间，力求用各种手段，通过各种表述和直观形象等，尽可能明白而有效地把这些基本内容教给我的学生。有了这个基础，<strong>他们每一个人在需要更深入地研究数学分析的某一章节时，就能够独立地找到他所需的材料，然后进行研究，也就是说，可以自立地区分主要和次要、本质和非本质</strong>。</p>
<h1 id="第一讲-连续统"><a href="#第一讲-连续统" class="headerlink" title="第一讲 连续统"></a>第一讲 连续统</h1><h2 id="为什么数学分析必须从研究连续统开始？"><a href="#为什么数学分析必须从研究连续统开始？" class="headerlink" title="为什么数学分析必须从研究连续统开始？"></a>为什么数学分析必须从研究连续统开始？</h2><blockquote>
<p>如果对于变量$x$的每一个值，变量$y$都有唯一确定的值与之对应，那么变量$y$称为变量$x$的函数。</p>
</blockquote>
<p>借助于这句话，我们可以定义<strong>最重要的、最首要的数学分析概念</strong>——<strong>函数关系</strong>。在此概念中，已经奠定了借助数学工具来把握自然现象和技术过程的完整思想的萌芽。由于其重要性，我们需要给该定义完全的明确性，其中的每一个字都不应有引起一点怀疑的阴影。</p>
<p>变量$x$的每一个值，构成了函数的<strong>定义域</strong>（$x$称为<strong>自变量</strong>，$y$称为<strong>因变量</strong>）。而”值“具体是什么？它应该是数，那么定义域应当是一个<strong>数集</strong>。这里先排除掉虚数（其中的分析涉及<strong>复变函数</strong>），假设自变量与因变量皆为<strong>实数</strong>。</p>
<p>函数的定义域既取决于该函数的性质，也取决于特定的问题。前者给出自然定义域，后者给出更为特殊的定义域。</p>
<p>数学分析中，最常见的$x$集合是<strong>区间</strong>，区间或是有界的，或是无界的（半直线或直线）。无论如何，对于数学分析中的函数而言，最根本的数集是<strong>实数集</strong>。这个集合在数学中称为<strong>连续统</strong>（或线性连续统）。因其根本，所有认真而科学地编写的数学分析教程中，连续统都是第一个研究对象。</p>
<h2 id="为什么没有建立完整的实数理论是不能研究连续统的？"><a href="#为什么没有建立完整的实数理论是不能研究连续统的？" class="headerlink" title="为什么没有建立完整的实数理论是不能研究连续统的？"></a>为什么没有建立完整的实数理论是不能研究连续统的？</h2><p>那么连续统是什么样的？存在什么样的实数？如何我们才能相信已经了解了所有实数？</p>
<p>在所有的数中，我们最先接触到有理数，它可以表示可公度线段的长度，不管是整数值还是分数值，它是相当直观的。但有的线段长度无法用有理数表示，最经典的就是$\sqrt{2}$。这样，我们需要承认<strong>非有理数</strong>的存在，或更直接的<strong>无理数</strong>，如果不承认，某些线段的长度就无法表示。</p>
<p>有了无理数，就是引入了新数，新数需要确定出它与旧数的关系，至少有二：它与一个有理数的大小关系；它与有理数的运算表示，并且运算结果会产生其它新数，如$1 + \sqrt{2}$。</p>
<p>$\sqrt{2}$之后，不可避免地要考虑所有形如$r^{1&#x2F;n}$的数，其中$r$是任意正有理数，$n$是$\geq 2$的整数。</p>
<p>继续这个过程，我们称形如$P(x) &#x3D; 0$的方程的所有实根为<strong>代数数</strong>，其中的$P(x)$为带整系数的任意多项式，并把所有代数数引入到我们的新数集。特别地，任何有理数$r &#x3D; \frac{p}{q}$可作为方程$qx - p &#x3D; 0$的根包含进代数数的集合中。</p>
<p>代数数是我们数集的一个扩展，我们可以给出法则使其可以排序，以及进行代数运算。看起来已经是一个相当不错的扩展了。但是<strong>在分析之中，仅限于代数数是不够的</strong>。</p>
<h3 id="代数数与极限"><a href="#代数数与极限" class="headerlink" title="代数数与极限"></a>代数数与极限</h3><p>数学分析的第一步就要对初等代数运算添加基本且重要的分析运算——<strong>极限过程</strong>。极限不止是概念上的，还有具体而现实的意义，而且还要支持代数运算和分析运算。</p>
<p>如果任何代数数序列的极限都是代数数，那么我们是可以说，代数数集合就是<strong>连续统</strong>（关键在于，它能满足于我们的需要）。我们取单位圆，并且作出其内接正多边形，无限增加其边数，那么这些周长都可以用代数数表示。这个代数数序列的极限为圆周长（即$2\pi$）。这个极限必须承认是存在的，否则就等于是否定了圆周率。</p>
<p>另一方面，则可以证明这个极限不是代数数。这也说明，数学分析中仅考虑代数数是不够的。事实上，$\pi$这样的数称为<strong>超越数</strong>。我们的数集需要包含代数数与超越数。另一个重要的超越数是$e$。</p>
<p>那么，对于超越数我们能了解什么？现在只知道某些特殊的极限值是超越数，如$\pi$和$e$。是否可以说，我们的连续统包括所有的代数数，加上”根据需要，再添加某些特别的超越数“呢？这种定义的问题是：</p>
<ul>
<li>该集合不是一个确定性的集合，随时有可能需要添加新数</li>
<li>该定义不像有理数和代数数那样具有一致的定义，也不够优雅</li>
<li>该定义无法保证，对于新引入的数，可以一致地满足代数运算与极限运算（如代数数那样），在某些情况下，还需要引入其它数，这说明连续统还没有包含所有的实数</li>
</ul>
<p>现在可以看到，对于连续统，我们不能仅限于”按照需要“引入几个新数，而是要给出<strong>建立实数的一般性理论</strong>，该理论适用于所有的实数。</p>
<h2 id="无理数的构造"><a href="#无理数的构造" class="headerlink" title="无理数的构造"></a>无理数的构造</h2><p>存在几种不同的连续统理论，它们在处理各自问题时的<strong>思路是完全一样的</strong>。在论证时，不需要囿于某一特定的理论，可以组合或交替使用。</p>
<p><strong>所有这些理论都把有理数作为最初的数据</strong>，然后<strong>用统一的构造原则得到所有实数的集合</strong>。各种理论都基于统一思想，即：<strong>在构造新数时，基本解析极限过程起首要、主导的作用</strong>，所遇到的种种方法都可以归结为它。例如，$\sqrt{2}$的值可视为一个经过适当选择而得的有理数序列的极限。</p>
<p>构造连续统的三种方法是：</p>
<ul>
<li>戴德金分割方法</li>
<li>康托尔的基本列方法</li>
<li>魏尔斯特拉斯从十进小数表示出发的方法</li>
</ul>
<p>本书采用戴德金分割法，因其在各种教材中被广泛的采纳。</p>
<p>在引入无理数之前，我们再仔细地观察以$R$（一般用$R$表示实数）表示的有理数集。首先是它的<strong>稠密性</strong>，即任何两个有理数$r_1$和$r_2$之间总可以找到第三个有理数，最简单的例子是两者的平均数。作为推论，我们可以得出，在$r_1$和$r_2$之间始终存在有理数的无穷集合。</p>
<p>现在，考察定义$\sqrt{2}$时的情况，该数不在有理数中。那么，如果<strong>仅考虑正有理数</strong>的话，任意给定有理数$r$，要么$r^2 &lt; 2$，要么$r^2 &gt; 2$。据此，正有理数可分为两类：A类，其中的数$r_1$满足$r_1^2 &lt; 2$，B类，其中的数$r_2$满足$r_2^2 &lt; 2$，因$r_1, r_2$皆为正数，故有$r_1 &lt; r_2$。这说明<strong>A类中的每个数都小于B类中的每个数</strong>。然后我们把零和所有负数归到A类，那么上述结论不变。这时我们得到有理数集的一个<strong>分割</strong>。</p>
<blockquote>
<p>若将$R$分为两个非空的类（A，B），且A类中的每一个数都小于B类，就称之为<strong>分割</strong>。</p>
</blockquote>
<p>我们可以用更简单的方法得到分割。如把所有小于等于5的数归为A类，大于5的归为B类。如果把有理数对应到数轴上的点，那么这种分割是非常直观的。</p>
<p>现在我们有两个分割的例子，即由$\sqrt{2}$和$5$构造的。它们只是有位置的差别，还是有本质的区别？对于我们构造实数这一目的来说，它们是很不一样的。原因是，第二个分割中，$5$将有理数分割为两类，所有其它的数，或大于或小于它，而它自身也属于有理数，这种数称为<strong>分割的界限</strong>；而第一个分割不存在这样的界限。</p>
<p>PS：界限，是指其本身是有理数，同时小于它的有理数属于一类，大于大的有理数属于另一类。是故$5$是界限，而$\sqrt{2}$所定义的分割没有界限（证明见P6）。</p>
<p>这样有理数集$R$的所有分割分为两种类型：有界限的和无界限的。此外，界限还有其它性质：</p>
<ul>
<li>一个分割不可能有两个界限</li>
<li>若界限存在，则其要么是$A$类最大数，要么是$B$类最小数</li>
<li>每一个有理数$r_0$都是两个不同分割的界限，其一的$A$类是$r \leq r_0$，其二的$A$类是$r &lt; r_0$</li>
</ul>
<p>由$\sqrt{2}$的例子可以看出，这样的数是存在的（单位正方形的对角线长度），而且如果不添加这样的数，那么数集就没有其<strong>连续性</strong>和<strong>致密性</strong>。因此，我们可考虑依据<strong>分割的界限</strong>来定义新数，即<strong>无理数</strong>。</p>
<p>对于有理数集$R$的每一个没有界限的分割，我们都定义一个新的无理数与之对应，并定义此无理数即分割的界限。根据这个统一的原则，我们就确定了整个无理数的集合。连同已知的有理数集，它们构成了所有实数的几何，即<strong>连续统</strong>。</p>
<h2 id="连续统理论"><a href="#连续统理论" class="headerlink" title="连续统理论"></a>连续统理论</h2><p>上面由分割，可以构造新的无理数，或者说所有的无理数，但这一原则只是连续统理论的开始，还有大量其它工作要做：</p>
<ul>
<li>对连续统<strong>排序</strong>，确定两个实数的大小关系</li>
<li>对实数定义运算，比如$1 + \sqrt{2}$的值是什么</li>
<li>新运算具有有理数域中我们所熟知的全部性质，如加法的交换律</li>
<li>确认我们定义的连续统确实已经适应了所有实际和直观表示之需要</li>
</ul>
<p>以下将讨论实数的各个性质，须知有理数和无理数都对应到两个分割，有理数是分割的界限且为最大&#x2F;小数，无理数则不是界限，其分类亦无最大&#x2F;小数。</p>
<h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><p>利用上面提及的实数与分割关系可以证得（详见P8），两个实数各自决定的分割也决定了它们之间的大小关系。</p>
<h3 id="运算"><a href="#运算" class="headerlink" title="运算"></a>运算</h3><p>在P8-9，书中以实数加法运算为例说明了如何为连续统添加运算，以及这些运算仍然满足旧有的运算律。</p>
<h3 id="连续统的连续性"><a href="#连续统的连续性" class="headerlink" title="连续统的连续性"></a>连续统的连续性</h3><p>至此所谈及的分割都是对于有理数集的分割，这些分割有的是不存在界限的，如$\sqrt{2}$，看起来就像是有理数之间夹杂着一些不属于有理数的数，那么以数轴的角度看，有理数集是<strong>不连续的</strong>。这种不连续性也是我们扩展有理数集的原因。</p>
<p>引入无理数并且定义了实数的排序后，也可以定义连续统的分割。如果每一个连续统的分割都有一个实数作为界限（证明见P10），那么我们可以说连续统本身是连续的，这样就弥补了有理数集的不足，而数学分析的讨论就可以继续下去了。</p>
<h2 id="基本引理"><a href="#基本引理" class="headerlink" title="基本引理"></a>基本引理</h2><p>以分割建立起来的连续统为我们带来了数学分析的逻辑基础。理论上来说，接下来的所有研究都可以直接回溯到分割的定义去解决问题，但实际上很多时候，构造分割是繁琐的过程。数学家们引入了几个辅助命题（引理），这些引理在很多情况下比分割更为方便，一旦证明了这些引理，就可以把它们和分割定义一起作为后续研究的工具。</p>
<h3 id="关于单调序列的引理"><a href="#关于单调序列的引理" class="headerlink" title="关于单调序列的引理"></a>关于单调序列的引理</h3><p><strong>引理1</strong>：任何单调有界序列都有极限。</p>
<h1 id="第二讲-极限"><a href="#第二讲-极限" class="headerlink" title="第二讲 极限"></a>第二讲 极限</h1>]]></content>
      <tags>
        <tag>数学</tag>
        <tag>数学分析</tag>
      </tags>
  </entry>
  <entry>
    <title>有所不为的反叛者 - 笔记</title>
    <url>/2019/12/31/%E6%9C%89%E6%89%80%E4%B8%8D%E4%B8%BA%E7%9A%84%E5%8F%8D%E5%8F%9B%E8%80%85/</url>
    <content><![CDATA[<p>作者：罗新</p>
<h1 id="小序"><a href="#小序" class="headerlink" title="小序"></a>小序</h1><p>本书来自于近年的随笔，多与专业反思有关，或者是反应了作者<strong>对史学工作的理解</strong>。</p>
<blockquote>
<p>和相当多的史学从业者一样，我更愿意处理具体的个案研究，而不是在理论层面进行思辨。</p>
</blockquote>
<h1 id="历史学家的美德"><a href="#历史学家的美德" class="headerlink" title="历史学家的美德"></a>历史学家的美德</h1><h2 id="历史与历史学"><a href="#历史与历史学" class="headerlink" title="历史与历史学"></a>历史与历史学</h2><p>历史有什么用？这是一个伪命题，因为：</p>
<blockquote>
<p>历史是人类精神的基本构造，是人类的思维形式，离开了历史就不会有人类的思维。</p>
</blockquote>
<p>此处的历史，可以理解为“过去”，那么谁会问“过去有什么用？”</p>
<p>历史学有什么用？这是值得讨论的。</p>
<blockquote>
<p>历史不等于过去，“过去”只有被诠释、被讲述之后才成为“历史”。历史是对过去的讲述，无比巨大、混沌一团的过去中被赋予了秩序和意义并且被讲述出来的那很小很小的一部分，才是我们所说的历史。</p>
</blockquote>
<p>这里的历史由“历史学”简化而来：历史总是被讲述出来的，被讲述的只是极小的一部分，过去的单一方向和线索成为</p>
]]></content>
      <categories>
        <category>Love</category>
      </categories>
      <tags>
        <tag>Love</tag>
      </tags>
  </entry>
  <entry>
    <title>爱的艺术读书笔记</title>
    <url>/2019/06/05/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>弗洛姆是德裔美籍心理学家，第一个研究“爱”和“爱的能力”的学者，除了《爱的艺术》，还有另一著作《逃避自由》。</p>
<hr>
<h1 id="一、爱是一门艺术吗？"><a href="#一、爱是一门艺术吗？" class="headerlink" title="一、爱是一门艺术吗？"></a>一、爱是一门艺术吗？</h1><p>爱是艺术，如绘画、木工，这意味着它需要去学习，努力学习。但也有人认为，爱不是艺术，而是一种偶然产生的令人心荡神怡的感受。如果是后者，那么爱不可学习，也不需要学习。</p>
<h2 id="为什么说爱不可学？"><a href="#为什么说爱不可学？" class="headerlink" title="为什么说爱不可学？"></a>为什么说爱不可学？</h2><p>若有此想法，大概因为以下视角：</p>
<ul>
<li>我是否值得被人爱：要赢得人心与对异性有吸引力（名利、权力、举止、谈吐等）</li>
<li>爱是否成功主要看对象是谁：象对了，爱也就对了）</li>
<li>爱，主要看人的交换价值：爱变为寻找”合适的对象“，人被物化</li>
<li>爱是一种偶然的激情：只看激情，那么会以巨大的希望开始，以巨大的失望结束</li>
</ul>
<p>现实中这几点不能说没有道理，甚至可以说主导了爱的领地。它们的问题是，没有关注对方，而爱却是两个人的事情。</p>
<p>具有吸引力，不一定会爱，比如某些成功人士、某些绅士；对象当然很重要，但指望“换一个对象”就解决问题，显然也是不现实的；考虑交换价值（有人会说自己行情如何，会说在相亲市场上处于何种位置），也无可厚非，家庭、教育、收入等，无疑决定了一个人的很多方面，但不可避免的是，过于关注这一方面，感情会变成一种“权衡”，权衡关注的是“合适”，而不是爱。</p>
<p>以上种种，都不能让人获得好的爱。其结果是，人们往往把注意力放在爱之外的方面，似乎爱是一种可以自动获得的能力。一个人愿意花很多时间在工作和学习上，而在爱上就吝啬得多了。</p>
<p>实际上，爱同绘画、木工等类似，也是一门艺术，需要专门的学习。要掌握爱的艺术，需要：</p>
<ul>
<li>重视爱这门艺术</li>
<li>理论</li>
<li>实践</li>
</ul>
<h1 id="二、为什么需要爱？"><a href="#二、为什么需要爱？" class="headerlink" title="二、为什么需要爱？"></a>二、为什么需要爱？</h1><p>人生而孤独，故人的一大需要是摆脱孤独，摆脱被隔绝的状态。途径看起来有很多，总结下来不外乎：</p>
<ul>
<li>纵欲：性、毒品、酒；集体纵欲（如狂欢、暴力等），因属于集体从而无须有愧疚感；</li>
<li>同一化：血缘之群体（家庭&#x2F;家族）；想象的共同体（民族&#x2F;国家）；与他人的一致性（主流价值观&#x2F;不被孤立）；</li>
<li>创造性劳动：沉浸于艺术、木工等，进入心流；</li>
</ul>
<p>各自问题：</p>
<ul>
<li>纵欲：短暂的，需不断重复</li>
<li>同一：假的统一</li>
<li>创造性劳动：不是人与人的结合</li>
</ul>
<p>那要摆脱的最终答案是？</p>
<p>爱：） （实际上，爱是不能帮助人完全摆脱孤独感，甚至什么都不可以，但爱或许是最接近答案的一种）</p>
<p>要获得满意的爱，需要去了解爱是什么。</p>
<h1 id="三、成熟的爱情是什么样的？"><a href="#三、成熟的爱情是什么样的？" class="headerlink" title="三、成熟的爱情是什么样的？"></a>三、成熟的爱情是什么样的？</h1><p>成熟爱情：保留自己的完整性、独立性，与他人合二为一。</p>
<p>爱情冲破两个人之间的高墙，客服孤独与隔绝感，同时保持自我的完整性。</p>
<h1 id="四、爱的要素有哪些？"><a href="#四、爱的要素有哪些？" class="headerlink" title="四、爱的要素有哪些？"></a>四、爱的要素有哪些？</h1><h2 id="爱是一种积极的活动"><a href="#爱是一种积极的活动" class="headerlink" title="爱是一种积极的活动"></a>爱是一种积极的活动</h2><p>所谓积极，是指内心生长的东西，而非被俘虏的情绪或外力驱使。它表现为”给“而非”得“。</p>
<p>“给”不是放弃、牺牲和交换，它表现或者激发了一个人的生命力，他分享欢乐、兴趣、知识等，结果是<strong>提高了彼此的生命感</strong>。</p>
<p>爱上一个人的感觉是美好的，远好于被人爱。</p>
<h2 id="关心"><a href="#关心" class="headerlink" title="关心"></a>关心</h2><p>真正去关心，不是”说“，不止是意愿。</p>
<h2 id="责任心"><a href="#责任心" class="headerlink" title="责任心"></a>责任心</h2><p>不是”义务“，而是有能力且愿意负责。</p>
<h2 id="尊重"><a href="#尊重" class="headerlink" title="尊重"></a>尊重</h2><p>正视对方，认识其独有个性，使他人成为他自己，而不是服务于我。</p>
<h2 id="了解-认识"><a href="#了解-认识" class="headerlink" title="了解&#x2F;认识"></a>了解&#x2F;认识</h2><p>尊重的前提，否则关心或责任心是盲目的。</p>
<p>关心、责任心，一般人都会认同是爱的要素，但更重要的却是尊重与了解。</p>
<h1 id="五、爱自己"><a href="#五、爱自己" class="headerlink" title="五、爱自己"></a>五、爱自己</h1><p>爱一个人是一种能力，自己也是人，故爱自己也是一种能力。可以说，不会爱自己的人，不可能会爱其他人。</p>
<p>在爱自己、爱他人的过程中，我们不断了解”人“，这是爱的一个伟大之处。</p>
]]></content>
      <categories>
        <category>Love</category>
      </categories>
      <tags>
        <tag>Love</tag>
      </tags>
  </entry>
  <entry>
    <title>睡前故事一则</title>
    <url>/2019/09/02/%E7%9D%A1%E5%89%8D%E6%95%85%E4%BA%8B%E4%B8%80%E5%88%99/</url>
    <content><![CDATA[<p>从前，有一个村妇，独自抚养着两个孩子——姐姐和弟弟。</p>
<p>有一天，村妇领着弟弟回娘家，让姐姐在家看门儿，临走前嘱咐说，不要给其他人开门。</p>
<p>半路上到了一个桥头，娘俩坐下来歇息。这时，走过来一个妖精。妖精说：“大姐，我给你看看头上有没有虱子吧”，村妇同意了。妖精开始边看虱子，边与村妇闲谈，然后，就一指甲一指甲把她吃掉了。</p>
<p>天黑的时候，妖精找到了村妇的家门前，敲了三下门。姐姐便问：“你是谁？不是我娘的话，我可不开门。” 妖精回答说：“我是你娘啊。”姐姐说：“你声音这么粗，不是我娘。” 妖精说：”路远口渴，声音变沙哑了。“姐姐说：”你伸过脚来我看看。“ 妖精便从门下的缝隙伸过脚去。姐姐说：”你脚这么大，不是我娘。”妖精说：“脚大是走路拍的。” 姐姐说：”你再伸过手来我看看。“ 妖精便从门缝中伸过手去。姐姐说：”你手这么大，不是我娘。”妖精说：“手大是走路甩的。”于是，姐姐开了门。</p>
<p>晚上，“两人”通腿睡下。半夜里，姐姐醒来，听到床那头有吃东西的声音，便说：”娘，你在吃什么？“ 妖精说：”我在吃萝卜。“ 姐姐说：”我也想吃。“ 妖精就扔了一块儿过来，姐姐一看，吓了一跳，竟然是弟弟的手指，就明白妖精做了什么了。</p>
<p>第二天晚上，隔壁家灯火通明，很是热闹。姐姐说：”娘，快来看啊，大爷家的哥哥在结婚哩，很热闹。“妖精说：“墙那么高，看不见啊”。姐姐说：“我在树上栓了一把椅子，把你拉上去。”姐姐没说的是，她还偷偷把一个烧得很烫的鏊子放在了椅子上。妖精走出屋来，一坐上椅子，姐姐就迅速把椅子拉了上去，妖精就这样烫死了。</p>
]]></content>
      <categories>
        <category>故事</category>
      </categories>
      <tags>
        <tag>故事</tag>
      </tags>
  </entry>
  <entry>
    <title>线性代数及其应用-线性代数中的线性方程组</title>
    <url>/2017/10/24/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%AD%E7%9A%84%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84/</url>
    <content><![CDATA[<p>原书链接：<a href="https://book.douban.com/subject/1425950/">线性代数及其应用</a></p>
<h1 id="0-1-前言"><a href="#0-1-前言" class="headerlink" title="0.1 前言"></a>0.1 前言</h1><p>完成微积分的学生学习起来更易接受。</p>
<h2 id="本身特点"><a href="#本身特点" class="headerlink" title="本身特点"></a>本身特点</h2><ul>
<li>提前介绍主要概念</li>
<li>矩阵乘法的现代观点：定义和证明中使用矩阵的“列”，而非“元素”，核心课题是<strong>将矩阵与向量之乘积$Ax$视为关于$A$的列的一个线性组合</strong>。这种现代方法简化了很多论述，并将向量空间和线性系统的研究联系在了一起。</li>
<li>线性变换：贯穿整本书，增强了本书的几何趣味。</li>
<li>特征值和动力系统：特征值来源并应用于离散动力系统和连续动力系统。</li>
<li>正交性和最小二乘法：与普通入门教材相比，本书对这些主题的讨论更为全面。</li>
</ul>
<h1 id="0-2-给学生的注释"><a href="#0-2-给学生的注释" class="headerlink" title="0.2 给学生的注释"></a>0.2 给学生的注释</h1><p>独立完成尽可能多的习题，过早查看答案，会误以为已经理解了尚未理解的概念。</p>
<p><strong>线性代数是一种语言</strong>，用学习外语的方法<strong>每天学习这种语言</strong>。</p>
<h2 id="数值计算的注解"><a href="#数值计算的注解" class="headerlink" title="数值计算的注解"></a>数值计算的注解</h2><p>关注一下这部分内容，因为现实中的应用通常会涉及一定误差下的计算，这部分可帮助你理解计算中潜在的困难。</p>
<h2 id="Study-Guide"><a href="#Study-Guide" class="headerlink" title="Study Guide"></a>Study Guide</h2><p>善用之。</p>
<h1 id="第一章-线性代数中的线性方程组"><a href="#第一章-线性代数中的线性方程组" class="headerlink" title="第一章 线性代数中的线性方程组"></a>第一章 线性代数中的线性方程组</h1><p>1949年夏末，哈佛大学教授列昂惕夫（Leontief）使用当时最大的计算机之一Mark II计算包含500个未知数的500个方程的方程组。由于运算量“过大”，他只好将问题简化为包含42个未知数的42个方程的方程组。他后来获得了诺贝尔经济学奖，他在哈佛的工作标志着<strong>应用计算机分析大规模数学模型的开始</strong>。</p>
<p>线性代数在科学的各个领域有极为广泛的应用。</p>
<p><strong>线性方程组是线性代数的核心</strong>，本章以它来引入线性代数的许多重要概念。先介绍求解线性方程组的一个系统方法；再说明线性方程组等价于一个向量方程与矩阵方程，其后引出线性组合、线性表示与线性变换等概念。</p>
<h2 id="1-1-线性方程组"><a href="#1-1-线性方程组" class="headerlink" title="1.1 线性方程组"></a>1.1 线性方程组</h2><p>本章先是讨论求解线性方程组的一个系统方法。早在初中数学里，我们就学过了线性方程组的求解方法，当时实际上已经提到了解法的一般过程，核心部分是<strong>消元</strong>，因为只有消元才能将方程转化为可直接求解的一元方程。本章讨论的系统方法也是循着这一思路。</p>
<p>包含未知数$x_1, x_2, \cdots, x_n$的一个<strong>线性方程</strong>是形如</p>
<p>$$a_1x_1 + a_2x_2 + \cdots + a_nx_n &#x3D; b$$</p>
<p>的方程，其中$b$与诸系数是实数或复数，通常为已知数。</p>
<p>而<strong>线性方程组</strong>是由一个或几个包含相同变量$x_1, x_2, \cdots, x_n$的线性方程组成的。</p>
<p>方程组的一个<strong>解</strong>是一组数$(s_1, s_2, \cdots, s_n)$，解满足方程组的每一个方程。方程组所有可能的解的集合称为其<strong>解集</strong>。两个方程组称为等价的，若它们有相同的解集。</p>
<p>最简单的线性方程是<strong>二元一次方程</strong>，在几何上它对应于一条直线，它的解与直线上的点一一对应。而两个二元一次方程构成方程组的解集，即对应于两条直线的交点。两条直线可能会相交、平行或重合，这意味着该类方程组的解集也有三种情形：</p>
<ol>
<li>唯一解</li>
<li>无穷多解</li>
<li>无解</li>
</ol>
<p>我们说一个线性方程组是<strong>相容的</strong>，若它有一个或无穷多个解（即有解）；否则称它为<strong>不相容的</strong>（即无解）。</p>
<h3 id="1-1-1-矩阵记号"><a href="#1-1-1-矩阵记号" class="headerlink" title="1.1.1 矩阵记号"></a>1.1.1 矩阵记号</h3><p>给定一个线性方程组，可以想见，该方程组解集的情况取决于系数和等式右端的常数，与未知数的具体记号无关，所以可以用一个<strong>矩阵</strong>（矩形阵列）来表示方程组，如</p>
<p>$$\begin{split}<br>	x_1 - 2x_2 + x_3 &#x3D; 0<br> 	\<br> 	2x_2 - 8x_3 &#x3D; 8<br> 	\<br> 	-4x_1 + 5x_2 + 9x_3 &#x3D; -9<br>  \end{split}$$</p>
<p>矩阵</p>
<p>$$\begin{bmatrix}<br>      1 &amp; -2 &amp; 1  \[0.3em]<br>      0 &amp; 2  &amp; -8 \[0.3em]<br>      -4 &amp; 5 &amp; 9<br>  \end{bmatrix}$$</p>
<p>称为方程组的<strong>系数矩阵</strong>，而加上方程组右端常数列的</p>
<p>$$\begin{bmatrix}<br>      1 &amp; -2 &amp; 1 &amp; 0 \[0.3em]<br>      0 &amp; 2  &amp; -8 &amp; 8 \[0.3em]<br>      -4 &amp; 5 &amp; 9 &amp; 9<br>  \end{bmatrix}$$</p>
<p>称为其<strong>增广矩阵</strong>。</p>
<p>矩阵的定义引出其<strong>维数</strong>的概念，表示其行列数。上述增广矩阵的维数是3行4列，一般矩阵称$m \times n$矩阵。</p>
<h3 id="1-1-2-线性方程组的解法"><a href="#1-1-2-线性方程组的解法" class="headerlink" title="1.1.2 线性方程组的解法"></a>1.1.2 线性方程组的解法</h3><p>基本思路是<strong>把方程组用一个更容易的等价方程组代替</strong>，类似于我们熟悉的<strong>消元法</strong>。</p>
<p>化简方程组有三种<strong>基本变换</strong>（即<strong>行初等变换</strong>）：</p>
<ul>
<li>倍加</li>
<li>对换</li>
<li>倍乘（一行的所以元素乘以同一个非零数）</li>
</ul>
<p>容易证明，一个方程组的增广矩阵经过若干次行初等变换后，新方程组与原方程组解集相同。而且，这些<strong>行变换是可逆的</strong>。</p>
<h3 id="1-1-3-存在与唯一性问题"><a href="#1-1-3-存在与唯一性问题" class="headerlink" title="1.1.3 存在与唯一性问题"></a>1.1.3 存在与唯一性问题</h3><p>前面提及，线性方程组的解集有三种可能，可归为如下两个基本问题：</p>
<ol>
<li>方程组是否相容，即它是否有解？</li>
<li>若它有解，解是否唯一？</li>
</ol>
<p>通过行变换法，我们可以借助化简了的增广矩阵判断出方程组是否有解，进一步得出其解是否唯一。</p>
<h3 id="1-1-4-解方程组与数值计算"><a href="#1-1-4-解方程组与数值计算" class="headerlink" title="1.1.4 解方程组与数值计算"></a>1.1.4 解方程组与数值计算</h3><p>计算机中的浮点数表示难免出现舍入误差，这种不精确性有时需要引起注意。</p>
<h2 id="1-2-行化简与阶梯型矩阵"><a href="#1-2-行化简与阶梯型矩阵" class="headerlink" title="1.2 行化简与阶梯型矩阵"></a>1.2 行化简与阶梯型矩阵</h2><p>将1.1中的方法精确化后，可以得到<strong>行化简算法</strong>，可以解任意线性方程组，而且容易编程实现。这样就可以解决1.1中提出的存在与唯一性问题。该算法适用于任意矩阵。</p>
<p>矩阵中的<strong>非零行&#x2F;列</strong>指矩阵中至少包含一个非零元素的行&#x2F;列，非零行的<strong>先导元素</strong>指该行中最左边的非零元素。由此引出两类矩阵：</p>
<p><strong>定义</strong>：一个矩阵称为<strong>阶梯形</strong>（或<strong>行阶梯形</strong>），若它有以下三个性质：</p>
<ol>
<li>每一非零行在零行之上；</li>
<li>每一行的先导元素所在的列位于前一行先导元素的右面；</li>
<li>某一先导元素所在列下方元素都是零。</li>
</ol>
<p>若一个阶梯形矩阵还满足以下性质，则称它为<strong>简化阶梯形</strong>：</p>
<ol start="4">
<li>每一非零行的先导元素是1；</li>
<li>每一先导元素1是该元素所在列的唯一非零元素。</li>
</ol>
<p>若一个矩阵具有阶梯形（简化阶梯形），它就称为阶梯形（简化阶梯形）矩阵。一个矩阵可以行化简为阶梯形矩阵，不同的方法可能得到不同的阶梯形，但一个矩阵只能化为唯一的简化阶梯形矩阵。</p>
<p><strong>定理1：每个矩阵行等价于唯一的简化阶梯形矩阵</strong>。</p>
<h3 id="1-2-1-主元位置"><a href="#1-2-1-主元位置" class="headerlink" title="1.2.1 主元位置"></a>1.2.1 主元位置</h3><p>矩阵化为阶梯形后，进一步化为简化阶梯形时，先导元素的位置并不改变，而简化阶梯形是唯一的，故<strong>一个矩阵的所有阶梯形的先导元素在相同的位置上</strong>。这些先导元素对应于简化阶梯形的先导1。</p>
<p>定义：矩阵中的<strong>主元位置</strong>是对应于其阶梯形中先导元素的位置，含有主元位置的列称为<strong>主元列</strong>。</p>
<p>将矩阵化为阶梯形就可以确定出主元位置，该过程可手工计算完成，由此可抽象出一个通用的<strong>行化简算法</strong>。</p>
<h3 id="1-2-2-行化简算法"><a href="#1-2-2-行化简算法" class="headerlink" title="1.2.2 行化简算法"></a>1.2.2 行化简算法</h3><p>该算法分为5步，1-4步化矩阵为阶梯形，自左至右，称为<strong>向前步骤</strong>，第5步化阶梯形为简化阶梯形，自右至左，称为<strong>向后步骤</strong>。</p>
<p><strong>数值计算的注解</strong>：第2步选择主元时，一般选择一列中绝对值最大的元素作为主元，此方法称为<strong>部分主元法</strong>，可减少舍入误差。</p>
<h3 id="1-2-3-线性方程组的解"><a href="#1-2-3-线性方程组的解" class="headerlink" title="1.2.3 线性方程组的解"></a>1.2.3 线性方程组的解</h3><p>行化简算法应用于方程组的增广矩阵时，可以得出线性方程组解集的一种显式方法。比如，一个方程组化简之后如下：</p>
<p>$$\begin{split}<br>	x_1 - 5x_3 &#x3D; 1<br> 	\<br> 	x_2 + x_3 &#x3D; 4<br> 	\<br> 	0 &#x3D; 0<br>  \end{split}$$</p>
<p>其相应的增广矩阵也得到了化简，对应于主元列的变量$x_1$和$x_2$称为<strong>基本变量</strong>，$x_3$则称为<strong>自由变量</strong>。</p>
<p>若方程组是相容的，其解集可显式表示出来。如果有自由变量，则用其表示基本变量。由于件化阶梯形中，每个基本变量仅包含在一行（一个方程）中，这是容易表示的。上面的方程组解集可表示为：</p>
<p>$$\begin{cases}<br>    x_1 &#x3D; 1 + 5x_3 \<br>    x_2 &#x3D; 4 - x_3  \<br>    x_3是自由变量<br>  \end{cases}<br>$$</p>
<p>所谓自由变量是指它可以取任意的值。自由变量的值确定之后，基本变量的值也随之确定下来。这种解集表示称为<strong>通解</strong>，因为它给出了方程组所有解的显式表示。此种表示亦称为解集的<strong>参数表示</strong>，其中自由变量作为参数。</p>
<p>若方程组是相容的，且具有自由变量，那么其<strong>解集具有多种参数表示</strong>，一般约定为使用自由变量作为参数来表示。</p>
<h3 id="1-2-4-回代"><a href="#1-2-4-回代" class="headerlink" title="1.2.4 回代"></a>1.2.4 回代</h3><p>计算机程序在解线性方程组时，通常使用<strong>回代法</strong>求解，即在阶梯形基础上回代，而非求出简化阶梯形后再求解。一个浮算（flop）就是两个浮点数的一次运算，一般地行化简算法的向前步骤比向后步骤需要更多运算。使用Matlab的<code>flops</code>可以计算某次计算中所需要的浮算次数。</p>
<p>手工计算时求出简化阶梯形更不易出错。</p>
<h3 id="1-2-5-存在与唯一性问题"><a href="#1-2-5-存在与唯一性问题" class="headerlink" title="1.2.5 存在与唯一性问题"></a>1.2.5 存在与唯一性问题</h3><p>虽然非简化阶梯形不能直接解出线性方程组，但已足以回答关于方程组的两个基本问题，也就是如下的定理。</p>
<p><strong>定理2</strong>：存在与唯一性定理</p>
<p>线性方程组相容的充要条件是增广矩阵的最右列不是主元列。若方程组相容，当其没有自由变量，有唯一解；否则有无穷多解。</p>
]]></content>
      <tags>
        <tag>线性代数</tag>
      </tags>
  </entry>
</search>
